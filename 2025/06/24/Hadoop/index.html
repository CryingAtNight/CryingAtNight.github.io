<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hadoop | Yinjin Yao的博客</title><meta name="author" content="Yinjin Yao"><meta name="copyright" content="Yinjin Yao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hadoop简介 Hadoop是一个由Apache基金会所开发的分布式系统基础架构 主要解决，海量数据的存储和海量数据的分析计算问题 广义上来说，Hadoop通常是指一个更广泛的概念-Hadoop生态圈  分布式存储Hadoop 的分布式存储主要基于 HDFS（分布式文件系统）:HDFS将数据分割成多个数据块（block），这些数据块分散存储在集群中的不同节点上。每个数据块会有多个副本，通常默认是">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop">
<meta property="og:url" content="https://cryingatnight.github.io/2025/06/24/Hadoop/index.html">
<meta property="og:site_name" content="Yinjin Yao的博客">
<meta property="og:description" content="Hadoop简介 Hadoop是一个由Apache基金会所开发的分布式系统基础架构 主要解决，海量数据的存储和海量数据的分析计算问题 广义上来说，Hadoop通常是指一个更广泛的概念-Hadoop生态圈  分布式存储Hadoop 的分布式存储主要基于 HDFS（分布式文件系统）:HDFS将数据分割成多个数据块（block），这些数据块分散存储在集群中的不同节点上。每个数据块会有多个副本，通常默认是">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cryingatnight.github.io/img/lita9.jpg">
<meta property="article:published_time" content="2025-06-24T04:00:00.000Z">
<meta property="article:modified_time" content="2025-08-10T07:01:57.246Z">
<meta property="article:author" content="Yinjin Yao">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cryingatnight.github.io/img/lita9.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Hadoop",
  "url": "https://cryingatnight.github.io/2025/06/24/Hadoop/",
  "image": "https://cryingatnight.github.io/img/lita9.jpg",
  "datePublished": "2025-06-24T04:00:00.000Z",
  "dateModified": "2025-08-10T07:01:57.246Z",
  "author": [
    {
      "@type": "Person",
      "name": "Yinjin Yao",
      "url": "https://cryingatnight.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/headimage.png"><link rel="canonical" href="https://cryingatnight.github.io/2025/06/24/Hadoop/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/headimage.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-flask"></i><span> 实验室</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="http://121.199.61.105/"><i class="fa-fw fas fa-q"></i><span> 豆瓣网开发</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://fuckornot.on.websim.com/"><i class="fa-fw fa fa-trophy"></i><span> 上不上AI评分系统</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://fontawesome.com/icons"><i class="fa-fw fa fa-check-circle"></i><span> font-awesome v6 图标</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/lita9.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/headimage.png" alt="Logo"><span class="site-name">Yinjin Yao的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">Hadoop</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-flask"></i><span> 实验室</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="http://121.199.61.105/"><i class="fa-fw fas fa-q"></i><span> 豆瓣网开发</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://fuckornot.on.websim.com/"><i class="fa-fw fa fa-trophy"></i><span> 上不上AI评分系统</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://fontawesome.com/icons"><i class="fa-fw fa fa-check-circle"></i><span> font-awesome v6 图标</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-24T04:00:00.000Z" title="发表于 2025-06-24 12:00:00">2025-06-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-10T07:01:57.246Z" title="更新于 2025-08-10 15:01:57">2025-08-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Hadoop简介"><a href="#Hadoop简介" class="headerlink" title="Hadoop简介"></a>Hadoop简介</h1><ul>
<li>Hadoop是一个由Apache基金会所开发的分布式系统基础架构</li>
<li>主要解决，<strong>海量数据的存储和海量数据的分析计算问题</strong></li>
<li>广义上来说，Hadoop通常是指一个更广泛的概念-Hadoop生态圈</li>
</ul>
<h2 id="分布式存储"><a href="#分布式存储" class="headerlink" title="分布式存储"></a>分布式存储</h2><p>Hadoop 的分布式存储主要基于 HDFS（分布式文件系统）:<br>HDFS将数据<strong>分割成多个数据块（block）</strong>，这些数据块<strong>分散存储在集群中的不同节点上</strong>。每个数据块会有多个副本，通常默认是 3 个副本.采用分布式存储在不同的节点上，提高了数据的可靠性和容错性。</p>
<p><img src="/2025/06/24/Hadoop/image-20250701140958694.png" alt="image-20250701140958694"></p>
<p>Hadoop的分布式核心组件是MapReduce编程模型:<br>在MapReduce任务中，数据被切分为多个任务，每个任务由或多个节点并行。每个节点负责将输入数据映射为键-值对生成中间结果。最后，中间结果按照键的排序进行合并和归并。</p>
<p><img src="/2025/06/24/Hadoop/image-20250701141052158.png" alt="image-20250701141052158"></p>
<p><img src="/2025/06/24/Hadoop/image-20250701141243480.png" alt="image-20250701141243480"></p>
<h1 id="Hadoop组件-面试重点"><a href="#Hadoop组件-面试重点" class="headerlink" title="Hadoop组件(面试重点)"></a>Hadoop组件(面试重点)</h1><p><a href="hadoop%E9%97%AE%E7%AD%94%E5%B0%8F%E6%B5%8B%E9%AA%8C.md">hadoop问答小测验</a></p>
<h2 id="HDFS-架构概述"><a href="#HDFS-架构概述" class="headerlink" title="HDFS 架构概述"></a>HDFS 架构概述</h2><p>HDFS组件用于存储数据,主要由NameNode,DataNode,SecondaryNameNode 组成</p>
<ul>
<li><strong>NameNode (nn)</strong>: <strong>存储文件的元数据</strong>，如文件名，文件目录结构，文件属性 (生成时间、副本数、文件权限)，以及每个文件的块列表和块所在的DataNode等。</li>
<li><strong>DataNode(dn)</strong>: 在本地文件系统<strong>存储文件块数据，以及块数据的校验。</strong></li>
<li><strong>SecondaryNameNode(2nn)</strong>: 每隔一段时间<strong>对NameNode元数据进行备份</strong></li>
</ul>
<h2 id="Yarn-架构概述"><a href="#Yarn-架构概述" class="headerlink" title="Yarn 架构概述"></a>Yarn 架构概述</h2><p><strong>Yet Another Resource Negotiator 简称YARN ，另一种资源协调者，是Hadoop 的资源管理器。</strong></p>
<p>Yarn资源调度负责硬件资源管理,主要由:ResourceManager,NodeManager,ApplicationMaster组成<br><img src="/2025/06/24/Hadoop/file-20250810003459589.png"></p>
<ul>
<li><strong>ResourceManager</strong> (资源管理器):<strong>.<strong>YARN集群中的中心调度器和资源管理器。</strong>负责整个集群的资源分配和调度 监控集群中的计算资源任务的运行状态</strong>。</li>
<li><strong>NodeManager</strong> (节点管理器):<strong>单个节点服务器资源的管理者。</strong>每个计算节点上运行的代理程序<strong>负责管理和监控节点上的资源和任务</strong>。接收来自RM的任务调度请求;启动、停止和监控任务的执行;发送节点的状态和可用资源报告</li>
<li><strong>ApplicationMaster</strong> (应用程序管理器)：<strong>单个任务运行的管理者</strong>。每个应用程序在YARN中都有一个对应的AM.AppMaster负责协调和管理应用程序的执行。它与RM交互申请资源并监任务的执行。它还<strong>负责任务的划分和调度、容错和恢复、进度跟踪</strong>等。</li>
<li><strong><code>Container</code><strong>：容器，相当于一台独立的服务器，里面封装了任务运行所需要的资源，如</strong>内存、CPU、磁盘、网络</strong>等。</li>
</ul>
<p>说明：<br>（1）客户端可以有多个<br>（2）集群上可以运行多个ApplicationMaster<br>（3）每个NodeManager上可以有多个Container</p>
<h2 id="MapReduce-架构概述"><a href="#MapReduce-架构概述" class="headerlink" title="MapReduce 架构概述"></a>MapReduce 架构概述</h2><p>MapReduce 将计算过程分为两个阶段：Map 和Reduce  </p>
<ol>
<li>Map 阶段并行处理输入数据  </li>
<li>Reduce 阶段对Map 结果进行汇总<br><img src="/2025/06/24/Hadoop/file-20250810004014162.png"></li>
</ol>
<h2 id="HDFS、YARN、MapReduce-三者关系"><a href="#HDFS、YARN、MapReduce-三者关系" class="headerlink" title="HDFS、YARN、MapReduce 三者关系"></a>HDFS、YARN、MapReduce 三者关系</h2><p><img src="/2025/06/24/Hadoop/file-20250810004101508.png"></p>
<h2 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h2><p><img src="/2025/06/24/Hadoop/file-20250810004247220.png"><br>图中涉及的技术名词解释如下：</p>
<ol>
<li><code>Sqoop</code>：Sqoop 是一款开源的工具，主要用于在Hadoop、Hive 与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到Hadoop 的HDFS 中，也可以将HDFS 的数据导进到关系型数据库中。</li>
<li><code>Flume</code>：Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume 支持在日志系统中定制各类数据发送方，用于收集数据。</li>
<li><code>Kafka</code>：Kafka 是一种高吞吐量的分布式发布订阅消息系统。</li>
<li><code>Spark</code>：Spark 是当前最流行的开源大数据内存计算框架。可以基于Hadoop 上存储的大数据进行计算。</li>
<li><code>Flink</code>：Flink 是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。</li>
<li><code>Oozie</code>：Oozie 是一个管理Hadoop 作业（job）的工作流程调度管理系统。</li>
<li><code>Hbase</code>：HBase 是一个分布式的、面向列的开源数据库。HBase 不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</li>
<li><code>Hive</code>：Hive 是基于Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL 查询功能，可以将SQL 语句转换为MapReduce 任务进行运行。其优点是学习成本低，可以通过类SQL 语句快速实现简单的MapReduce 统计，不必开发专门的MapReduce 应用，十分适合数据仓库的统计分析。</li>
<li><code>ZooKeeper</code>：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</li>
</ol>
<h2 id="推荐系统框架图"><a href="#推荐系统框架图" class="headerlink" title="推荐系统框架图"></a>推荐系统框架图</h2><p>推荐系统项目框架<br><img src="/2025/06/24/Hadoop/file-20250810004351655.png"></p>
<h1 id="三个虚拟机配置分布式-环境搭建-开发重点"><a href="#三个虚拟机配置分布式-环境搭建-开发重点" class="headerlink" title="三个虚拟机配置分布式(环境搭建:开发重点)"></a>三个虚拟机配置分布式(环境搭建:开发重点)</h1><p><img src="/2025/06/24/Hadoop/image-20250626092139322.png" alt="image-20250626092139322"> </p>
<h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><ol>
<li><p>操作系统环境</p>
<ol>
<li>操作系统以及软件系统环境搭建</li>
<li>ssh免密操作</li>
</ol>
</li>
<li><p>hadoop软件</p>
<ol>
<li><p>软件安装</p>
</li>
<li><p>集群配置</p>
</li>
</ol>
</li>
</ol>
<p><strong>环境配置</strong></p>
<ol>
<li><p>打开虚拟机-&gt;2.虚拟网络编辑-&gt;3.更改配置-&gt;</p>
</li>
<li><p><img src="/2025/06/24/Hadoop/image-20250626093107076.png" alt="image-20250626093107076"></p>
</li>
<li><p>本机网络更改适配器选项，找到</p>
</li>
<li><p><img src="/2025/06/24/Hadoop/image-20250626093422694.png" alt="image-20250626093422694"></p>
</li>
<li><p>新建虚拟机-&gt;稍后安装操作系统-&gt;虚拟机名称改为hadoop100，位置改为D:vmware&#x2F;hadoop100,<img src="/2025/06/24/Hadoop/image-20250626094736868.png" alt="image-20250626094736868"></p>
</li>
</ol>
<p><img src="/2025/06/24/Hadoop/image-20250626094807272.png" alt="image-20250626094807272"><img src="/2025/06/24/Hadoop/image-20250626094854252.png" alt="image-20250626094854252"><img src="/2025/06/24/Hadoop/image-20250626094926569.png" alt="image-20250626094926569"></p>
<p><strong>启动虚拟机</strong></p>
<ol>
<li><p>最小化安装</p>
</li>
<li><p><strong>网络配置</strong></p>
<p><img src="/2025/06/24/Hadoop/image-20250626095142289.png" alt="image-20250626095142289"></p>
</li>
</ol>
<p><img src="/2025/06/24/Hadoop/image-20250626095226047.png" alt="image-20250626095226047"></p>
<p>开始安装-&gt;<strong>用户和密码都改为root</strong></p>
<h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h2><h3 id="软件准备-上传文件"><a href="#软件准备-上传文件" class="headerlink" title="软件准备&#x2F;上传文件"></a>软件准备&#x2F;上传文件</h3><ol>
<li><p>jdk-8u212-linux-x64.tar.gz</p>
</li>
<li><p>hadoop-3.1.3.tar.gz</p>
</li>
<li><p>CentOS-Base.repo</p>
</li>
</ol>
<h3 id="hadoop安装过程"><a href="#hadoop安装过程" class="headerlink" title="hadoop安装过程"></a>hadoop安装过程</h3><h4 id="系统环境配置"><a href="#系统环境配置" class="headerlink" title="系统环境配置"></a>系统环境配置</h4><ol>
<li><p>下载源的调整</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.拷贝一份新的阿里云的 下载源 到 /etc/yum.repos.d/下 </span></span><br><span class="line"><span class="built_in">mv</span> /etc/yum.repos.d/CentOS-Base.repo</span><br><span class="line"><span class="comment">#2.清空原下载池</span></span><br><span class="line"><span class="built_in">sudo</span> yum clean all</span><br><span class="line"><span class="comment">#3. 加载新源</span></span><br><span class="line"><span class="built_in">sudo</span> yum makecache</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装epel-release(软件仓库)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装必要工具</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y net-tools rsync vim wget ntp</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭防火墙</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭selinux</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/selinux/config</span><br><span class="line"><span class="comment"># 将SELINUX=enforcing改为</span></span><br><span class="line">SELINUX=disabled</span><br><span class="line"><span class="comment">#wq保存</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="软件安装-1"><a href="#软件安装-1" class="headerlink" title="软件安装"></a>软件安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#配置主机名映射</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line">ip hostname</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line">vim /etc/profile.d/my_env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line">tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br><span class="line"></span><br><span class="line">vim /etc/profile.d/my_env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"></span><br><span class="line"><span class="comment">#更新环境变量</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"><span class="comment">#测试环境变量配置</span></span><br><span class="line">hadoop version</span><br></pre></td></tr></table></figure>

<h4 id="主机克隆操作"><a href="#主机克隆操作" class="headerlink" title="主机克隆操作"></a>主机克隆操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br><span class="line"></span><br><span class="line">IPADDR=<span class="string">&quot;192.168.200.102&quot;</span></span><br><span class="line"></span><br><span class="line">hostnamectl set-hostname hadoop101</span><br></pre></td></tr></table></figure>

<h4 id="SSH协议免密配置"><a href="#SSH协议免密配置" class="headerlink" title="SSH协议免密配置"></a>SSH协议免密配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#生成密钥对</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="comment">#传输密钥</span></span><br><span class="line">ssh-copy-id hadoop100</span><br></pre></td></tr></table></figure>

<p><img src="/2025/06/24/Hadoop/image-20250701141804317.png" alt="image-20250701141804317"></p>
<h4 id="配置集群文件"><a href="#配置集群文件" class="headerlink" title="配置集群文件"></a>配置集群文件</h4><h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop100:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为root --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- nn web端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 2nn web端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="workers"><a href="#workers" class="headerlink" title="workers"></a>workers</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /opt/module/hadoop-3.1.3/etc/hadoop/workers</span><br></pre></td></tr></table></figure>

<figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop100</span><br><span class="line">hadoop101</span><br><span class="line">hadoop102</span><br></pre></td></tr></table></figure>

<h3 id="格式化hdfs文件系统-谨慎使用"><a href="#格式化hdfs文件系统-谨慎使用" class="headerlink" title="格式化hdfs文件系统(谨慎使用)"></a>格式化hdfs文件系统(<em><strong>谨慎使用</strong></em>)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br><span class="line"><span class="comment">#hdfs 安全模式 关闭</span></span><br><span class="line">hdfs dfsadmin -safemode leave</span><br><span class="line"><span class="comment">#hdfs 安全模式 强制关闭</span></span><br><span class="line">hdfs dfsadmin -safemode forceExit</span><br></pre></td></tr></table></figure>

<h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><h4 id="start-dfs-sh-stop-dfs-sh"><a href="#start-dfs-sh-stop-dfs-sh" class="headerlink" title="start-dfs.sh stop-dfs.sh"></a>start-dfs.sh stop-dfs.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim sbin/start-dfs.sh </span><br><span class="line">vim sbin/stop-dfs.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">HDFS_DATANODE_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=hdfs</span><br><span class="line">HDFS_NAMENODE_USER=root</span><br><span class="line">HDFS_SECONDARYNAMENODE_USER=root</span><br></pre></td></tr></table></figure>

<h4 id="start-yarn-sh-stop-yarn-sh"><a href="#start-yarn-sh-stop-yarn-sh" class="headerlink" title="start-yarn.sh stop-yarn.sh"></a>start-yarn.sh stop-yarn.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim sbin/start-yarn.sh</span><br><span class="line">vim sbin/stop-yarn.sh</span><br><span class="line"></span><br><span class="line">YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=yarn</span><br><span class="line">YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure>

<h3 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h3><h4 id="mapred-site-xml-1"><a href="#mapred-site-xml-1" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h4><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br><span class="line">mapred --daemon start historyserver</span><br><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="配置历史聚集"><a href="#配置历史聚集" class="headerlink" title="配置历史聚集"></a>配置历史聚集</h3><h4 id="yarn-site-xml-1"><a href="#yarn-site-xml-1" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h4><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br><span class="line"><span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop101:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="启停脚本"><a href="#启停脚本" class="headerlink" title="启停脚本"></a>启停脚本</h3><h4 id="myhadoop-sh"><a href="#myhadoop-sh" class="headerlink" title="myhadoop.sh"></a>myhadoop.sh</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;No Args Input...&quot;</span><br><span class="line">    exit ;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">    echo &quot; =================== 启动 hadoop集群 ===================&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    echo &quot; --------------- 启动 hdfs ---------------&quot;</span><br><span class="line">    ssh hadoop100 &quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh&quot;</span><br><span class="line">    echo &quot; --------------- 启动 yarn ---------------&quot;</span><br><span class="line">    ssh hadoop101 &quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;</span><br><span class="line">    echo &quot; --------------- 启动 historyserver ---------------&quot;</span><br><span class="line">    ssh hadoop100 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver&quot;</span><br><span class="line">;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">    echo &quot; =================== 关闭 hadoop集群 ===================&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    echo &quot; --------------- 关闭 historyserver ---------------&quot;</span><br><span class="line">    ssh hadoop100 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver&quot;</span><br><span class="line">    echo &quot; --------------- 关闭 yarn ---------------&quot;</span><br><span class="line">    ssh hadoop101 &quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot;</span><br><span class="line">    echo &quot; --------------- 关闭 hdfs ---------------&quot;</span><br><span class="line">    ssh hadoop100 &quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;status&quot;)</span><br><span class="line">    echo &quot; =================== hadoop集群状态 ===================&quot;</span><br><span class="line">   for host in hadoop100 hadoop101 hadoop102</span><br><span class="line">do</span><br><span class="line">        echo =============== $host ===============</span><br><span class="line">        ssh $host jps </span><br><span class="line">done</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<h3 id="同步脚本"><a href="#同步脚本" class="headerlink" title="同步脚本"></a>同步脚本</h3><p>在<code>/root/bin</code>目录下创建<code>xsync</code>文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1. 判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo &quot;请输入文件目录的路径&quot;</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in hadoop100 hadoop101 hadoop102 </span><br><span class="line">do</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    echo ==================== $host ====================</span><br><span class="line">    #3. 遍历所有⽬录，挨个发送</span><br><span class="line">    for file in $@</span><br><span class="line">    do</span><br><span class="line">        #4. 判断⽂件是否存在</span><br><span class="line">        if [ -e $file ]</span><br><span class="line">        then</span><br><span class="line">            #5. 获取父目录</span><br><span class="line">            pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">            #6. 获取当前⽂件的名称</span><br><span class="line">            fname=$(basename $file)</span><br><span class="line">            rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">        else</span><br><span class="line">            echo &quot;文件不存在 $file&quot;</span><br><span class="line">        fi</span><br><span class="line">     done</span><br><span class="line">done</span><br><span class="line">xsync abc </span><br></pre></td></tr></table></figure>

<hr>
<p>修改脚本<code>xsync</code>具有执行权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x xsync</span><br></pre></td></tr></table></figure>

<h4 id="结果截图"><a href="#结果截图" class="headerlink" title="结果截图"></a>结果截图</h4><p><img src="/2025/06/24/Hadoop/image-20250701144157828.png" alt="image-20250701144157828"></p>
<p><img src="/2025/06/24/Hadoop/image-20250701144252469.png" alt="image-20250701144252469"></p>
<p><img src="/2025/06/24/Hadoop/image-20250701144309728.png" alt="image-20250701144309728"></p>
<h1 id="hadoop大数据平台-hive组件部署介绍"><a href="#hadoop大数据平台-hive组件部署介绍" class="headerlink" title="hadoop大数据平台-hive组件部署介绍"></a>hadoop大数据平台-hive组件部署介绍</h1><p><img src="/2025/06/24/Hadoop/image-20250701143412258.png" alt="image-20250701143412258"></p>
<h1 id="Hadoop平台-进程启停命令"><a href="#Hadoop平台-进程启停命令" class="headerlink" title="Hadoop平台-进程启停命令"></a>Hadoop平台-进程启停命令</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.日志服务启停命令</span></span><br><span class="line">mapred --daemon start historyserver</span><br><span class="line"><span class="comment">#2.HDFS文件系统服务启停命令</span></span><br><span class="line">hdfs --daemon start namenode/datanode/secondarynamenode</span><br><span class="line"><span class="comment">#4.Yarn服务启停命令</span></span><br><span class="line">yarn --daemon start/stop  resourcemanager/nodemanager</span><br></pre></td></tr></table></figure>

<h1 id="Hadoop平台-HDFS文件系统命令"><a href="#Hadoop平台-HDFS文件系统命令" class="headerlink" title="Hadoop平台-HDFS文件系统命令"></a>Hadoop平台-HDFS文件系统命令</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">-<span class="built_in">ls</span> [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [&lt;path&gt; ...]:  <span class="comment">#查看指定路径的文件或目录列表。</span></span><br><span class="line">-<span class="built_in">mkdir</span> [-p] &lt;path&gt; ...:  <span class="comment">#创建新的文件夹。</span></span><br><span class="line">-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;:  <span class="comment">#从本地移动文件到HDFS。</span></span><br><span class="line">-moveToLocal &lt;src&gt; &lt;localdst&gt;:  <span class="comment">#将文件从HDFS移动到本地。</span></span><br><span class="line">-<span class="built_in">mv</span> &lt;src&gt; ... &lt;dst&gt;:  <span class="comment">#在HDFS文件系统内移动文件。</span></span><br><span class="line">-put [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;:  <span class="comment">#上传文件到HDFS。</span></span><br><span class="line">-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;:  <span class="comment">#重命名指定目录下的快照。</span></span><br><span class="line">-<span class="built_in">rm</span> [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...:  <span class="comment">#删除文件或目录（只能删除空文件夹）。</span></span><br><span class="line">-<span class="built_in">rmdir</span> [--ignore-fail-on-non-empty] &lt;<span class="built_in">dir</span>&gt; ...:  <span class="comment">#删除空文件夹，可以使用`--ignore-fail-on-non-empty`选项删除非空文件夹。</span></span><br><span class="line">-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--<span class="built_in">set</span> &lt;acl_spec&gt; &lt;path&gt;]:  <span class="comment">#设置文件或目录的ACL（访问控制列表）。</span></span><br><span class="line">-setfattr &#123;-n name [-v value] | -x name&#125; &lt;path&gt;:  <span class="comment">#设置文件或目录的扩展属性。</span></span><br><span class="line">-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...:  <span class="comment">#设置文件的副本数量。</span></span><br><span class="line">-<span class="built_in">stat</span> [format] &lt;path&gt; ...:  <span class="comment">#显示文件或目录的状态信息。</span></span><br><span class="line">-<span class="built_in">tail</span> [-f] [-s &lt;<span class="built_in">sleep</span> interval&gt;] &lt;file&gt;:  <span class="comment">#查看文件的末尾部分内容。</span></span><br><span class="line">-<span class="built_in">test</span> -[defsz] &lt;path&gt;:  <span class="comment">#测试文件的存在性、目录的空或非空等属性。</span></span><br><span class="line">-text [-ignoreCrc] &lt;src&gt; ...:  <span class="comment">#以文本形式查看文件的内容。</span></span><br><span class="line">-<span class="built_in">touch</span> [-a] [-m] [-t TIMESTAMP ] [-c] &lt;path&gt; ...:  <span class="comment">#创建一个空文件或者更新已有文件的时间戳。</span></span><br><span class="line">-touchz &lt;path&gt; ...:  <span class="comment">#创建一个空文件。</span></span><br><span class="line">-<span class="built_in">truncate</span> [-w] &lt;length&gt; &lt;path&gt; ...:  <span class="comment">#清空文件内容或者将文件截断到指定的长度。</span></span><br><span class="line">-usage [cmd ...]:  <span class="comment">#显示HDFS命令的用法信息。</span></span><br><span class="line"></span><br><span class="line">-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;:  <span class="comment">#将本地目录追加到HDFS下的某个文件中。</span></span><br><span class="line">-<span class="built_in">cat</span> [-ignoreCrc] &lt;src&gt; ...:  <span class="comment">#查看某个文件的内容。</span></span><br><span class="line">-checksum &lt;src&gt; ...:  <span class="comment">#计算并确认文件的校验和。</span></span><br><span class="line">-<span class="built_in">chgrp</span> [-R] GROUP PATH...:  <span class="comment">#修改文件或目录的所属用户组。</span></span><br><span class="line">-<span class="built_in">chmod</span> [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...:  <span class="comment">#修改文件或目录的权限。</span></span><br><span class="line">-<span class="built_in">chown</span> [-R] [OWNER][:[GROUP]] PATH...:  <span class="comment">#修改文件或目录的所属用户。</span></span><br><span class="line">-copyFromLocal [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] &lt;localsrc&gt; ... &lt;dst&gt;:  <span class="comment">#从本地复制文件到HDFS。</span></span><br><span class="line">-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;:  <span class="comment">#从HDFS复制文件到本地。</span></span><br><span class="line">-count [-q] [-h] [-v] [-t [&lt;storage <span class="built_in">type</span>&gt;]] [-u] [-x] [-e] &lt;path&gt; ...:  <span class="comment">#统计文件或目录的数量。</span></span><br><span class="line">-<span class="built_in">cp</span> [-f] [-p | -p[topax]] [-d] &lt;src&gt; ... &lt;dst&gt;:  <span class="comment">#在HDFS文件系统中拷贝文件。</span></span><br><span class="line">-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]:  <span class="comment">#创建指定目录的快照。</span></span><br><span class="line">-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;:  <span class="comment">#删除指定目录下的快照。</span></span><br><span class="line">-<span class="built_in">df</span> [-h] [&lt;path&gt; ...]:  <span class="comment">#查看文件系统剩余空间。</span></span><br><span class="line">-<span class="built_in">du</span> [-s] [-h] [-v] [-x] &lt;path&gt; ...:  <span class="comment">#计算文件或目录的磁盘使用情况。</span></span><br><span class="line">-expunge:  <span class="comment">#清空HDFS垃圾箱。</span></span><br><span class="line">-find &lt;path&gt; ... &lt;expression&gt; ...:  <span class="comment">#在指定路径下查找符合条件的文件。</span></span><br><span class="line">-get [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;:  <span class="comment">#从HDFS下载文件到本地。</span></span><br><span class="line">-getfacl [-R] &lt;path&gt;:  <span class="comment">#获取文件或目录的ACL（访问控制列表）信息。</span></span><br><span class="line">-getfattr [-R] &#123;-n name | -d&#125; [-e en] &lt;path&gt;:  <span class="comment">#获取文件或目录的扩展属性信息。</span></span><br><span class="line">-getmerge [-<span class="built_in">nl</span>] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;:  <span class="comment">#将多个文件合并为一个文件并下载到本地。</span></span><br><span class="line">-<span class="built_in">head</span> &lt;file&gt;:  <span class="comment">#查看文件的开头部分内容。</span></span><br><span class="line">-<span class="built_in">help</span> [cmd ...]:  <span class="comment">#获取HDFS命令的帮助。</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Hadoop平台-HDFS优缺点"><a href="#Hadoop平台-HDFS优缺点" class="headerlink" title="Hadoop平台-HDFS优缺点"></a>Hadoop平台-HDFS优缺点</h1><p><strong>HDFS组件用于存储数据,主要由*NameNode,DataNode,SecondaryNameNode 组成</strong></p>
<p><img src="/2025/06/24/Hadoop/image-20250701144959041.png" alt="image-20250701144959041"></p>
<h1 id="Hadoop平台-HDFS读取流程"><a href="#Hadoop平台-HDFS读取流程" class="headerlink" title="Hadoop平台-HDFS读取流程"></a>Hadoop平台-HDFS读取流程</h1><p><img src="/2025/06/24/Hadoop/image-20250701145056181.png" alt="image-20250701145056181"></p>
<h1 id="Hadoop平台-NameNode更新流程"><a href="#Hadoop平台-NameNode更新流程" class="headerlink" title="Hadoop平台-NameNode更新流程"></a>Hadoop平台-NameNode更新流程</h1><p><img src="/2025/06/24/Hadoop/image-20250701145144059.png" alt="image-20250701145144059"></p>
<h1 id="Hadoop平台-yarn工作流程"><a href="#Hadoop平台-yarn工作流程" class="headerlink" title="Hadoop平台-yarn工作流程"></a>Hadoop平台-yarn工作流程</h1><p><img src="/2025/06/24/Hadoop/image-20250701145303204.png" alt="image-20250701145303204"></p>
<h1 id="Hadoop平台-mapreduce工作流程"><a href="#Hadoop平台-mapreduce工作流程" class="headerlink" title="Hadoop平台-mapreduce工作流程"></a>Hadoop平台-mapreduce工作流程</h1><p><img src="/2025/06/24/Hadoop/image-20250701145353344.png" alt="image-20250701145353344"></p>
<h1 id="什么是HIVE"><a href="#什么是HIVE" class="headerlink" title="什么是HIVE"></a>什么是HIVE</h1><p>Hive 是<strong>基于 Hadoop 的一个数据仓库工具</strong>。以下是具体介绍:</p>
<ul>
<li><strong>功能特点</strong>：Hive 可以<strong>将结构化的数据文件映射为一张数据库表</strong>，并提供完整的 SQL 查询功能，能将 SQL 语句转换为 MapReduce 任务进行运行。它允许熟悉 SQL 的用户方便地查询数据，也支持熟悉 MapReduce 的开发者自定义 mapper 和 reducer，以处理复杂的分析工作。</li>
<li><strong>优势</strong>：学习成本低，通过类 SQL 语句可快速实现简单的 MapReduce 统计，无需开发专门的 MapReduce 应用，十分适合数据仓库的统计分析。</li>
<li><strong>应用场景</strong>：常用于对时效性要求不高的数据分析场景。由于 <strong>Hive 底层依赖 Hadoop 的 HDFS 存储数据</strong>，利用 MapReduce 进行计算，因此能够处理大规模的数据，在处理海量结构化日志的数据统计等方面应用广泛。</li>
<li><strong>与数据库的区别</strong>：<ol>
<li>数据库一般用于在线应用，支持对某一行或某些行数据的更新、删除等操作，采用 “写时模式”，数据加载慢但查询快。</li>
<li>而 Hive 不支持对具体行的操作，也不支持事务和索引，采用 “读时模式”，适合处理非结构化或存储模式未知的数据，更侧重于对海量数据的批量处理和分析。</li>
</ol>
</li>
</ul>
<h1 id="HIVE安装"><a href="#HIVE安装" class="headerlink" title="HIVE安装"></a>HIVE安装</h1><h2 id="配置mysql安装源"><a href="#配置mysql安装源" class="headerlink" title="配置mysql安装源"></a>配置mysql安装源</h2><p>（在线安装方法）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载安装源</span></span><br><span class="line">wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 mysql 源</span></span><br><span class="line">yum localinstall mysql57-community-release-el7-11.noarch.rpm</span><br><span class="line"><span class="comment"># 导入key</span></span><br><span class="line">rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022</span><br><span class="line"><span class="comment"># 修改国内源</span></span><br><span class="line">vim /etc/yum.repos.d/mysql-community.repo</span><br><span class="line">修改 baseurl 为 https://mirrors.cloud.tencent.com/mysql/yum/mysql-5.7-community-el7-x86_64/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#安装mysql</span></span><br><span class="line">yum install -y mysql-community-server</span><br></pre></td></tr></table></figure>

<ol>
<li>安装mysql （本地安装方法）</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">00#rpm包安装</span><br><span class="line"><span class="comment">#tar -zvxf mysql-5.7.22-linux-glibc2.12-x86_64.tar.gz  -C /usr/local/mysql</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#2.解压：</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local</span><br><span class="line">tar -zxvf mysql-5.7.22-linux-glibc2.12-x86_64.tar</span><br><span class="line"><span class="built_in">mv</span> mysql-5.7.22-linux-glibc2.12-x86_64 mysql-5.7.22</span><br><span class="line"><span class="built_in">ln</span> -s mysql-5.7.22 mysql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#3.添加用户组和用户</span></span><br><span class="line"><span class="comment">#添加用户组</span></span><br><span class="line">groupadd mysql</span><br><span class="line"><span class="comment">#添加用户mysql 到用户组mysql</span></span><br><span class="line">useradd -g mysql mysql</span><br><span class="line"><span class="comment">#4.安装</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local/mysql</span><br><span class="line"><span class="built_in">mkdir</span> data</span><br><span class="line"><span class="built_in">chown</span> -R mysql:mysql ./</span><br><span class="line">./bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql/m<span class="string">&#x27;y&#x27;</span>s<span class="string">&#x27;q --datadir=/usr/local/mysql/data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#将mysql/目录下除了data/目录的所有文件，改回root用户所有</span></span><br><span class="line"><span class="string">chown -R root .</span></span><br><span class="line"><span class="string">#mysql用户只需作为mysql-5.7.22/data/目录下所有文件的所有者</span></span><br><span class="line"><span class="string">chown -R mysql data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#5.复制启动文件</span></span><br><span class="line"><span class="string">cp support-files/mysql.server /etc/init.d/mysqld</span></span><br><span class="line"><span class="string">chmod 755 /etc/init.d/mysqld</span></span><br><span class="line"><span class="string">cp bin/my_print_defaults /usr/bin/ </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#6.修改启动脚本</span></span><br><span class="line"><span class="string">vi /etc/init.d/mysqld</span></span><br><span class="line"><span class="string">#修改项：</span></span><br><span class="line"><span class="string">basedir=/usr/local/mysql-5.7.22/</span></span><br><span class="line"><span class="string">datadir=/usr/local/mysql-5.7.22/data</span></span><br><span class="line"><span class="string">port=3306</span></span><br><span class="line"><span class="string">#加入环境变量，编辑 /etc/profile，这样可以在任何地方用mysql命令了</span></span><br><span class="line"><span class="string">vi ~/.bash_profile</span></span><br><span class="line"><span class="string">#添加mysql路径，加入下面内容，按ESC--&gt;:wq保存</span></span><br><span class="line"><span class="string">export PATH=$PATH:/usr/local/mysql-5.7.22/bin</span></span><br><span class="line"><span class="string">#刷新立即生效</span></span><br><span class="line"><span class="string">source ~/.bash_profile</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#7.修改mysql配置项</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">vi /etc/my.cnf</span></span><br><span class="line"><span class="string">#配置如下：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[mysqld]</span></span><br><span class="line"><span class="string">basedir = /usr/local/mysql</span></span><br><span class="line"><span class="string">datadir = /usr/local/mysql/data</span></span><br><span class="line"><span class="string">socket = /tmp/mysql.sock</span></span><br><span class="line"><span class="string">user = mysql</span></span><br><span class="line"><span class="string">tmpdir = /tmp</span></span><br><span class="line"><span class="string">symbolic-links=0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[mysqld_safe]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">log-error = /usr/local/mysql/data/error.log</span></span><br><span class="line"><span class="string">pid-file = /usr/local/mysql/data/mysql.pid</span></span><br><span class="line"><span class="string">#!includedir /etc/my.cnf.d</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#8.启动mysql</span></span><br><span class="line"><span class="string">service mysqld start</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#如启动失败，删除 /usr/local/mysql-5.7.22/data下所有文件，重新执行./bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data，再启动</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#9.进入mysql修改初始密码，修改远程连接的用户权限问题</span></span><br><span class="line"><span class="string">mysql -uroot -p</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ALTER USER &#x27;</span>root<span class="string">&#x27;@&#x27;</span>localhost<span class="string">&#x27; IDENTIFIED BY &#x27;</span>root<span class="string">&#x27;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">use mysql;</span></span><br><span class="line"><span class="string">UPDATE user SET host=&#x27;</span>%<span class="string">&#x27; WHERE user=&#x27;</span>root<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">flush privileges;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#开机自启动</span></span><br><span class="line"><span class="string">chkconfig --add mysqld</span></span><br><span class="line"><span class="string">chkconfig mysqld on</span></span><br><span class="line"><span class="string">chkconfig --list</span></span><br><span class="line"><span class="string">  mysqld          0:关    1:关    2:开    3:开    4:开    5:开    6:关</span></span><br></pre></td></tr></table></figure>

<ol>
<li>配置mysql</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动mysql 服务</span></span><br><span class="line">systemctl start mysqld</span><br><span class="line"><span class="comment">#设置开机启动</span></span><br><span class="line">systemctl <span class="built_in">enable</span> mysqld</span><br><span class="line"><span class="comment"># 重载所有修改过的配置文件</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="comment"># 关闭密码验证</span></span><br><span class="line">vim /etc/my.cnf</span><br><span class="line"><span class="comment"># mysqld选项下加入</span></span><br><span class="line">validate_password=OFF</span><br><span class="line"><span class="comment">#重启mysql服务</span></span><br><span class="line">systemctl restart mysqld</span><br><span class="line"><span class="comment"># 得到临时密码</span></span><br><span class="line">grep <span class="string">&#x27;temporary password&#x27;</span> /var/log/mysqld.log</span><br><span class="line"><span class="comment">#登录mysql</span></span><br><span class="line">mysql -uroot -p</span><br><span class="line"><span class="comment"># 开发环境 修改密码为root</span></span><br><span class="line">ALTER USER <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="string">&#x27;root&#x27;</span>;</span><br><span class="line"><span class="comment">#修改root账号登录限制</span></span><br><span class="line">use mysql;</span><br><span class="line">UPDATE user SET host=<span class="string">&#x27;%&#x27;</span> WHERE user=<span class="string">&#x27;root&#x27;</span>;</span><br><span class="line">flush privileges; </span><br><span class="line"><span class="comment">#创建metastore元数据库</span></span><br><span class="line">create database metastore</span><br><span class="line">DEFAULT CHARACTER SET utf8</span><br><span class="line">DEFAULT COLLATE utf8_general_ci;</span><br></pre></td></tr></table></figure>

<h2 id="安装HIVE"><a href="#安装HIVE" class="headerlink" title="安装HIVE"></a>安装HIVE</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解压apache-hive-3.1.2-bin.tar.gz到/opt/module/目录下面</span></span><br><span class="line">   tar -zxvf apache-hive-3.1.2-bin.tar.gz -C /opt/module/</span><br><span class="line"><span class="comment">#修改`/etc/profile.d/my_env.sh`，添加环境变量</span></span><br><span class="line">   vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="comment">#添加内容</span></span><br><span class="line"><span class="comment">#HIVE_HOME</span></span><br><span class="line">   <span class="built_in">export</span> HIVE_HOME=/opt/module/apache-hive-3.1.2-bin</span><br><span class="line">   <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br><span class="line"><span class="comment">#刷新环境变量</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>

<ol>
<li>hive基础配置</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#解决日志Jar包冲突</span></span><br><span class="line"><span class="built_in">mv</span> <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.10.0.jar <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.10.0.bak</span><br><span class="line"></span><br><span class="line"><span class="comment">#拷贝mysql-connector.jar到lib库</span></span><br><span class="line"><span class="built_in">cp</span> /opt/software/mysql-connector-java-5.1.27-bin.jar <span class="variable">$HIVE_HOME</span>/lib</span><br></pre></td></tr></table></figure>

<ol>
<li><p>配置hive-site.xml</p>
<p>挑转到<code>/opt/module/apache-hive-3.1.2-bin/conf/</code>目录新建文件 hive-site.xml</p>
</li>
</ol>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;utf-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">  <span class="comment">&lt;!--jdbc连接的URL--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop100:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--jdbc连接的Driver--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--jdbc连接的username--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--jdbc连接的password--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--Hive元数据存储版本的验证--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--元数据存储授权--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--Hive默认在HDFS的工作目录--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.enable.doAs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--取消本地模式改为false--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.mode.local.auto<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapred.map.child.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>-Xmx2048m<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol>
<li>初始化Hive元数据库</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool -initSchema -dbType mysql -verbose</span><br></pre></td></tr></table></figure>

<h2 id="优化mapreduce"><a href="#优化mapreduce" class="headerlink" title="优化mapreduce"></a>优化mapreduce</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim <span class="variable">$HADOOP_HOME</span>/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>增加配置</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1536<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>-Xmx1024M<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3072<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.java.opts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>-Xmx2560M<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="配置beeline"><a href="#配置beeline" class="headerlink" title="配置beeline"></a>配置beeline</h2><p>配置core-site.xml 使其任意节点都可以访问hadoop</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ol>
<li>启动 hiveserver2</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#前端启动</span></span><br><span class="line">hiveserver2</span><br><span class="line"><span class="comment">#后台启动</span></span><br><span class="line"><span class="built_in">nohup</span> hiveserver2 &amp;</span><br></pre></td></tr></table></figure>

<ol>
<li>登录命令</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">beeline -u jdbc:hive2://localhost:10000 -n root -p 123456 [密码随意]</span><br><span class="line">beeline -u jdbc:hive2://localhost:10000 -n root -p 123456  -e <span class="string">&#x27;show tables;&#x27;</span> </span><br></pre></td></tr></table></figure>

<ol>
<li>dbeaver登录</li>
</ol>
<ul>
<li>获取文件 hadoop-common-3.1.3.jar</li>
<li>获取文件 hive-jdbc-3.1.2-standalone.jar</li>
<li>添加hive数据库链接</li>
</ul>
<h1 id="hive-数据操作语句"><a href="#hive-数据操作语句" class="headerlink" title="hive 数据操作语句"></a><strong>hive</strong> 数据操作语句</h1><h2 id="元数据查看语句"><a href="#元数据查看语句" class="headerlink" title="元数据查看语句"></a>元数据查看语句</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--查看数据库</span></span><br><span class="line"><span class="keyword">show</span>  database db_hive</span><br><span class="line"><span class="comment">--过滤查看数据库</span></span><br><span class="line"><span class="keyword">show</span> databases <span class="keyword">like</span> <span class="string">&#x27;db_hive*&#x27;</span>;</span><br><span class="line"><span class="comment">--查看详情</span></span><br><span class="line"><span class="keyword">desc</span> database db_hive</span><br><span class="line"><span class="keyword">desc</span> database extended db_hive;</span><br><span class="line"><span class="comment">--查看表</span></span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="comment">--查看表列详情</span></span><br><span class="line"><span class="keyword">desc</span> dept;</span><br><span class="line"><span class="comment">--查看表所有详细信息</span></span><br><span class="line"><span class="keyword">desc</span> extended emp;</span><br><span class="line"><span class="keyword">show</span> formatted emp;</span><br><span class="line"><span class="comment">--查看分区信息</span></span><br><span class="line"><span class="keyword">show</span> partitions emp;</span><br></pre></td></tr></table></figure>

<h2 id="建库操作"><a href="#建库操作" class="headerlink" title="建库操作"></a>建库操作</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建数据库</span></span><br><span class="line"><span class="keyword">CREATE</span> DATABASE [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] database_name</span><br><span class="line">[COMMENT database_comment]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="建表操作"><a href="#建表操作" class="headerlink" title="建表操作"></a>建表操作</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name <span class="comment">--内部表</span></span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)] <span class="comment">--数据类型 </span></span><br><span class="line">[COMMENT table_comment] </span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)] <span class="comment">--分区表</span></span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) </span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS] <span class="comment">--分桶表</span></span><br><span class="line">[<span class="type">ROW</span> FORMAT DELIMITED <span class="comment">--数据格式</span></span><br><span class="line">[FIELDS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] <span class="comment">--列分隔</span></span><br><span class="line">[COLLECTION ITEMS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] <span class="comment">--复合数据item分隔</span></span><br><span class="line">[MAP KEYS TERMINATED <span class="keyword">BY</span> <span class="type">char</span>] <span class="comment">--复合数据key分隔</span></span><br><span class="line">[LINES TERMINATED <span class="keyword">BY</span> <span class="type">char</span>]] <span class="comment">--行分隔</span></span><br><span class="line">[STORED <span class="keyword">AS</span> file_format] <span class="comment">--压缩格式</span></span><br><span class="line">[LOCATION hdfs_path] <span class="comment">--表数据文件存储路径</span></span><br><span class="line">[TBLPROPERTIES (property_name<span class="operator">=</span>property_value, ...)] <span class="comment">--内外部表转换</span></span><br><span class="line">[<span class="keyword">AS</span> select_statement]</span><br></pre></td></tr></table></figure>

<h2 id="上传数据"><a href="#上传数据" class="headerlink" title="上传数据"></a>上传数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--load</span></span><br><span class="line">load data [<span class="keyword">local</span>] inpath <span class="string">&#x27;数据的path&#x27;</span> [overwrite] <span class="keyword">into</span> <span class="keyword">table</span> student [<span class="keyword">partition</span> (partcol1<span class="operator">=</span>val1,…)];</span><br><span class="line"></span><br><span class="line"><span class="comment">--上传hdfs</span></span><br><span class="line">dfs <span class="operator">-</span>put <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hive<span class="operator">/</span>datas<span class="operator">/</span>student.txt <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>atguigu<span class="operator">/</span>hive;</span><br><span class="line"></span><br><span class="line"><span class="comment">--插入数据</span></span><br><span class="line"><span class="keyword">insert into</span> <span class="keyword">table</span>  student_par <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">&#x27;wangwu&#x27;</span>),(<span class="number">2</span>,<span class="string">&#x27;zhaoliu&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">--覆盖插入并且使用结果集进行插入</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> student_par <span class="keyword">select</span> id, name <span class="keyword">from</span> student ;</span><br></pre></td></tr></table></figure>

<h2 id="下载数据"><a href="#下载数据" class="headerlink" title="下载数据"></a>下载数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;数据的path&#x27;</span></span><br><span class="line"><span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> dql_command;</span><br><span class="line"></span><br><span class="line"><span class="comment">--hadoop 导出</span></span><br><span class="line">dfs <span class="operator">-</span><span class="keyword">get</span> <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>student<span class="operator">/</span>student.txt</span><br><span class="line"><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>datas<span class="operator">/</span>export<span class="operator">/</span>student3.txt;</span><br><span class="line"></span><br><span class="line"><span class="comment">--hive shell导出</span></span><br><span class="line">bin<span class="operator">/</span>hive <span class="operator">-</span>e <span class="string">&#x27;select * from default.student;&#x27;</span> <span class="operator">&gt;</span></span><br><span class="line"><span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>hive<span class="operator">/</span>datas<span class="operator">/</span>export<span class="operator">/</span>student4.txt;</span><br><span class="line"></span><br><span class="line"><span class="comment">--export导出</span></span><br><span class="line"> export <span class="keyword">table</span> default.student <span class="keyword">to</span></span><br><span class="line"> <span class="string">&#x27;/user/hive/warehouse/export/student&#x27;</span>; </span><br></pre></td></tr></table></figure>

<h2 id="select语句"><a href="#select语句" class="headerlink" title="select语句"></a>select语句</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [<span class="keyword">ALL</span> <span class="operator">|</span> <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...</span><br><span class="line">  <span class="keyword">FROM</span> table_reference</span><br><span class="line">  [<span class="keyword">WHERE</span> where_condition]</span><br><span class="line">  [<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">  [<span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">  [CLUSTER <span class="keyword">BY</span> col_list</span><br><span class="line">    <span class="operator">|</span> [DISTRIBUTE <span class="keyword">BY</span> col_list] [SORT <span class="keyword">BY</span> col_list]</span><br><span class="line">  ]</span><br><span class="line"> [LIMIT number]</span><br></pre></td></tr></table></figure>



<h1 id="Hive复合数据类型"><a href="#Hive复合数据类型" class="headerlink" title="Hive复合数据类型"></a>Hive复合数据类型</h1><ul>
<li><p><strong>数组array</strong>: 			<strong>array&lt;value数据类型&gt;</strong></p>
<ol>
<li>相同数据类型</li>
<li>有序的排列</li>
<li>下标为数字</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--查询复合数据</span></span><br><span class="line"><span class="keyword">select</span>  a_score[<span class="number">0</span>] <span class="keyword">from</span> student2</span><br><span class="line"></span><br><span class="line"><span class="comment">--构造复合数据-array</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">array</span>(值,值) <span class="keyword">from</span> student</span><br></pre></td></tr></table></figure>


</li>
<li><p><strong>集合struct</strong>:                         <strong>struct&lt;key值:value数据类型,key值:value数据类型&gt;</strong></p>
<ol>
<li><p>预定义个数</p>
</li>
<li><p>预定义顺序</p>
</li>
<li><p>key预定义</p>
</li>
<li><p>数据类型可不同</p>
</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--查询复合数据</span></span><br><span class="line"><span class="keyword">select</span>  s_score.chinese <span class="keyword">from</span> student2</span><br><span class="line"></span><br><span class="line"><span class="comment">--构造复合数据</span></span><br><span class="line"><span class="keyword">select</span> named_struct(key,<span class="keyword">value</span>,key,<span class="keyword">value</span>)</span><br><span class="line"><span class="keyword">from</span> student</span><br></pre></td></tr></table></figure>


</li>
<li><p><strong>字典map</strong>:                              <strong>map&lt;key数据类型,value数据类型&gt;</strong></p>
<ol>
<li><p>标准字典类型</p>
</li>
<li><p>key自定义</p>
</li>
<li><p>数据类型可不同</p>
</li>
<li><p>个数不限</p>
</li>
</ol>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--查询复合数据</span></span><br><span class="line"><span class="keyword">select</span>  m_score[<span class="string">&#x27;语文&#x27;</span>] <span class="keyword">from</span> student2</span><br><span class="line"></span><br><span class="line"><span class="comment">--构造复合数据</span></span><br><span class="line"><span class="keyword">select</span> map(key,<span class="keyword">value</span>,key,<span class="keyword">value</span>)</span><br><span class="line"><span class="keyword">from</span> student</span><br></pre></td></tr></table></figure>
<h2 id="hive-内置函数"><a href="#hive-内置函数" class="headerlink" title="hive 内置函数"></a><strong>hive</strong> 内置函数</h2>  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查看系统自带的函数</span></span><br><span class="line"><span class="keyword">show</span> functions;</span><br><span class="line"><span class="comment">-- 显示自带的函数的用法</span></span><br><span class="line"><span class="keyword">desc</span> <span class="keyword">function</span> upper;</span><br><span class="line"><span class="comment">-- 详细显示自带的函数的用法</span></span><br><span class="line"><span class="keyword">desc</span> <span class="keyword">function</span> extended upper;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="python连接hive"><a href="#python连接hive" class="headerlink" title="python连接hive"></a>python连接hive</h1><h2 id="linux环境安装python"><a href="#linux环境安装python" class="headerlink" title="linux环境安装python"></a>linux环境安装python</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载安装包 或上传安装包</span></span><br><span class="line">wget https://www.python.org/ftp/python/3.9.0/Python-3.9.0.tgz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget https://www.python.org/ftp/python/3.9.9/Python-3.9.9.tgz</span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -zxvf Python-3.9.10.tgz -C /opt/module/</span><br><span class="line"><span class="comment"># 支撑包</span></span><br><span class="line">yum install openssl-devel libffi-devel bzip2-devel gcc gcc-c++ wget -y</span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line">./configure --enable-optimizations</span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">make altinstall</span><br></pre></td></tr></table></figure>

<h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line">vim  /etc/profile.d/my_env.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PATH=<span class="variable">$PATH</span>:/opt/python39/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#生效 环境变量</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#或者进行软连接 配置 </span></span><br><span class="line"><span class="built_in">cp</span> libpython3.9.a  /usr/lib64/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">ln</span> -s /root/software/python3.9/Python-3.9.10/python /usr/bin/python3</span><br><span class="line"><span class="built_in">ln</span> -s /opt/module/Python-3.9.10/python /usr/bin/python3</span><br></pre></td></tr></table></figure>

<h2 id="安装pyhive库"><a href="#安装pyhive库" class="headerlink" title="安装pyhive库"></a>安装pyhive库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pip3 install  -i https://mirrors.aliyun.com/pypi/simple/  thrift</span><br><span class="line">pip3 install  -i https://mirrors.aliyun.com/pypi/simple/  thrift-sasl</span><br><span class="line">pip3 install   -i https://mirrors.aliyun.com/pypi/simple/ PyHive</span><br><span class="line">pip3 install   -i https://mirrors.aliyun.com/pypi/simple/ PyM</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyhive <span class="keyword">import</span> hive</span><br><span class="line">conn=hive.connect(host=<span class="string">&#x27;localhost&#x27;</span>,port=<span class="number">10000</span>,username=<span class="string">&#x27;root&#x27;</span>,database=<span class="string">&#x27;db_hive&#x27;</span>)</span><br><span class="line">cursor=conn.cursor()</span><br><span class="line">sql=<span class="string">&#x27;show tables&#x27;</span></span><br><span class="line">cursor.execute(sql)</span><br><span class="line"><span class="built_in">print</span>(cursor.fetchall())</span><br></pre></td></tr></table></figure>

<h1 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h1><ul>
<li><p>分区是将一个表或索引物理地分解为多个更小、更可管理的部分。</p>
</li>
<li><p>分区对应用透明，即对访问数据库的应用而言，逻辑上讲只有一个表或一个索引（相当于应用“看到”的只是一个表或索引），但在物理上这个表或索引可能由数十个物理分区组成。</p>
</li>
</ul>
<h2 id="分区应用场景"><a href="#分区应用场景" class="headerlink" title="分区应用场景"></a>分区应用场景</h2><p><img src="/2025/06/24/Hadoop/image-20250701152059542.png" alt="image-20250701152059542"></p>
<h2 id="oracle分区表种类"><a href="#oracle分区表种类" class="headerlink" title="oracle分区表种类"></a><strong>oracle</strong>分区表种类</h2><ol>
<li><strong>范围分区</strong>(range)</li>
<li><strong>列表分区</strong>(list)</li>
<li><strong>散列分区</strong>(hash)</li>
<li><strong>组合组合分区</strong>(subpartition)</li>
</ol>
<h2 id="oracle分区-范围分区"><a href="#oracle分区-范围分区" class="headerlink" title="oracle分区-范围分区"></a><em>oracle</em>分区-范围分区</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> ORDER_ACTIVITIES   </span><br><span class="line">(  ORDER_ID      NUMBER(<span class="number">7</span>) <span class="keyword">NOT NULL</span>,   </span><br><span class="line">    ORDER_DATE    <span class="type">DATE</span>,   </span><br><span class="line">    TOTAL_AMOUNT NUMBER,   </span><br><span class="line">    CUSTOTMER_ID NUMBER(<span class="number">7</span>),   </span><br><span class="line">    PAID   <span class="type">CHAR</span>(<span class="number">1</span>)   </span><br><span class="line">)   <span class="comment">-- 建表语句不变</span></span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span> (ORDER_DATE) <span class="comment">-- 范围分区创建 语句 关键字 range(列名)</span></span><br><span class="line">(  </span><br><span class="line">  <span class="keyword">PARTITION</span> ORD_ACT_PART01 <span class="keyword">VALUES</span> LESS THAN (TO_DATE(<span class="string">&#x27;01- MAY -2003&#x27;</span>,<span class="string">&#x27;DD-MON-YYYY&#x27;</span>)) TABLESPACE ORD_TS01,  </span><br><span class="line">    <span class="comment">-- 分区名 （时间值）表空间</span></span><br><span class="line">  <span class="keyword">PARTITION</span> ORD_ACT_PART02 <span class="keyword">VALUES</span> LESS THAN (TO_DATE(<span class="string">&#x27;01-JUN-2003&#x27;</span>,<span class="string">&#x27;DD-MON-YYYY&#x27;</span>)) TABLESPACE ORD_TS02,  </span><br><span class="line">  <span class="keyword">PARTITION</span> ORD_ACT_PART02 <span class="keyword">VALUES</span> LESS THAN (MAXVALUE) TABLESPACE ORD_TS03   <span class="comment">--使用maxvalue 将其他不符合上述范围的值放入其中</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>



<h2 id="oracle分区-列表分区"><a href="#oracle分区-列表分区" class="headerlink" title="oracle分区-列表分区"></a>oracle分区-列表分区</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> ORDER_ACTIVITIES  </span><br><span class="line">(  PROBLEM_ID   NUMBER(<span class="number">7</span>) <span class="keyword">NOT NULL</span> <span class="keyword">PRIMARY KEY</span>,   </span><br><span class="line">    CUSTOMER_ID  NUMBER(<span class="number">7</span>) <span class="keyword">NOT NULL</span>,     </span><br><span class="line">    STATUS       VARCHAR2(<span class="number">20</span>))   </span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> LIST (STATUS)    <span class="comment">-- 范围分区创建 语句 关键字 LIST(列名)</span></span><br><span class="line">(    <span class="keyword">PARTITION</span> PROB_ACTIVE   <span class="keyword">VALUES</span> (<span class="string">&#x27;ACTIVE&#x27;</span>) TABLESPACE PROB_TS01,  <span class="comment">-- </span></span><br><span class="line">      <span class="keyword">PARTITION</span> PROB_INACTIVE <span class="keyword">VALUES</span> (<span class="string">&#x27;INACTIVE&#x27;</span>,<span class="string">&#x27;unknow&#x27;</span>) TABLESPACE PROB_TS02  </span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<h2 id="oracle分区-散列分区"><a href="#oracle分区-散列分区" class="headerlink" title="oracle分区-散列分区"></a>oracle分区-散列分区</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> HASH_TABLE   </span><br><span class="line">( COL NUMBER(<span class="number">8</span>),   </span><br><span class="line">  INF VARCHAR2(<span class="number">100</span>)   </span><br><span class="line">)   </span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> HASH (COL)    <span class="comment">-- 范围分区创建 语句 关键字 HASH(列名) </span></span><br><span class="line">(   </span><br><span class="line">  <span class="keyword">PARTITION</span> PART01 TABLESPACE HASH_TS01,   </span><br><span class="line">  <span class="keyword">PARTITION</span> PART02 TABLESPACE HASH_TS02,   </span><br><span class="line">  <span class="keyword">PARTITION</span> PART03 TABLESPACE HASH_TS03   </span><br><span class="line">) </span><br></pre></td></tr></table></figure>

<h2 id="oracle分区-组合分区"><a href="#oracle分区-组合分区" class="headerlink" title="oracle分区-组合分区"></a><strong>oracle</strong>分区-组合分区</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE TABLE</span> SALES   </span><br><span class="line">(  </span><br><span class="line">PRODUCT_ID VARCHAR2(<span class="number">5</span>),  </span><br><span class="line">SALES_DATE <span class="type">DATE</span>,  </span><br><span class="line">SALES_COST NUMBER(<span class="number">10</span>),  </span><br><span class="line">STATUS VARCHAR2(<span class="number">20</span>)  </span><br><span class="line">)  </span><br><span class="line"><span class="keyword">PARTITION</span> <span class="keyword">BY</span> <span class="keyword">RANGE</span>(SALES_DATE) SUBPARTITION <span class="keyword">BY</span> LIST (STATUS)  </span><br><span class="line">(  </span><br><span class="line">   <span class="keyword">PARTITION</span> P1 <span class="keyword">VALUES</span> LESS THAN(TO_DATE(<span class="string">&#x27;2003-01-01&#x27;</span>,<span class="string">&#x27;YYYY-MM-DD&#x27;</span>))TABLESPACE rptfact2009   </span><br><span class="line">  (   </span><br><span class="line">      SUBPARTITION P1SUB1 <span class="keyword">VALUES</span> (<span class="string">&#x27;ACTIVE&#x27;</span>) TABLESPACE rptfact2009,   </span><br><span class="line">      SUBPARTITION P1SUB2 <span class="keyword">VALUES</span> (<span class="string">&#x27;INACTIVE&#x27;</span>) TABLESPACE rptfact2009   </span><br><span class="line">  ),   </span><br><span class="line">   <span class="keyword">PARTITION</span> P2 <span class="keyword">VALUES</span> LESS THAN (TO_DATE(<span class="string">&#x27;2003-03-01&#x27;</span>,<span class="string">&#x27;YYYY-MM-DD&#x27;</span>)) TABLESPACE rptfact2009   </span><br><span class="line">  (   </span><br><span class="line">      SUBPARTITION P2SUB1 <span class="keyword">VALUES</span> (<span class="string">&#x27;ACTIVE&#x27;</span>) TABLESPACE rptfact2009,   </span><br><span class="line">      SUBPARTITION P2SUB2 <span class="keyword">VALUES</span> (<span class="string">&#x27;INACTIVE&#x27;</span>) TABLESPACE rptfact2009   </span><br><span class="line">  )   </span><br><span class="line">)  </span><br></pre></td></tr></table></figure>

<h2 id="oracle分区-分区表操作"><a href="#oracle分区-分区表操作" class="headerlink" title="oracle分区-分区表操作"></a><em>oracle</em>分区-分区表操作</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 添加分区</span></span><br><span class="line"><span class="keyword">ALTER TABLE</span> SALES <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> P3 <span class="keyword">VALUES</span> LESS THAN(TO_DATE(<span class="string">&#x27;2003-06-01&#x27;</span>,<span class="string">&#x27;YYYY-MM-DD&#x27;</span>));  </span><br><span class="line"><span class="comment">--注意：以上添加的分区界限应该高于最后一个 分区界限。</span></span><br><span class="line"><span class="comment">-- 添加了一个P3SUB1子分区</span></span><br><span class="line"><span class="keyword">ALTER TABLE</span> SALES MODIFY <span class="keyword">PARTITION</span> P3 <span class="keyword">ADD</span> SUBPARTITION P3SUB1 <span class="keyword">VALUES</span>(<span class="string">&#x27;COMPLETE&#x27;</span>); </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除分区</span></span><br><span class="line"><span class="keyword">ALTER TABLE</span> SALES <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> P3;  </span><br><span class="line"><span class="keyword">ALTER TABLE</span> SALES <span class="keyword">DROP</span> SUBPARTITION P4SUB1;</span><br><span class="line"><span class="comment">-- 注意：如果删除的分区是表中唯一的分区，那么此分区将不能被删除，要想删除此分区，必须删除表。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 交换分区</span></span><br><span class="line"><span class="keyword">ALTER TABLE</span> table_name EXCHANGE <span class="keyword">PARTITION</span> partition_name <span class="keyword">WITH</span> <span class="keyword">TABLE</span> nonpartition_name;</span><br><span class="line"></span><br><span class="line"><span class="comment">--将一个分区(子分区)和非分区表进行数据交换，oracle交换的方法是其实是对逻辑存储段进行交换。使用INCLUDEING INDEXES子句可以同步将本地索引也进行交换，使用WITH VALIDATATION子句还可以实现行数据的验证。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--交换分区时如果不带UPDATE INDEXES子句，则全局索引或全局索引基于的分区将变为不可用。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="hive分区-创建分区表"><a href="#hive分区-创建分区表" class="headerlink" title="hive分区-创建分区表"></a>hive分区-创建分区表</h2><p><strong>在 Hadoop 中，Hive 分区表通常以特定的目录结构来存储。</strong></p>
<p><strong>每个分区对应一个独立的目录，目录名通常包含分区列的值。数据文件会存储在相应的分区目录下。</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建分区表</span></span><br><span class="line"><span class="keyword">create table</span> dept_partition(</span><br><span class="line">deptno <span class="type">int</span>, dname string, loc string</span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (<span class="keyword">day</span> string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="hive分区-分区表操作"><a href="#hive分区-分区表操作" class="headerlink" title="hive分区-分区表操作"></a>hive分区-分区表操作</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 分区表数据导入</span></span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/hive/datas/dept_20200401.log&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_partition <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200401&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">--select分区表插入数据</span></span><br><span class="line"><span class="keyword">insert into</span> <span class="keyword">table</span> log_list_6 <span class="keyword">partition</span>(dat<span class="operator">=</span><span class="string">&#x27;20221231&#x27;</span>) <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_list_tmp</span><br><span class="line"><span class="comment">--多表分区插入 </span></span><br><span class="line"><span class="keyword">from</span> student </span><br><span class="line">  <span class="keyword">insert</span> overwrite <span class="keyword">table</span> student <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201707&#x27;</span>)<span class="keyword">select</span> id, name <span class="keyword">where</span> <span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201707&#x27;</span></span><br><span class="line">  <span class="keyword">insert</span> overwrite <span class="keyword">table</span> student <span class="keyword">partition</span>(<span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201706&#x27;</span>)<span class="keyword">select</span> id, name <span class="keyword">where</span> <span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;201706&#x27;</span>;</span><br><span class="line"><span class="comment">-- 查看分区</span></span><br><span class="line"><span class="keyword">show</span> partitions tab_name;</span><br><span class="line"></span><br><span class="line"><span class="comment">--添加分区</span></span><br><span class="line"><span class="keyword">alter table</span> dept_partition <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200404&#x27;</span>) ;</span><br><span class="line"><span class="comment">--添加多分区</span></span><br><span class="line"><span class="keyword">alter table</span> dept_partition <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200405&#x27;</span>) <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200406&#x27;</span>);</span><br><span class="line"><span class="comment">--删除分区</span></span><br><span class="line"><span class="keyword">alter table</span> dept_partition <span class="keyword">drop</span> <span class="keyword">partition</span> (<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200406&#x27;</span>);</span><br><span class="line"><span class="comment">--查看分区表信息</span></span><br><span class="line"><span class="keyword">show</span> partitions dept_partition;</span><br><span class="line"><span class="comment">--查看分区表结构</span></span><br><span class="line"><span class="keyword">desc</span> formatted dept_partition;</span><br><span class="line"><span class="comment">--修改分区表</span></span><br><span class="line"><span class="keyword">ALTER TABLE</span> table_name <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>) <span class="keyword">SET</span> LOCATION &quot;new location&quot;;</span><br><span class="line"><span class="keyword">ALTER TABLE</span> table_name <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;2008-08-08&#x27;</span>) RENAME <span class="keyword">TO</span> <span class="keyword">PARTITION</span> (dt<span class="operator">=</span><span class="string">&#x27;20080808&#x27;</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="超市分区表示例"><a href="#超市分区表示例" class="headerlink" title="超市分区表示例"></a>超市分区表示例</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create table</span> supermarket_p (</span><br><span class="line">id string, <span class="comment">-- 行 ID  </span></span><br><span class="line">ord_id string comment <span class="string">&#x27;订单 ID&#x27;</span>,  </span><br><span class="line">ord_date string comment <span class="string">&#x27;订单日期&#x27;</span>, </span><br><span class="line">exch_date string comment <span class="string">&#x27;发货日期&#x27;</span>,</span><br><span class="line">exch_type string comment <span class="string">&#x27;邮寄方式&#x27;</span>,</span><br><span class="line">cust_id string comment <span class="string">&#x27;客户 ID &#x27;</span>,</span><br><span class="line">cust_name string comment <span class="string">&#x27;客户名称&#x27;</span>,</span><br><span class="line">d_type string comment <span class="string">&#x27;细分&#x27;</span>,</span><br><span class="line">city string comment <span class="string">&#x27;城市&#x27;</span>, </span><br><span class="line">prov string comment <span class="string">&#x27;省/自治区&#x27;</span>,  </span><br><span class="line">country string comment<span class="string">&#x27;国家&#x27;</span>,</span><br><span class="line">area string comment <span class="string">&#x27;地区&#x27;</span>, </span><br><span class="line">pro_id string comment <span class="string">&#x27;产品 ID&#x27;</span>,  </span><br><span class="line">type1 string comment <span class="string">&#x27;类别&#x27;</span>,</span><br><span class="line">type2 string comment <span class="string">&#x27;子类别&#x27;</span>, </span><br><span class="line">pro_name string comment <span class="string">&#x27;产品名称&#x27;</span>,</span><br><span class="line">sales <span class="type">float</span> comment <span class="string">&#x27;销售额&#x27;</span>,  </span><br><span class="line">count1 <span class="type">int</span> comment <span class="string">&#x27;数量  &#x27;</span>,</span><br><span class="line">discount <span class="type">float</span> comment <span class="string">&#x27;折扣  &#x27;</span>,</span><br><span class="line">profit <span class="type">float</span> comment <span class="string">&#x27;利润&#x27;</span></span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (c_type1 string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="动态分区配置"><a href="#动态分区配置" class="headerlink" title="动态分区配置"></a>动态分区配置</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">--开启动态分区(默认开启)</span><br><span class="line"><span class="built_in">set</span> hive.exec.dynamic.partition=<span class="literal">true</span></span><br><span class="line">--指定非严格模式 nonstrict模式表示允许所有的分区字段都可以使用动态分区</span><br><span class="line"><span class="built_in">set</span> hive.exec.dynamic.partition.mode=nonstrict</span><br><span class="line">--在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000</span><br><span class="line"><span class="built_in">set</span> hive.exec.max.dynamic.partitions=1000</span><br><span class="line">--在每个执行MR的节点上，最大可以创建多少个动态分区(分区字段有多少种设多少个)</span><br><span class="line"><span class="built_in">set</span> hive.exec.max.dynamic.partitions.pernode=100</span><br><span class="line">--整个MR Job中，最大可以创建多少个HDFS文件。默认100000</span><br><span class="line"><span class="built_in">set</span> hive.exec.max.created.files=100000</span><br><span class="line">--当有空分区生成时，是否抛出异常</span><br><span class="line"><span class="built_in">set</span> hive.error.on.empty.partition=<span class="literal">false</span></span><br><span class="line">--打开正则查询模式`(dt|hr)?+.+`</span><br><span class="line"><span class="built_in">set</span> hive.support.quoted.identifiers=none</span><br></pre></td></tr></table></figure>

<h1 id="分桶表"><a href="#分桶表" class="headerlink" title="分桶表"></a>分桶表</h1><ul>
<li><p>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围划分。</p>
</li>
<li><p>分桶是将数据集分解成更容易管理的若干部分的另一个技术。</p>
</li>
<li><p>分区<strong>针对的是数据的存储路径</strong>；分桶<strong>针对的是数据文件</strong>。</p>
</li>
</ul>
<h2 id="分桶表注意事项"><a href="#分桶表注意事项" class="headerlink" title="分桶表注意事项"></a><strong>分桶表注意事项</strong></h2><ul>
<li><p><strong>分桶策略</strong></p>
</li>
<li><p><strong>Hive的分桶采用对分桶字段的值进行哈希，然后除以桶的个数求余的方 式决定该条记录存放在哪个桶当中</strong></p>
<p>&#x3D;&#x3D;reduce的个数设置为-1,让Job自行决定需要用多少个reduce或者将reduce的个数设置为大于等于分桶表的桶数&#x3D;&#x3D;</p>
<p>&#x3D;&#x3D;<strong>从hdfs中load数据到分桶表中，避免本地文件找不到问题</strong>&#x3D;&#x3D;</p>
<p>&#x3D;&#x3D;<strong>不要使用本地模式</strong>&#x3D;&#x3D;</p>
</li>
</ul>
<h2 id="hive分桶表-创建分桶表"><a href="#hive分桶表-创建分桶表" class="headerlink" title="hive分桶表-创建分桶表"></a>hive分桶表-创建分桶表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--创建4个分桶的分桶表</span></span><br><span class="line"><span class="keyword">create table</span> stu_bucket(id <span class="type">int</span>, name string)</span><br><span class="line">clustered <span class="keyword">by</span>(id) </span><br><span class="line"><span class="keyword">into</span> <span class="number">4</span> buckets</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--设置mapreduce数量(二选一)</span></span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">3</span></span><br><span class="line"> <span class="keyword">set</span> mapred.reduce.tasks<span class="operator">=</span><span class="number">3</span></span><br><span class="line"><span class="comment">--向分桶表导入数据</span></span><br><span class="line">load data inpath   <span class="string">&#x27;/student.txt&#x27;</span> </span><br><span class="line"><span class="keyword">into</span> <span class="keyword">table</span> stu_bucket;</span><br></pre></td></tr></table></figure>

<h2 id="hive排序关键字"><a href="#hive排序关键字" class="headerlink" title="hive排序关键字"></a>hive排序关键字</h2><p><img src="/2025/06/24/Hadoop/image-20250701153814791.png" alt="image-20250701153814791"></p>
<hr>
<p>##<strong>hive****排序语句</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--使用order by 排序</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student2 <span class="keyword">order</span> <span class="keyword">by</span> id</span><br><span class="line"><span class="comment">--使用sort by 排序</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student2 sort <span class="keyword">by</span> class_name <span class="keyword">desc</span></span><br><span class="line"><span class="comment">--使用distribute by 分组</span></span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">15</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student2 distribute <span class="keyword">by</span> class_name sort <span class="keyword">by</span> id <span class="keyword">desc</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite  <span class="keyword">local</span> directory <span class="string">&#x27;/root/student2/&#x27;</span></span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student2_b </span><br><span class="line">distribute <span class="keyword">by</span> sex </span><br><span class="line">sort <span class="keyword">by</span> chinese <span class="keyword">desc</span></span><br><span class="line"><span class="comment">--使用cluster by 分组并排序</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student2 cluster <span class="keyword">by</span> class_name</span><br></pre></td></tr></table></figure>



<h2 id="使用awk-清洗-log"><a href="#使用awk-清洗-log" class="headerlink" title="使用awk 清洗 log"></a>使用awk 清洗 log</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> 2021-05-20.<span class="built_in">log</span> | awk -F <span class="string">&quot;\&quot;-\&quot;&quot;</span> <span class="string">&#x27;&#123;split($1, arr, &quot; &quot;);\</span></span><br><span class="line"><span class="string">split(substr(arr[4],2),dd,&quot;:&quot;);\</span></span><br><span class="line"><span class="string">split(dd[1],ee,&quot;/&quot;);\</span></span><br><span class="line"><span class="string">print arr[1]&quot;\t&quot;ee[1]&quot;-</span></span><br><span class="line"><span class="string">&quot;ee[2]&quot;-&quot;ee[3]&quot; &quot;dd[2]&quot;:&quot;dd[3]&quot;:&quot;dd[4]&quot;\t&quot;arr[7]&quot;\t&quot;$2&#125;&#x27;</span> | \</span><br><span class="line">awk -F <span class="string">&quot;\t&quot;</span> <span class="string">&#x27;&#123;&quot;date -d \&quot;&quot;$2&quot;\&quot; +%Y%m%d%H%M%S&quot; | getline d;print</span></span><br><span class="line"><span class="string">$1&quot;\t&quot;d&quot;\t&quot;$3&quot;\t&quot;$4 &#125;&#x27;</span> | \</span><br><span class="line">awk -F <span class="string">&quot;\t&quot;</span> <span class="string">&#x27;&#123;print $1&quot;\t&quot;$2&quot;\t&quot;$3&quot;\t&quot;(index($4,&quot;Windows&quot;)?&quot;Windows&quot;:</span></span><br><span class="line"><span class="string">(index($4,&quot;Linux&quot;)?&quot;Linux&quot;:&quot;Mac&quot;))&quot;\t&quot;(index($4,&quot;Chrome&quot;)?&quot;Chrome&quot;:</span></span><br><span class="line"><span class="string">(index($4,&quot;Version&quot;)?&quot;Safari&quot;:(index($4,&quot;Firefox&quot;)?&quot;Firefox&quot;:&quot;Opera&quot;)))&#125;&#x27;</span> &gt;</span><br><span class="line">new_2021-05-20.log</span><br></pre></td></tr></table></figure>


<h1 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h1><ol>
<li><p>安装sqoop</p>
</li>
<li><p>sqoop介绍</p>
<ol>
<li>Sqoop 是 Apache 旗下一款<strong>专为 Hadoop 设计的数据同步工具</strong>，全称为 “SQL to Hadoop”，主要用于在<strong>关系型数据库</strong>（如 MySQL、Oracle）和<strong>Hadoop 生态系统</strong>（如 HDFS、Hive、HBase）之间高效传输数据。它通过 MapReduce 任务并行处理数据，支持大规模数据的批量导入导出，是 Hadoop 生态中连接结构化数据和非结构化数据的重要桥梁。</li>
<li><h3 id="核心功能与特点"><a href="#核心功能与特点" class="headerlink" title="核心功能与特点"></a>核心功能与特点</h3><ol>
<li><strong>数据导入（Import）</strong><br>将关系型数据库中的数据抽取到 Hadoop 中（如 HDFS 存储为文件，或直接导入 Hive 表、HBase 表）。<ul>
<li><strong>支持增量导入</strong>：可基于时间戳或主键增量同步变化的数据。</li>
<li><strong>并行处理</strong>：通过 MapReduce 并行读取数据库分片，提升传输效率。</li>
</ul>
</li>
<li><strong>数据导出（Export）</strong><br>将 Hadoop 中的数据（如 HDFS 文件、Hive 表）写回到关系型数据库。<ul>
<li><strong>事务支持</strong>：确保导出操作的原子性，失败时可回滚。</li>
</ul>
</li>
<li><strong>多种数据库支持</strong><br>支持主流关系型数据库，如 MySQL、Oracle、PostgreSQL、SQL Server 等，也可通过 JDBC 连接其他数据库。</li>
<li><strong>元数据映射</strong><br>自动将数据库表结构映射为 Hive 表或 HDFS 文件格式（如 Avro、Parquet），简化数据建模。</li>
<li><strong>与 Hadoop 生态集成</strong><br>无缝集成 Hive、HBase、Spark 等组件，可作为 ETL（抽取 - 转换 - 加载）工具链的核心环节。</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><strong>总结</strong><br>         Sqoop 是 Hadoop 生态中连接结构化数据源（如数据库）与分布式计算平台的关键工具，尤其适合批量数据迁移和周期性 ETL 任务。通过简单的命令行接口，它让数据工程师能够高效地在 Hadoop 与传统 IT 系统间交换数据，降低了大数据应用的集成门槛。</p>
<ol start="3">
<li>sqoop使用</li>
</ol>
<hr>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol>
<li>配置mysql</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> database test</span><br><span class="line"><span class="keyword">DEFAULT</span> <span class="keyword">CHARACTER SET</span> utf8</span><br><span class="line"><span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line"><span class="comment">--创建数据库</span></span><br><span class="line"><span class="keyword">show</span> databases;</span><br><span class="line"><span class="comment">--创建账号</span></span><br><span class="line"><span class="keyword">Create</span> <span class="keyword">user</span> <span class="string">&#x27;test&#x27;</span>@<span class="string">&#x27;%&#x27;</span> identified <span class="keyword">by</span> <span class="string">&#x27;test&#x27;</span>;</span><br><span class="line"><span class="keyword">Grant</span> <span class="keyword">all</span> privileges <span class="keyword">on</span> test.<span class="operator">*</span> <span class="keyword">to</span> test@<span class="string">&#x27;%&#x27;</span> </span><br><span class="line">identified <span class="keyword">by</span> <span class="string">&#x27;test&#x27;</span> <span class="keyword">with</span> <span class="keyword">grant</span> option;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>



<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.拷贝安装包以及mysql的jar到/root目录 并解压</span></span><br><span class="line">tar -zvxf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/module/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.配置环境变量</span></span><br><span class="line"></span><br><span class="line">vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="comment"># 加入 sqoop 路径</span></span><br><span class="line"><span class="comment">#SQOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> SQOOP_HOME=/opt/module/sqoop-1.4.6.bin__hadoop-2.0.4-alpha</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SQOOP_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="安装sqoop"><a href="#安装sqoop" class="headerlink" title="安装sqoop"></a>安装sqoop</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3.配置sqoop</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$SQOOP_HOME</span>/conf</span><br><span class="line"><span class="built_in">cp</span> sqoop-env-template.sh sqoop-env.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/opt/module/apache-hive-3.1.2-bin</span><br><span class="line"><span class="comment">#export ZOOKEEPER_HOME=/opt/module/zookeeper-3.4.10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#拷贝 jdbc 驱动到 sqoop 的 lib 目录下</span></span><br><span class="line"><span class="built_in">cp</span> mysql-connector-java-5.1.27-bin.jar /opt/module/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/lib/</span><br></pre></td></tr></table></figure>

<p>4.测试连接</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqoop list-databases --connect jdbc:mysql://localhost:3306/ --username root --password root</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="分区重构"><a href="#分区重构" class="headerlink" title="分区重构"></a>分区重构</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">beeline -u <span class="string">&quot;jdbc:hive2://hadoop100:10000/db_hive&quot;</span> \</span><br><span class="line"> --outputformat=csv2 --showHeader=<span class="literal">false</span> -n root -p 123456 -e <span class="string">&quot;msck repair table log_sqoop&quot;</span></span><br></pre></td></tr></table></figure>





<h1 id="DataX"><a href="#DataX" class="headerlink" title="DataX"></a>DataX</h1><p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/alibaba/DataX">https://github.com/alibaba/DataX</a><br>官方文档：<a target="_blank" rel="noopener" href="https://github.com/alibaba/DataX/blob/master/introduction.md">https://github.com/alibaba/DataX/blob/master/introduction.md</a></p>
<p>DataX 是阿里巴巴开源的一个<strong>异构数据源离线同步工具</strong>，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。</p>
<p> DataX本身作为数据同步框架，将不同数据源的同步抽象为<strong>从源头数据源读取数据的Reader插件，以及向目标端写入数据的Writer插件</strong>，理论上DataX框架可以支持任意数据源类型的数据同步工作。同时DataX插件体系作为一套生态系统, 每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。</p>
<h2 id="安装-datax"><a href="#安装-datax" class="headerlink" title="安装 datax"></a>安装 datax</h2><p>确保hadoop集群没有问题</p>
<p>将 <code>datax.tar.gz</code> 上传到 hadoop100 的 <code>/root</code>目录下, 解压安装</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf datax.tar.gz -C /opt/moudule</span><br><span class="line"><span class="comment"># 同步到其他机器</span></span><br><span class="line">xsync /opt/moudule/datax</span><br></pre></td></tr></table></figure>

<h3 id="编写配置文件"><a href="#编写配置文件" class="headerlink" title="编写配置文件"></a>编写配置文件</h3><p>开发目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /zhiyun/lijinquan</span><br><span class="line"><span class="built_in">cd</span> /zhiyun/lijinquan</span><br><span class="line"><span class="comment"># 创建几个目录</span></span><br><span class="line"><span class="built_in">mkdir</span> <span class="built_in">jobs</span> sql python shell data</span><br></pre></td></tr></table></figure>

<p>datax的配置文件需要放在 jobs 目录下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /zhiyun/lijinquan/jobs/c_org_busi.json</span><br></pre></td></tr></table></figure>

<p>加入内容</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;job&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;setting&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;speed&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                 <span class="attr">&quot;channel&quot;</span><span class="punctuation">:</span> <span class="number">3</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;errorLimit&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;record&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span> <span class="number">0.02</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;reader&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mysqlreader&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;username&quot;</span><span class="punctuation">:</span> <span class="string">&quot;zhiyun&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;password&quot;</span><span class="punctuation">:</span> <span class="string">&quot;zhiyun&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;*&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;connection&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                    <span class="string">&quot;c_org_busi&quot;</span></span><br><span class="line">                                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;jdbcUrl&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                    <span class="string">&quot;jdbc:mysql://192.168.50.179:3306/his?useSSL=false&quot;</span></span><br><span class="line">                                <span class="punctuation">]</span></span><br><span class="line">                            <span class="punctuation">&#125;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;writer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfswriter&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;defaultFS&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://hadoop100:8020&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;fileType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;orc&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/zhiyun/lijinquan/ods/c_org_busi&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;fileName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;c_org_busi.data&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;col1&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;TINYINT&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                           ..</span><br><span class="line">                        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;writeMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;truncate`&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;fieldDelimiter&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\t&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python /opt/datax/bin/datax.py /zhiyun/lijinquan/jobs/c_org_busi.json</span><br></pre></td></tr></table></figure>

<p>列名的处理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 一个列一个列的处理</span><br><span class="line">2. vscode多行编辑  alt+shift+鼠标拖动</span><br></pre></td></tr></table></figure>

<p>抽取 <code>c_org_busi</code> 表</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">您配置的path: [/zhiyun/lijinquan/ods/c_org_busi] 不存在, 请先在hive端创建对应的数据库和表.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">datax不会自动创建HDFS上的路径, 需要手动创建</span><br><span class="line">hadoop fs -<span class="built_in">mkdir</span> -p /zhiyun/lijinquan/ods/c_org_busi</span><br></pre></td></tr></table></figure>

<p>确保抽取成功, 没有报错</p>
<h3 id="Hive建表"><a href="#Hive建表" class="headerlink" title="Hive建表"></a>Hive建表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 确保数据库存在</span></span><br><span class="line"><span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> ods_lijinquan location &quot;/zhiyun/lijinquan/ods&quot;;</span><br><span class="line"><span class="comment">-- 建表</span></span><br><span class="line"><span class="comment">-- ods层的表都应该是外部表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> ods_lijinquan.c_org_busi(</span><br><span class="line">...</span><br><span class="line">) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> &quot;\t&quot;</span><br><span class="line">lines terminated <span class="keyword">by</span> &quot;\n&quot;</span><br><span class="line">stored <span class="keyword">as</span> orc</span><br><span class="line">location &quot;/zhiyun/lijinquan/ods/c_org_busi&quot;;</span><br></pre></td></tr></table></figure>

<h3 id="验证数据"><a href="#验证数据" class="headerlink" title="验证数据"></a>验证数据</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> ods_lijinquan.c_org_busi limit <span class="number">1</span>;</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> ods_lijinquan.c_org_busi;</span><br></pre></td></tr></table></figure>

<h3 id="调度平台的安装"><a href="#调度平台的安装" class="headerlink" title="调度平台的安装"></a>调度平台的安装</h3><p>将目录 <code>\07_医药\xxl-job-student-20221220</code>上传到 hadoop100的 <code>/opt</code>目录下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 改名</span></span><br><span class="line"><span class="built_in">mv</span> /opt/xxl-job-student-20221220 /opt/xxljob</span><br><span class="line"><span class="comment"># 导入到mysql</span></span><br><span class="line"><span class="comment"># 确保mysql的密码为root</span></span><br><span class="line">mysql -uroot -proot</span><br><span class="line"><span class="comment"># 在mysql里执行:</span></span><br><span class="line"><span class="built_in">source</span> /opt/xxljob/tables_xxl_job.sql;</span><br><span class="line">quit;</span><br></pre></td></tr></table></figure>

<p>编写启停脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /root/bin/xxl</span><br></pre></td></tr></table></figure>

<p>内容:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">act=$1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">start()&#123;</span><br><span class="line">    echo &quot;starting xxl-job&quot;</span><br><span class="line">    ssh root@hadoop100 &quot;cd /opt/xxljob; nohup java -jar xxl-job-admin-2.3.0.jar &gt; xxl-job.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    ssh root@hadoop100 &quot;cd /opt/xxljob; nohup java -jar xxl-job-executor-sample-springboot-2.3.0.jar &gt; xxl-job-executor.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    ssh root@hadoop101 &quot;cd /opt/xxljob; nohup java -jar xxl-job-executor-sample-springboot-2.3.0.jar &gt; xxl-job-executor.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">    ssh root@hadoop102 &quot;cd /opt/xxljob; nohup java -jar xxl-job-executor-sample-springboot-2.3.0.jar &gt; xxl-job-executor.log 2&gt;&amp;1 &amp;&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">stop()&#123;</span><br><span class="line">    echo &quot;stopping xxl-job&quot;</span><br><span class="line">    ssh root@hadoop100 &quot;ps -aux | grep xxl-job-admin | grep -v grep | awk &#x27;&#123;print \$2&#125;&#x27; | xargs kill -9&quot;</span><br><span class="line">    ssh root@hadoop100 &quot;ps -aux | grep xxl-job-executor-sample | grep -v grep | awk &#x27;&#123;print \$2&#125;&#x27; | xargs kill -9&quot;</span><br><span class="line">    ssh root@hadoop101 &quot;ps -aux | grep xxl-job-executor-sample | grep -v grep | awk &#x27;&#123;print \$2&#125;&#x27; | xargs kill -9&quot;</span><br><span class="line">    ssh root@hadoop102 &quot;ps -aux | grep xxl-job-executor-sample | grep -v grep | awk &#x27;&#123;print \$2&#125;&#x27; | xargs kill -9&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">status()&#123;</span><br><span class="line">    echo &quot;=============== hadoop102 =================&quot;</span><br><span class="line">    ssh root@hadoop102 &quot;ps -aux | grep xxl-job-executor-sample | grep -v grep&quot;</span><br><span class="line">    echo &quot;=============== hadoop101 =================&quot;</span><br><span class="line">    ssh root@hadoop101 &quot;ps -aux | grep xxl-job-executor-sample | grep -v grep&quot;</span><br><span class="line">    echo &quot;=============== hadoop100 =================&quot;</span><br><span class="line">    ssh root@hadoop100 &quot;ps -aux | grep xxl-job | grep -v grep&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">case $act in</span><br><span class="line">start)</span><br><span class="line">    start</span><br><span class="line">    status</span><br><span class="line">;;</span><br><span class="line">stop)</span><br><span class="line">    stop</span><br><span class="line">    status</span><br><span class="line">;;</span><br><span class="line">restart)</span><br><span class="line">    stop</span><br><span class="line">    start</span><br><span class="line">    status</span><br><span class="line">;;</span><br><span class="line">status)</span><br><span class="line">    status</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p>加权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x /root/bin/xxl</span><br></pre></td></tr></table></figure>

<p>使用</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同步</span></span><br><span class="line">xsync /opt/xxljob</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动</span></span><br><span class="line">xxl start</span><br><span class="line"></span><br><span class="line">=============== hadoop102 =================</span><br><span class="line">root       2340  0.0  1.2 2679420 22952 ?       Sl   15:40   0:00 java -jar xxl-job-executor-sample-springboot-2.3.0.jar</span><br><span class="line">=============== hadoop101 =================</span><br><span class="line">root       2293  134  2.2 2679420 42324 ?       Sl   15:40   0:01 java -jar xxl-job-executor-sample-springboot-2.3.0.jar</span><br><span class="line">=============== hadoop100 =================</span><br><span class="line">root      20685  146  2.0 2679452 38340 ?       Sl   15:40   0:01 java -jar xxl-job-admin-2.3.0.jar</span><br><span class="line">root      20710  150  2.1 2679424 40340 ?       Sl   15:40   0:01 java -jar xxl-job-executor-sample-springboot-2.3.0.jar</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">状态</span></span><br><span class="line">xxl status</span><br></pre></td></tr></table></figure>

<p>等到 8080 端口启动成功后, 可以访问:</p>
<p><a target="_blank" rel="noopener" href="http://192.168.200.100:8080/xxl-job-admin">http://192.168.200.100:8080/xxl-job-admin</a></p>
<p>登录 admin &#x2F; 123456</p>
<p>执行器: 调度平台会随机使用任一执行器去执行任务</p>
<h1 id="Hive-表导出到-MySQL-数据库"><a href="#Hive-表导出到-MySQL-数据库" class="headerlink" title="Hive 表导出到 MySQL 数据库"></a>Hive 表导出到 MySQL 数据库</h1><h2 id="test-read-hdfs-json"><a href="#test-read-hdfs-json" class="headerlink" title="test_read_hdfs.json"></a><code>test_read_hdfs.json</code></h2><p>将 HDFS 中的数据同步到 MySQL 数据库</p>
<ol>
<li>从 HDFS 路径 <code>/user/hive/warehouse/db_hive.db/sqoop_emp</code> 读取数据</li>
<li>按制表符分隔解析文本行，提取 8 个字段</li>
<li>通过 3 个并发通道将数据传输到 MySQL</li>
<li>将数据插入到 MySQL 的 <code>test.emp</code> 表中</li>
</ol>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;job&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;setting&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;speed&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;channel&quot;</span><span class="punctuation">:</span> <span class="number">3</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;reader&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfsreader&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/user/hive/warehouse/db_hive.db/sqoop_emp&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;defaultFS&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://hadoop100:8020&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="number">7</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span></span><br><span class="line">                        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;fileType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;encoding&quot;</span><span class="punctuation">:</span> <span class="string">&quot;UTF-8&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;fieldDelimiter&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\t&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;writer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mysqlwriter&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;writeMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;insert&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;username&quot;</span><span class="punctuation">:</span> <span class="string">&quot;test&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;password&quot;</span><span class="punctuation">:</span> <span class="string">&quot;test&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;empno&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;ename&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;job&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;mgr&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;hiredate&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;sal&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;comm&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="string">&quot;deptno&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;session&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;set session sql_mode=&#x27;ANSI&#x27;&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;connection&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;jdbcUrl&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jdbc:mysql://hadoop100:3306/test?useSSL=False&amp;useUnicode=true&amp;characterEncoding=utf-8&quot;</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;table&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                    <span class="string">&quot;emp&quot;</span></span><br><span class="line">                                <span class="punctuation">]</span></span><br><span class="line">                            <span class="punctuation">&#125;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2025/06/24/Hadoop/image-20250707111745049.png" alt="image-20250707111745049"></p>
<h2 id="exp-log-sh"><a href="#exp-log-sh" class="headerlink" title="exp_log.sh"></a><code>exp_log.sh</code></h2><ol>
<li><strong>生成配置文件</strong>：根据传入的日期分区参数 <code>$1</code>，动态生成 DataX 配置文件 <code>exp_log.json</code>，配置从 HDFS 读取指定日期分区的数据，并写入 MySQL 表。</li>
<li><strong>创建目标表</strong>：在 MySQL 中创建 <code>log</code> 表（如果不存在），定义五个 VARCHAR 类型的字段用于存储日志数据。</li>
<li><strong>执行数据同步</strong>：调用 DataX 工具执行数据导出任务，将 HDFS 上的文本格式数据（<code>/user/hive/warehouse/db_hive.db/log/dt=$part</code>）按字段映射关系写入 MySQL 的 <code>log</code> 表。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">part=<span class="variable">$1</span> </span><br><span class="line"><span class="comment"># 创建一个json，用来给datax调用</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;job&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;setting&quot;: &#123;</span></span><br><span class="line"><span class="string">            &quot;speed&quot;: &#123;</span></span><br><span class="line"><span class="string">                &quot;channel&quot;: 3</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#125;,</span></span><br><span class="line"><span class="string">        &quot;content&quot;: [</span></span><br><span class="line"><span class="string">            &#123;</span></span><br><span class="line"><span class="string">                &quot;reader&quot;: &#123;</span></span><br><span class="line"><span class="string">                    &quot;name&quot;: &quot;hdfsreader&quot;,</span></span><br><span class="line"><span class="string">                    &quot;parameter&quot;: &#123;</span></span><br><span class="line"><span class="string">                        &quot;path&quot;: &quot;/user/hive/warehouse/db_hive.db/log/dt=&#x27;</span><span class="variable">$part</span><span class="string">&#x27;&quot;,</span></span><br><span class="line"><span class="string">                        &quot;defaultFS&quot;: &quot;hdfs://hadoop100:8020&quot;,</span></span><br><span class="line"><span class="string">                        &quot;column&quot;: [</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;index&quot;: 0,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;,</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;index&quot;: 1,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;,</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;index&quot;: 2,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;,</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;index&quot;: 3,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;,</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;index&quot;: 4,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;</span></span><br><span class="line"><span class="string">                        ],</span></span><br><span class="line"><span class="string">                        &quot;fileType&quot;: &quot;text&quot;,</span></span><br><span class="line"><span class="string">                        &quot;encoding&quot;: &quot;UTF-8&quot;,</span></span><br><span class="line"><span class="string">                        &quot;fieldDelimiter&quot;: &quot;\t&quot;</span></span><br><span class="line"><span class="string">                    &#125;</span></span><br><span class="line"><span class="string">                &#125;,</span></span><br><span class="line"><span class="string">                &quot;writer&quot;: &#123;</span></span><br><span class="line"><span class="string">                    &quot;name&quot;: &quot;mysqlwriter&quot;,</span></span><br><span class="line"><span class="string">                    &quot;parameter&quot;: &#123;</span></span><br><span class="line"><span class="string">                        &quot;writeMode&quot;: &quot;insert&quot;,</span></span><br><span class="line"><span class="string">                        &quot;username&quot;: &quot;test&quot;,</span></span><br><span class="line"><span class="string">                        &quot;password&quot;: &quot;test&quot;,</span></span><br><span class="line"><span class="string">                        &quot;column&quot;: [</span></span><br><span class="line"><span class="string">                            &quot;ip&quot;,</span></span><br><span class="line"><span class="string">                            &quot;date_l&quot;,</span></span><br><span class="line"><span class="string">                            &quot;url&quot;,</span></span><br><span class="line"><span class="string">                            &quot;osinfo&quot;,</span></span><br><span class="line"><span class="string">                            &quot;bowser&quot;</span></span><br><span class="line"><span class="string">                        ],</span></span><br><span class="line"><span class="string">                        &quot;session&quot;: [</span></span><br><span class="line"><span class="string">                            &quot;set session sql_mode=&#x27;</span><span class="string">&quot;&#x27;ANSI&#x27;&quot;</span><span class="string">&#x27;&quot;</span></span><br><span class="line"><span class="string">                        ],</span></span><br><span class="line"><span class="string">                        &quot;connection&quot;: [</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;jdbcUrl&quot;: &quot;jdbc:mysql://hadoop100:3306/test?useSSL=False&amp;useUnicode=true&amp;characterEncoding=utf-8&quot;,</span></span><br><span class="line"><span class="string">                                &quot;table&quot;: [</span></span><br><span class="line"><span class="string">                                    &quot;log&quot;</span></span><br><span class="line"><span class="string">                                ]</span></span><br><span class="line"><span class="string">                            &#125;</span></span><br><span class="line"><span class="string">                        ]</span></span><br><span class="line"><span class="string">                    &#125;</span></span><br><span class="line"><span class="string">                &#125;</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span> &gt; /root/datax/json/exp_log.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写一个建表语句，再mysql建表</span></span><br><span class="line">mysql -utest -ptest --database=<span class="built_in">test</span> -e \</span><br><span class="line"><span class="string">&#x27;create table if not exists log (</span></span><br><span class="line"><span class="string">    ip varchar(500),</span></span><br><span class="line"><span class="string">    date_l varchar(500),</span></span><br><span class="line"><span class="string">    url varchar(500),</span></span><br><span class="line"><span class="string">    osinfo varchar(500),</span></span><br><span class="line"><span class="string">    bowser varchar(500)</span></span><br><span class="line"><span class="string">)&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动datax程序，完成操作</span></span><br><span class="line">/usr/local/bin/python3.9 /opt/module/datax/bin/datax.py /root/datax/json/exp_log.json</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2025/06/24/Hadoop/image-20250707111856490.png" alt="image-20250707111856490"></p>
<h2 id="xxl-job-任务调度中心-新增任务管理"><a href="#xxl-job-任务调度中心-新增任务管理" class="headerlink" title="xxl-job-任务调度中心-新增任务管理"></a>xxl-job-任务调度中心-新增任务管理</h2><p><img src="/2025/06/24/Hadoop/image-20250707111920017.png" alt="image-20250707111920017"></p>
<p><strong>GLUE IDE</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;xxl-job: hello shell&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;脚本位置：<span class="variable">$0</span>&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;任务参数：<span class="variable">$1</span>&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;分片序号 = <span class="variable">$2</span>&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;分片总数 = <span class="variable">$3</span>&quot;</span></span><br><span class="line">/root/datax/shell/exp_log.sh <span class="variable">$1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Good bye!&quot;</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure>

<p>分别手动执行一次\</p>
<p><img src="/2025/06/24/Hadoop/image-20250707112014506.png" alt="image-20250707112014506"></p>
<p>mysql.test中查询log数据量</p>
<p><img src="/2025/06/24/Hadoop/image-20250707112033577.png" alt="image-20250707112033577"></p>
<h1 id="动态分区表导入导出"><a href="#动态分区表导入导出" class="headerlink" title="动态分区表导入导出"></a>动态分区表导入导出</h1><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;job&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;setting&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;speed&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;channel&quot;</span><span class="punctuation">:</span> <span class="number">3</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;errorLimit&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;record&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;percentage&quot;</span><span class="punctuation">:</span> <span class="number">0.02</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;reader&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mysqlreader&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;username&quot;</span><span class="punctuation">:</span> <span class="string">&quot;test&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;password&quot;</span><span class="punctuation">:</span> <span class="string">&quot;test&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="string">&quot;*&quot;</span></span><br><span class="line">                        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;splitPk&quot;</span><span class="punctuation">:</span> <span class="string">&quot;db_id&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;connection&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;querySql&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                    <span class="string">&quot;select * from log where osinfo = &#x27;Windows&#x27;;&quot;</span></span><br><span class="line">                                <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;jdbcUrl&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                                    <span class="string">&quot;jjdbc:mysql://hadoop100:3306/test?useSSL=False&amp;useUnicode=true&amp;characterEncoding=utf-8&quot;</span></span><br><span class="line">                                <span class="punctuation">]</span></span><br><span class="line">                            <span class="punctuation">&#125;</span></span><br><span class="line">                        <span class="punctuation">]</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;writer&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfswriter&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;parameter&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;defaultFS&quot;</span><span class="punctuation">:</span> <span class="string">&quot;hdfs://hadoop100:8020&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;fileType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;orc&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/user/hive/warehouse/db_hive.db/log_tmp&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;fileName&quot;</span><span class="punctuation">:</span> <span class="string">&quot;log_p&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;column&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ip&quot;</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;date_l&quot;</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;url&quot;</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;osinfo&quot;</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="punctuation">&#123;</span></span><br><span class="line">                                <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;browser&quot;</span><span class="punctuation">,</span></span><br><span class="line">                                <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">                            <span class="punctuation">&#125;</span></span><br><span class="line">                        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;writeMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;truncate&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;fieldDelimiter&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\t&quot;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;compress&quot;</span><span class="punctuation">:</span> <span class="string">&quot;NONE&quot;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>在db_hive中建log_temp表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create table</span> log_tmp(</span><br><span class="line">	ip string,</span><br><span class="line">	date_l string,</span><br><span class="line">	url string,</span><br><span class="line">	osinfo string,</span><br><span class="line">	browser string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited</span><br><span class="line">fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> orc</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>运行脚本<br><code>/usr/local/bin/python3.9 /opt/module/datax/bin/datax.py /root/datax/json/imp_log.json</code></p>
<p><img src="/2025/06/24/Hadoop/image-20250707112144219.png" alt="image-20250707112144219"></p>
<h2 id="imp-log-sh"><a href="#imp-log-sh" class="headerlink" title="imp_log.sh"></a><code>imp_log.sh</code></h2><ol>
<li><strong>JSON 配置文件生成</strong>：创建 DataX 任务配置文件 <code>imp_log.json</code>，配置从 MySQL 读取数据并写入 HDFS 的 ORC 文件格式。</li>
<li>Hive 表创建：使用 Beeline 连接 Hive，创建两个 ORC 格式的表：<ul>
<li><code>log_tmp</code>：临时表，用于存储从 MySQL 导入的原始数据</li>
<li><code>log_p</code>：分区表，按操作系统类型 (<code>os_tp</code>) 分区</li>
</ul>
</li>
<li><strong>数据抽取与导入</strong>：调用 DataX 工具执行数据同步任务，将 MySQL 的 <code>log</code> 表数据导入到 Hive 的 <code>log_tmp</code> 表。</li>
<li><strong>动态分区插入</strong>：配置 Hive 动态分区参数，将 <code>log_tmp</code> 表的数据按 <code>osinfo</code> 字段的值自动分配到 <code>log_tmp2</code> 表的不同分区中。</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#创建json文件</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    &quot;job&quot;: &#123;</span></span><br><span class="line"><span class="string">        &quot;setting&quot;: &#123;</span></span><br><span class="line"><span class="string">            &quot;speed&quot;: &#123;</span></span><br><span class="line"><span class="string">                &quot;channel&quot;: 3</span></span><br><span class="line"><span class="string">            &#125;,</span></span><br><span class="line"><span class="string">            &quot;errorLimit&quot;: &#123;</span></span><br><span class="line"><span class="string">                &quot;record&quot;: 0,</span></span><br><span class="line"><span class="string">                &quot;percentage&quot;: 0.02</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        &#125;,</span></span><br><span class="line"><span class="string">        &quot;content&quot;: [</span></span><br><span class="line"><span class="string">            &#123;</span></span><br><span class="line"><span class="string">                &quot;reader&quot;: &#123;</span></span><br><span class="line"><span class="string">                    &quot;name&quot;: &quot;mysqlreader&quot;,</span></span><br><span class="line"><span class="string">                    &quot;parameter&quot;: &#123;</span></span><br><span class="line"><span class="string">                        &quot;username&quot;: &quot;test&quot;,</span></span><br><span class="line"><span class="string">                        &quot;password&quot;: &quot;test&quot;,</span></span><br><span class="line"><span class="string">                        &quot;column&quot;: [</span></span><br><span class="line"><span class="string">                            &quot;*&quot;</span></span><br><span class="line"><span class="string">                        ],</span></span><br><span class="line"><span class="string">                        //&quot;splitPk&quot;: &quot;db_id&quot;,</span></span><br><span class="line"><span class="string">                        &quot;connection&quot;: [</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;table&quot;: [</span></span><br><span class="line"><span class="string">                                    &quot;log;&quot;</span></span><br><span class="line"><span class="string">                                ],</span></span><br><span class="line"><span class="string">                                &quot;jdbcUrl&quot;: [</span></span><br><span class="line"><span class="string">                                    &quot;jdbc:mysql://hadoop100:3306/test?useSSL=False&amp;useUnicode=true&amp;characterEncoding=utf-8&quot;</span></span><br><span class="line"><span class="string">                                ]</span></span><br><span class="line"><span class="string">                            &#125;</span></span><br><span class="line"><span class="string">                        ]</span></span><br><span class="line"><span class="string">                    &#125;</span></span><br><span class="line"><span class="string">                &#125;,</span></span><br><span class="line"><span class="string">                &quot;writer&quot;: &#123;</span></span><br><span class="line"><span class="string">                    &quot;name&quot;: &quot;hdfswriter&quot;,</span></span><br><span class="line"><span class="string">                    &quot;parameter&quot;: &#123;</span></span><br><span class="line"><span class="string">                        &quot;defaultFS&quot;: &quot;hdfs://hadoop100:8020&quot;,</span></span><br><span class="line"><span class="string">                        &quot;fileType&quot;: &quot;orc&quot;,</span></span><br><span class="line"><span class="string">                        &quot;path&quot;: &quot;/user/hive/warehouse/db_hive.db/log_tmp&quot;,</span></span><br><span class="line"><span class="string">                        &quot;fileName&quot;: &quot;log_tmp&quot;,</span></span><br><span class="line"><span class="string">                        &quot;column&quot;: [</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;name&quot;: &quot;ip&quot;,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;,</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;name&quot;: &quot;date_l&quot;,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;,</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;name&quot;: &quot;url&quot;,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;,</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;name&quot;: &quot;osinfo&quot;,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;,</span></span><br><span class="line"><span class="string">                            &#123;</span></span><br><span class="line"><span class="string">                                &quot;name&quot;: &quot;browser&quot;,</span></span><br><span class="line"><span class="string">                                &quot;type&quot;: &quot;string&quot;</span></span><br><span class="line"><span class="string">                            &#125;</span></span><br><span class="line"><span class="string">                        ],</span></span><br><span class="line"><span class="string">                        &quot;writeMode&quot;: &quot;truncate&quot;,</span></span><br><span class="line"><span class="string">                        &quot;fieldDelimiter&quot;: &quot;\t&quot;,</span></span><br><span class="line"><span class="string">                        &quot;compress&quot;: &quot;NONE&quot;</span></span><br><span class="line"><span class="string">                    &#125;</span></span><br><span class="line"><span class="string">                &#125;</span></span><br><span class="line"><span class="string">            &#125;</span></span><br><span class="line"><span class="string">        ]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span> &gt; /root/datax/json/imp_log.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 建临时表和分区表</span></span><br><span class="line">beeline -u jdbc:hive2://hadoop100:10000/db_hive -u root -p 545456 -e \</span><br><span class="line"><span class="string">&quot;CREATE TABLE if not exists log_tmp(</span></span><br><span class="line"><span class="string">ip string,</span></span><br><span class="line"><span class="string">date_l string,</span></span><br><span class="line"><span class="string">url string,</span></span><br><span class="line"><span class="string">osinfo string,</span></span><br><span class="line"><span class="string">browser string</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">row format delimited</span></span><br><span class="line"><span class="string">fields terminated by &#x27;\t&#x27;</span></span><br><span class="line"><span class="string">lines TERMINATED by &#x27;\n&#x27;</span></span><br><span class="line"><span class="string">STORED AS orc;</span></span><br><span class="line"><span class="string">CREATE TABLE if not exists log_p(</span></span><br><span class="line"><span class="string">ip string,</span></span><br><span class="line"><span class="string">date_l string,</span></span><br><span class="line"><span class="string">url string, </span></span><br><span class="line"><span class="string">osinfo string,</span></span><br><span class="line"><span class="string">browser string</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">partitioned by (os_tp string)</span></span><br><span class="line"><span class="string">row format delimited</span></span><br><span class="line"><span class="string">fields terminated by &#x27;\t&#x27;</span></span><br><span class="line"><span class="string">lines TERMINATED by &#x27;\n&#x27;</span></span><br><span class="line"><span class="string">STORED AS orc &quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;*******************建表完成--***********************&#x27;</span></span><br><span class="line"><span class="comment">#导入数据</span></span><br><span class="line">/bin/python3 /opt/module/datax/bin/datax.py /root/datax/json/imp_log.json</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;*****************数据导入成功************************&#x27;</span></span><br><span class="line"><span class="comment">#动态分区</span></span><br><span class="line">beeline -u jdbc:hive2://hadoop100:10000/db_hive -u root -p 545456 -e \</span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line"><span class="string">set hive.exec.dynamic.partition=true;</span></span><br><span class="line"><span class="string">set hive.exec.dynamic.partition.mode=nonstrict;</span></span><br><span class="line"><span class="string">set hive.exec.max.dynamic.partitions=200;</span></span><br><span class="line"><span class="string">set hive.exec.max.dynamic.partitions.pernode=50;</span></span><br><span class="line"><span class="string">set hive.exec.max.created.files=1000;</span></span><br><span class="line"><span class="string">set hive.error.on.empty.partition=false;</span></span><br><span class="line"><span class="string">set hive.support.quoted.identifiers=none;</span></span><br><span class="line"><span class="string">insert into log_p partition (os_tp) select l.*,osinfo from log_tmp l;</span></span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;------------------完成------------------&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2025/06/24/Hadoop/image-20250707112233843.png" alt="image-20250707112233843"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://cryingatnight.github.io">Yinjin Yao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://cryingatnight.github.io/2025/06/24/Hadoop/">https://cryingatnight.github.io/2025/06/24/Hadoop/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://cryingatnight.github.io" target="_blank">Yinjin Yao的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post-share"><div class="social-share" data-image="/img/lita9.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/06/27/Hive/" title="Hive"><img class="cover" src="/img/lita3.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Hive</div></div><div class="info-2"><div class="info-item-1">什么是HIVEHive 是基于 Hadoop 的一个数据仓库工具。以下是具体介绍:  功能特点：Hive 可以将结构化的数据文件映射为一张数据库表，并提供完整的 SQL 查询功能，能将 SQL 语句转换为 MapReduce 任务进行运行。它允许熟悉 SQL 的用户方便地查询数据，也支持熟悉 MapReduce 的开发者自定义 mapper 和 reducer，以处理复杂的分析工作。 优势：学习成本低，通过类 SQL 语句可快速实现简单的 MapReduce 统计，无需开发专门的 MapReduce 应用，十分适合数据仓库的统计分析。 应用场景：常用于对时效性要求不高的数据分析场景。由于 Hive 底层依赖 Hadoop 的 HDFS 存储数据，利用 MapReduce 进行计算，因此能够处理大规模的数据，在处理海量结构化日志的数据统计等方面应用广泛。 与数据库的区别： 数据库一般用于在线应用，支持对某一行或某些行数据的更新、删除等操作，采用 “写时模式”，数据加载慢但查询快。 而 Hive 不支持对具体行的操作，也不支持事务和索引，采用 “读时模式”，适合处理非结构化或存储模式...</div></div></div></a><a class="pagination-related" href="/2025/05/28/Python/" title="Python"><img class="cover" src="/img/lita7.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Python</div></div><div class="info-2"><div class="info-item-1">国内常用镜像源12345678910111213清华大学 ：https://pypi.tuna.tsinghua.edu.cn/simple/阿里云：http://mirrors.aliyun.com/pypi/simple/中国科学技术大学 ：http://pypi.mirrors.ustc.edu.cn/simple/华中科技大学：http://pypi.hustunique.com/豆瓣源：http://pypi.douban.com/simple/腾讯源：http://mirrors.cloud.tencent.com/pypi/simple华为镜像源：https://repo.huaweicloud.com/repository/pypi/simple/    数据类型 数字型： bool int float   ⾮数字型： str list tuple set dict   ⽇期型： time datetime   例子： 123456sno=1age=18sname=&quot;小明&quot;high=1.786print(f&quot;&#123;sname&#...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/08/10/datax/" title="datax"><img class="cover" src="/img/lita9.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-08-10</div><div class="info-item-2">datax</div></div><div class="info-2"><div class="info-item-1">DataX简介DataX概述DataX 是阿里巴巴开源的一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。 datax源码地址：https://github.com/alibaba/DataX DataX支持的数据源DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入，目前支持数据如下图。    类型 数据源 Reader(读) Writer(写) 文档    RDBMS 关系型数据库 MySQL √ √ 读 、写    Oracle √ √ 读 、写    OceanBase √ √ 读 、写    SQLServer √ √ 读 、写    PostgreSQL √ √ 读 、写    DRDS √ √ 读 、写    Kingbase √ √ 读 、写    通用RDBMS(支持所有关系型数据库) √ √ 读 、写   阿里云数仓数据存储 ODPS √ √ 读 、写    ADB  √ 写    A...</div></div></div></a><a class="pagination-related" href="/2025/07/07/hadoop%E9%97%AE%E7%AD%94%E5%B0%8F%E6%B5%8B%E9%AA%8C/" title="hadoop问答小测验"><img class="cover" src="/img/lita2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-07</div><div class="info-item-2">hadoop问答小测验</div></div><div class="info-2"><div class="info-item-1">hadoop问答小测验1. hadoop组件有哪些?分别有什么功能一、核心组件由三个基础组件构成，它们是整个框架的基石：  Hadoop Distributed File System（HDFS）—— 分布式文件系统  功能： 专为存储海量数据设计的分布式文件系统，具有高容错性和高吞吐量。  将大文件分割成固定大小的 “块”（默认 128MB），分散存储在集群的多个节点上，每个块会有多个副本（默认 3 个），确保数据安全。适合处理 “一次写入、多次读取” 的场景，不支持频繁的文件修改（更适合静态数据）。      MapReduce—— 分布式计算框架  功能：    ​		基于 “分而治之” 思想的编程模型，用于并行处理大规模数据。  Map 阶段：将输入数据分割成多个子任务，并行处理后生成中间结果（键值对）。 Reduce 阶段：汇总 Map 阶段的中间结果，合并计算得到最终输出。   YARN（Yet Another Resource Negotiator）—— 资源管理器   功能 ：负责集群资源（CPU、内存等）的统一管理和任务调度，替代了早期 Hadoop 中的 Jo...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/headimage.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Yinjin Yao</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/cryingatnight/cryingatnight.github.io"><i class="fab fa-github"></i><span>关注</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/cryingatnight/cryingatnight.github.io" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1816192779@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">Hadoop简介</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8"><span class="toc-number">1.1.</span> <span class="toc-text">分布式存储</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E7%BB%84%E4%BB%B6-%E9%9D%A2%E8%AF%95%E9%87%8D%E7%82%B9"><span class="toc-number">2.</span> <span class="toc-text">Hadoop组件(面试重点)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">2.1.</span> <span class="toc-text">HDFS 架构概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Yarn-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">2.2.</span> <span class="toc-text">Yarn 架构概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">2.3.</span> <span class="toc-text">MapReduce 架构概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E3%80%81YARN%E3%80%81MapReduce-%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB"><span class="toc-number">2.4.</span> <span class="toc-text">HDFS、YARN、MapReduce 三者关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB"><span class="toc-number">2.5.</span> <span class="toc-text">大数据技术生态体系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%A1%86%E6%9E%B6%E5%9B%BE"><span class="toc-number">2.6.</span> <span class="toc-text">推荐系统框架图</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E4%B8%AA%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE%E5%88%86%E5%B8%83%E5%BC%8F-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-%E5%BC%80%E5%8F%91%E9%87%8D%E7%82%B9"><span class="toc-number">3.</span> <span class="toc-text">三个虚拟机配置分布式(环境搭建:开发重点)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.1.</span> <span class="toc-text">安装步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85"><span class="toc-number">3.2.</span> <span class="toc-text">软件安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BD%AF%E4%BB%B6%E5%87%86%E5%A4%87-%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6"><span class="toc-number">3.2.1.</span> <span class="toc-text">软件准备&#x2F;上传文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hadoop%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B"><span class="toc-number">3.2.2.</span> <span class="toc-text">hadoop安装过程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">系统环境配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85-1"><span class="toc-number">3.2.2.2.</span> <span class="toc-text">软件安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E6%9C%BA%E5%85%8B%E9%9A%86%E6%93%8D%E4%BD%9C"><span class="toc-number">3.2.2.3.</span> <span class="toc-text">主机克隆操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SSH%E5%8D%8F%E8%AE%AE%E5%85%8D%E5%AF%86%E9%85%8D%E7%BD%AE"><span class="toc-number">3.2.2.4.</span> <span class="toc-text">SSH协议免密配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4%E6%96%87%E4%BB%B6"><span class="toc-number">3.2.2.5.</span> <span class="toc-text">配置集群文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#core-site-xml"><span class="toc-number">3.2.3.</span> <span class="toc-text">core-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hdfs-site-xml"><span class="toc-number">3.2.4.</span> <span class="toc-text">hdfs-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#yarn-site-xml"><span class="toc-number">3.2.5.</span> <span class="toc-text">yarn-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mapred-site-xml"><span class="toc-number">3.2.6.</span> <span class="toc-text">mapred-site.xml</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#workers"><span class="toc-number">3.2.7.</span> <span class="toc-text">workers</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%BC%E5%BC%8F%E5%8C%96hdfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F-%E8%B0%A8%E6%85%8E%E4%BD%BF%E7%94%A8"><span class="toc-number">3.2.8.</span> <span class="toc-text">格式化hdfs文件系统(谨慎使用)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.9.</span> <span class="toc-text">启动集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#start-dfs-sh-stop-dfs-sh"><span class="toc-number">3.2.9.1.</span> <span class="toc-text">start-dfs.sh stop-dfs.sh</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#start-yarn-sh-stop-yarn-sh"><span class="toc-number">3.2.9.2.</span> <span class="toc-text">start-yarn.sh stop-yarn.sh</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="toc-number">3.2.10.</span> <span class="toc-text">配置历史服务器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#mapred-site-xml-1"><span class="toc-number">3.2.10.1.</span> <span class="toc-text">mapred-site.xml</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E8%81%9A%E9%9B%86"><span class="toc-number">3.2.11.</span> <span class="toc-text">配置历史聚集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#yarn-site-xml-1"><span class="toc-number">3.2.11.1.</span> <span class="toc-text">yarn-site.xml</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%81%9C%E8%84%9A%E6%9C%AC"><span class="toc-number">3.2.12.</span> <span class="toc-text">启停脚本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#myhadoop-sh"><span class="toc-number">3.2.12.1.</span> <span class="toc-text">myhadoop.sh</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8C%E6%AD%A5%E8%84%9A%E6%9C%AC"><span class="toc-number">3.2.13.</span> <span class="toc-text">同步脚本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C%E6%88%AA%E5%9B%BE"><span class="toc-number">3.2.13.1.</span> <span class="toc-text">结果截图</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0-hive%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2%E4%BB%8B%E7%BB%8D"><span class="toc-number">4.</span> <span class="toc-text">hadoop大数据平台-hive组件部署介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E5%B9%B3%E5%8F%B0-%E8%BF%9B%E7%A8%8B%E5%90%AF%E5%81%9C%E5%91%BD%E4%BB%A4"><span class="toc-number">5.</span> <span class="toc-text">Hadoop平台-进程启停命令</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E5%B9%B3%E5%8F%B0-HDFS%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%91%BD%E4%BB%A4"><span class="toc-number">6.</span> <span class="toc-text">Hadoop平台-HDFS文件系统命令</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E5%B9%B3%E5%8F%B0-HDFS%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">7.</span> <span class="toc-text">Hadoop平台-HDFS优缺点</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E5%B9%B3%E5%8F%B0-HDFS%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B"><span class="toc-number">8.</span> <span class="toc-text">Hadoop平台-HDFS读取流程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E5%B9%B3%E5%8F%B0-NameNode%E6%9B%B4%E6%96%B0%E6%B5%81%E7%A8%8B"><span class="toc-number">9.</span> <span class="toc-text">Hadoop平台-NameNode更新流程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E5%B9%B3%E5%8F%B0-yarn%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">10.</span> <span class="toc-text">Hadoop平台-yarn工作流程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop%E5%B9%B3%E5%8F%B0-mapreduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">11.</span> <span class="toc-text">Hadoop平台-mapreduce工作流程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFHIVE"><span class="toc-number">12.</span> <span class="toc-text">什么是HIVE</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#HIVE%E5%AE%89%E8%A3%85"><span class="toc-number">13.</span> <span class="toc-text">HIVE安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEmysql%E5%AE%89%E8%A3%85%E6%BA%90"><span class="toc-number">13.1.</span> <span class="toc-text">配置mysql安装源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85HIVE"><span class="toc-number">13.2.</span> <span class="toc-text">安装HIVE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96mapreduce"><span class="toc-number">13.3.</span> <span class="toc-text">优化mapreduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEbeeline"><span class="toc-number">13.4.</span> <span class="toc-text">配置beeline</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hive-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E8%AF%AD%E5%8F%A5"><span class="toc-number">14.</span> <span class="toc-text">hive 数据操作语句</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE%E6%9F%A5%E7%9C%8B%E8%AF%AD%E5%8F%A5"><span class="toc-number">14.1.</span> <span class="toc-text">元数据查看语句</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%BA%E5%BA%93%E6%93%8D%E4%BD%9C"><span class="toc-number">14.2.</span> <span class="toc-text">建库操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BB%BA%E8%A1%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">14.3.</span> <span class="toc-text">建表操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%95%B0%E6%8D%AE"><span class="toc-number">14.4.</span> <span class="toc-text">上传数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">14.5.</span> <span class="toc-text">下载数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#select%E8%AF%AD%E5%8F%A5"><span class="toc-number">14.6.</span> <span class="toc-text">select语句</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive%E5%A4%8D%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">15.</span> <span class="toc-text">Hive复合数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#hive-%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0"><span class="toc-number">15.1.</span> <span class="toc-text">hive 内置函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#python%E8%BF%9E%E6%8E%A5hive"><span class="toc-number">16.</span> <span class="toc-text">python连接hive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#linux%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85python"><span class="toc-number">16.1.</span> <span class="toc-text">linux环境安装python</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">16.1.1.</span> <span class="toc-text">配置环境变量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85pyhive%E5%BA%93"><span class="toc-number">16.2.</span> <span class="toc-text">安装pyhive库</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="toc-number">17.</span> <span class="toc-text">分区表</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">17.1.</span> <span class="toc-text">分区应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#oracle%E5%88%86%E5%8C%BA%E8%A1%A8%E7%A7%8D%E7%B1%BB"><span class="toc-number">17.2.</span> <span class="toc-text">oracle分区表种类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#oracle%E5%88%86%E5%8C%BA-%E8%8C%83%E5%9B%B4%E5%88%86%E5%8C%BA"><span class="toc-number">17.3.</span> <span class="toc-text">oracle分区-范围分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#oracle%E5%88%86%E5%8C%BA-%E5%88%97%E8%A1%A8%E5%88%86%E5%8C%BA"><span class="toc-number">17.4.</span> <span class="toc-text">oracle分区-列表分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#oracle%E5%88%86%E5%8C%BA-%E6%95%A3%E5%88%97%E5%88%86%E5%8C%BA"><span class="toc-number">17.5.</span> <span class="toc-text">oracle分区-散列分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#oracle%E5%88%86%E5%8C%BA-%E7%BB%84%E5%90%88%E5%88%86%E5%8C%BA"><span class="toc-number">17.6.</span> <span class="toc-text">oracle分区-组合分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#oracle%E5%88%86%E5%8C%BA-%E5%88%86%E5%8C%BA%E8%A1%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">17.7.</span> <span class="toc-text">oracle分区-分区表操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hive%E5%88%86%E5%8C%BA-%E5%88%9B%E5%BB%BA%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="toc-number">17.8.</span> <span class="toc-text">hive分区-创建分区表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hive%E5%88%86%E5%8C%BA-%E5%88%86%E5%8C%BA%E8%A1%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">17.9.</span> <span class="toc-text">hive分区-分区表操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B6%85%E5%B8%82%E5%88%86%E5%8C%BA%E8%A1%A8%E7%A4%BA%E4%BE%8B"><span class="toc-number">17.10.</span> <span class="toc-text">超市分区表示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA%E9%85%8D%E7%BD%AE"><span class="toc-number">17.11.</span> <span class="toc-text">动态分区配置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="toc-number">18.</span> <span class="toc-text">分桶表</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E6%A1%B6%E8%A1%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">18.1.</span> <span class="toc-text">分桶表注意事项</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hive%E5%88%86%E6%A1%B6%E8%A1%A8-%E5%88%9B%E5%BB%BA%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="toc-number">18.2.</span> <span class="toc-text">hive分桶表-创建分桶表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hive%E6%8E%92%E5%BA%8F%E5%85%B3%E9%94%AE%E5%AD%97"><span class="toc-number">18.3.</span> <span class="toc-text">hive排序关键字</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8awk-%E6%B8%85%E6%B4%97-log"><span class="toc-number">18.4.</span> <span class="toc-text">使用awk 清洗 log</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#sqoop"><span class="toc-number">19.</span> <span class="toc-text">sqoop</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD%E4%B8%8E%E7%89%B9%E7%82%B9"><span class="toc-number">19.0.1.</span> <span class="toc-text">核心功能与特点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85"><span class="toc-number">19.1.</span> <span class="toc-text">安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85sqoop"><span class="toc-number">19.2.</span> <span class="toc-text">安装sqoop</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E9%87%8D%E6%9E%84"><span class="toc-number">19.2.1.</span> <span class="toc-text">分区重构</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DataX"><span class="toc-number">20.</span> <span class="toc-text">DataX</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-datax"><span class="toc-number">20.1.</span> <span class="toc-text">安装 datax</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">20.1.1.</span> <span class="toc-text">编写配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive%E5%BB%BA%E8%A1%A8"><span class="toc-number">20.1.2.</span> <span class="toc-text">Hive建表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E6%95%B0%E6%8D%AE"><span class="toc-number">20.1.3.</span> <span class="toc-text">验证数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E5%BA%A6%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-number">20.1.4.</span> <span class="toc-text">调度平台的安装</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive-%E8%A1%A8%E5%AF%BC%E5%87%BA%E5%88%B0-MySQL-%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">21.</span> <span class="toc-text">Hive 表导出到 MySQL 数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#test-read-hdfs-json"><span class="toc-number">21.1.</span> <span class="toc-text">test_read_hdfs.json</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#exp-log-sh"><span class="toc-number">21.2.</span> <span class="toc-text">exp_log.sh</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xxl-job-%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E4%B8%AD%E5%BF%83-%E6%96%B0%E5%A2%9E%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86"><span class="toc-number">21.3.</span> <span class="toc-text">xxl-job-任务调度中心-新增任务管理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA%E8%A1%A8%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA"><span class="toc-number">22.</span> <span class="toc-text">动态分区表导入导出</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#imp-log-sh"><span class="toc-number">22.1.</span> <span class="toc-text">imp_log.sh</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/" title="LangChain使用之Retrieval"><img src="/img/lita9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LangChain使用之Retrieval"/></a><div class="content"><a class="title" href="/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/" title="LangChain使用之Retrieval">LangChain使用之Retrieval</a><time datetime="2025-09-28T03:10:40.030Z" title="更新于 2025-09-28 11:10:40">2025-09-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/26/LangChain%E4%BD%BF%E7%94%A8%E6%A6%82%E8%BF%B0/" title="LangChain使用概述"><img src="/img/lita4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LangChain使用概述"/></a><div class="content"><a class="title" href="/2025/09/26/LangChain%E4%BD%BF%E7%94%A8%E6%A6%82%E8%BF%B0/" title="LangChain使用概述">LangChain使用概述</a><time datetime="2025-09-26T03:37:36.148Z" title="更新于 2025-09-26 11:37:36">2025-09-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/23/chromadb%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/" title="chromadb向量数据库"><img src="/img/%E4%BA%94%E6%9D%A1%E6%82%9F.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="chromadb向量数据库"/></a><div class="content"><a class="title" href="/2025/09/23/chromadb%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/" title="chromadb向量数据库">chromadb向量数据库</a><time datetime="2025-09-23T16:37:51.853Z" title="更新于 2025-09-24 00:37:51">2025-09-24</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By Yinjin Yao</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div><div class="footer_custom_text">感谢阅读</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="输入以搜索内容..." type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>