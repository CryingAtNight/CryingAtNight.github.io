<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LangChain使用之Retrieval | Yinjin Yao的博客</title><meta name="author" content="Yinjin Yao"><meta name="copyright" content="Yinjin Yao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Retrieval模块的设计意义 大模型的幻觉问题 拥有记忆后，确实扩展了AI工程的应用场景。 但是在专有领域，LLM无法学习到所有的专业知识细节，因此在 面向专业领域知识的提问时，无法给出 可靠准确的回答，甚至会“胡言乱语”，这种现象称之为 LLM的“幻觉”。 大模型生成内容的不可控，尤其是在金融和医疗领域等领域，一次金额评估的错误，一次医疗诊断的失误，哪怕只出现一次都是致命的。但，对于">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain使用之Retrieval">
<meta property="og:url" content="https://cryingatnight.github.io/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/index.html">
<meta property="og:site_name" content="Yinjin Yao的博客">
<meta property="og:description" content="Retrieval模块的设计意义 大模型的幻觉问题 拥有记忆后，确实扩展了AI工程的应用场景。 但是在专有领域，LLM无法学习到所有的专业知识细节，因此在 面向专业领域知识的提问时，无法给出 可靠准确的回答，甚至会“胡言乱语”，这种现象称之为 LLM的“幻觉”。 大模型生成内容的不可控，尤其是在金融和医疗领域等领域，一次金额评估的错误，一次医疗诊断的失误，哪怕只出现一次都是致命的。但，对于">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cryingatnight.github.io/img/lita9.jpg">
<meta property="article:published_time" content="2025-09-28T04:00:00.000Z">
<meta property="article:modified_time" content="2025-09-28T03:10:40.030Z">
<meta property="article:author" content="Yinjin Yao">
<meta property="article:tag" content="LangChain">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cryingatnight.github.io/img/lita9.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LangChain使用之Retrieval",
  "url": "https://cryingatnight.github.io/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/",
  "image": "https://cryingatnight.github.io/img/lita9.jpg",
  "datePublished": "2025-09-28T04:00:00.000Z",
  "dateModified": "2025-09-28T03:10:40.030Z",
  "author": [
    {
      "@type": "Person",
      "name": "Yinjin Yao",
      "url": "https://cryingatnight.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/headimage.png"><link rel="canonical" href="https://cryingatnight.github.io/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LangChain使用之Retrieval',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/headimage.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-flask"></i><span> 实验室</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="http://121.199.61.105/"><i class="fa-fw fas fa-q"></i><span> 豆瓣网开发</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://fuckornot.on.websim.com/"><i class="fa-fw fa fa-trophy"></i><span> 上不上AI评分系统</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://fontawesome.com/icons"><i class="fa-fw fa fa-check-circle"></i><span> font-awesome v6 图标</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/lita9.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/headimage.png" alt="Logo"><span class="site-name">Yinjin Yao的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">LangChain使用之Retrieval</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-flask"></i><span> 实验室</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener" href="http://121.199.61.105/"><i class="fa-fw fas fa-q"></i><span> 豆瓣网开发</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://fuckornot.on.websim.com/"><i class="fa-fw fa fa-trophy"></i><span> 上不上AI评分系统</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://fontawesome.com/icons"><i class="fa-fw fa fa-check-circle"></i><span> font-awesome v6 图标</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LangChain使用之Retrieval</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-09-28T04:00:00.000Z" title="发表于 2025-09-28 12:00:00">2025-09-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-28T03:10:40.030Z" title="更新于 2025-09-28 11:10:40">2025-09-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="retrieval模块的设计意义">Retrieval模块的设计意义</h1>
<h2 id="大模型的幻觉问题">大模型的幻觉问题</h2>
<p>拥有记忆后，确实扩展了AI工程的应用场景。</p>
<p>但是在专有领域，LLM无法学习到所有的专业知识细节，因此在 面向专业领域知识的提问时，无法给出 可靠准确的回答，甚至会“胡言乱语”，这种现象称之为 <strong>LLM的“幻觉”</strong>。</p>
<p>大模型生成内容的不可控，尤其是在金融和医疗领域等领域，<strong>一次金额评估的错误，一次医疗诊断的失误，哪怕只出现一次都是致命的</strong>。但，对于非专业人士来说可能难以辨识。<strong>目前还没有能够百分之百解决这种情况的方案。</strong></p>
<p><strong>当前大家普遍达成共识的一个方案</strong>： 首先，为大模型提供一定的上下文信息，让其输出会变得更稳定。 其次，利用本章的RAG，将检索出来的 文档和提示词输送给大模型，生成更可靠的答案。</p>
<h2 id="rag的优缺点">RAG的优缺点</h2>
<ul>
<li>RAG的优点
<ol type="1">
<li>相比提示词工程，RAG有 <strong>更丰富的上下文和数据样本</strong>，可以不需要用户提供过多的背景描述，就能生 成比较符合用户预期的答案。</li>
<li>相比于模型微调，RAG可以提升问答内容的 <strong>时效性和 可靠性</strong></li>
<li>在一定程度上保护了业务数据的 隐私性。</li>
</ol></li>
<li>RAG的缺点
<ol type="1">
<li>由于每次问答都涉及外部系统数据检索，因此RAG的 <strong>响应时延相对较高</strong>。</li>
<li>引用的外部知识数据会 <strong>消耗大量的模型Token</strong> 资源。</li>
</ol></li>
</ul>
<h2 id="retrieval流程">Retrieval流程</h2>
<p><img src="file-20250926111132475.png" /></p>
<h3 id="环节1source数据源">环节1：Source（数据源）</h3>
<p>指的是RAG架构中所外挂的知识库。这里有三点说明： 1. 原始数据源类型多样：如：视频、图片、文本、代码、文档等 2. 形式的多样性： - 可以是上百个.csv文件，可以是上千个.json文件，也可以是上万个.pdf文件 - 可以是某一个业务流程外放的API，可以是某个网站的实时数据等</p>
<h3 id="环节2load加载">环节2：Load（加载）</h3>
<p>文档加载器（Document Loaders）负责将来自不同数据源的非结构化文本，加载到 <strong>内存</strong>成为(Document)对象 。</p>
<p>文档对象包含 <strong>文档内容</strong>和相关<strong>元数据信息</strong> ，例如TXT、CSV、HTML、JSON、Markdown、PDF，甚至 YouTube 视频转录等。 <img src="file-20250926111455347.png" /></p>
<p>文档加载器还支持“ <strong>延迟加载</strong>”模式，以缓解处理大文件时的内存压力。 文档加载器的编程接口使用起来非常简单，以下给出加载TXT格式文档的例子。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.document_loadersimport TextLoader </span><br><span class="line"></span><br><span class="line">text_loader = TextLoader( <span class="string">&quot;./test.txt&quot;</span> ) </span><br><span class="line"></span><br><span class="line">docs = text_loader.load() <span class="comment">#返回List列表(Document对象) </span></span><br><span class="line"><span class="built_in">print</span> (docs)</span><br></pre></td></tr></table></figure>
<h3 id="环节3transform转换">环节3：Transform（转换）</h3>
<p><strong>文档转换器(Document Transformers)</strong> 负责对加载的文档进行转换和处理，以便更好地适应下游任务的 需求。</p>
<p>文档转换器提供了一致的接口（工具）来操作文档，主要包括以下几类： - <strong>文本拆分器(Text Splitters)</strong> ：将长文本拆分成语义上相关的小块，以适应语言模型的上下文窗口限 制。 - <strong>冗余过滤器(Redundancy Filters)</strong> ：识别并过滤重复的文档。 - 元数据提取器(Metadata Extractors) ：从文档中提取标题、语调等结构化元数据。 - <strong>多语言转换器(Multi-lingual Transformers)</strong> ：实现文档的机器翻译。 - <strong>对话转换器(Conversational Transformers)</strong> ：将非结构化对话转换为问答格式的文档。</p>
<p>总的来说，文档转换器是 LangChain 处理管道中非常重要的一个组件，它丰富了框架对文档的表示和 操作能力。</p>
<h4 id="环节3.1text-splitting文档拆分">环节3.1：Text Splitting（文档拆分）</h4>
<ul>
<li>向量化并存入数据库中。 拆分/分块的必要性：前一个环节加载后的文档对象可以直接传入文档拆分器进行拆分，而文档切块 后才能</li>
<li>文档拆分器的多样性：LangChain提供了丰富的文档拆分器，不仅能够切分普通文本，还能切分 Markdown、JSON、HTML、代码等特殊格式的文本。</li>
<li>拆分/分块的挑战性：实际拆分操作中需要处理许多细节问题， 需要采用不同的分块策略。
<ul>
<li>可以按照 数据类型进行切片处理，比如针对 不同类型的文本、 不同的使用场景都 文本类数据，可以直接按照字符、段落进行切 片；代 码类数据则需要进一步细分以保证代码的功能性；</li>
<li>可以直接根据 token 进行切片处理</li>
</ul></li>
</ul>
<p><strong>在构建RAG应用程序的整个流程中，拆分/分块是最具挑战性的环节之一，它显著影响检索效果</strong>。目前 还没有通用的方法可以明确指出哪一种分块策略最为有效。不同的使用场景和数据类型都会影响分块策 略的选择。</p>
<h3 id="环节4embed嵌入">环节4：Embed（嵌入）</h3>
<p>文档嵌入模型（Text Embedding Models）负责将 <strong>文本</strong>转换为 <strong>向量表示</strong>，即<strong>模型赋予了文本计算机可 理解的数值表示</strong>，使文本可用于向量空间中的各种运算，大大拓展了文本分析的可能性，是自然语言处 理领域非常重要的技术。</p>
<p>举例： <img src="file-20250927222436889.png" /> - 实现原理：通过 <strong>特定算法</strong>（如Word2Vec）将语义信息编码为固定维度的向量，具体算法细节需后 续深入。 - 关键特性：<strong>相似的词在向量空间中距离相近</strong>，例如“猫”和“犬”的向量夹角小于“猫”和“汽车”。 <img src="file-20250927222545025.png" /></p>
<p>文本嵌入为 LangChain 中的问答、检索、推荐等功能提供了重要支持。具体为： - <strong>语义匹配</strong>：通过计算两个文本的向量余弦相似度，判断它们在语义上的相似程度，实现语义匹配。 - <strong>文本检索</strong>：通过计算不同文本之间的向量相似度，可以实现语义搜索，找到向量空间中最相似的文 本。 - <strong>信息推荐</strong>：根据用户的历史记录或兴趣嵌入生成用户向量，计算不同信息的向量与用户向量的相似 度，推荐相似的信息。 - <strong>知识挖掘</strong>：可以通过聚类、降维等手段分析文本向量的分布，发现文本之间的潜在关联，挖掘知 识。 - <strong>自然语言处理</strong>：将词语、句子等表示为稠密向量，为神经网络等下游任务提供输入。</p>
<h3 id="环节5store存储">环节5：Store（存储）</h3>
<p>LangChain 还支持把文本嵌入存储到向量存储或临时缓存，以避免需要重新计算它们。这里就出现了数 据库，支持这些嵌入的高效 <strong>存储和搜索</strong>的需求。</p>
<p><img src="file-20250927222756909.png" /></p>
<h3 id="环节6retrieve检索">环节6：Retrieve（检索）</h3>
<p>检索器（Retrievers）是一种用于 <strong>响应非结构化查询</strong>的接口，它可以返回符合查询要求的文档。</p>
<p>LangChain 提供了一些常用的检索器，如 <strong>向量检索器、 文档检索器、 网站研究检索器</strong>等。</p>
<p>通过配置不同的检索器，LangChain 可以灵活地平衡检索的精度、召回率与效率。检索结果将为后续的 问答生成提供信息支持，以产生更加准确和完整的回答。</p>
<h1 id="文档加载器-document-loaders">文档加载器 Document Loaders</h1>
<p>LangChain的设计：对于<strong>Source</strong>中多种不同的数据源，我们可以用一种统一的形式读取、调用。</p>
<h2 id="加载txt">加载txt</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> TextLoader, PyPDFLoader  </span><br><span class="line">   </span><br><span class="line"><span class="comment"># 指明txt文档的路径  </span></span><br><span class="line">file_path = <span class="string">&quot;./asset/load/01-langchain-utf-8.txt&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建一个TextLoader的实例  </span></span><br><span class="line">text_loader = TextLoader(  </span><br><span class="line">    file_path=file_path,  </span><br><span class="line">    encoding=<span class="string">&quot;utf-8&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 调用load()，返回一个list[Document]  </span></span><br><span class="line">docs = text_loader.load()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(docs)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs))  <span class="comment"># 查看列表中元素的个数‘  </span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(docs[<span class="number">0</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/01-langchain-utf-8.txt&#x27;</span>&#125;, page_content=<span class="string">&#x27;LangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务&#x27;</span>)]</span><br><span class="line"></span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">page_content=<span class="string">&#x27;LangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务&#x27;</span> metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/01-langchain-utf-8.txt&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>Documment对象中有两个重要的属性： - page_content：真正的文档内容 - metadata：文档内容的原数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示Document对象的元数据  </span></span><br><span class="line"><span class="built_in">print</span>(docs[<span class="number">0</span>].metadata)  </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&#123;&#x27;source&#x27;: &#x27;./asset/load/01-langchain-utf-8.txt&#x27;&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>  </span><br><span class="line"><span class="comment"># 显示文档中的内容信息  </span></span><br><span class="line"><span class="built_in">print</span>(docs[<span class="number">0</span>].page_content)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">LangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>结果：</p>
<h2 id="加载pdf">加载pdf</h2>
<h3 id="举例1"><strong>举例1：</strong></h3>
<p>LangChain加载PDF文件使用的是pypdf，先安装 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pypdf</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的依赖 PyPDFLoader()</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders.pdf <span class="keyword">import</span> PyPDFLoader  </span><br><span class="line">  </span><br><span class="line">pdf_loader = PyPDFLoader(  </span><br><span class="line">    file_path=<span class="string">&quot;./asset/load/02-load.pdf&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = pdf_loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(docs)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs))</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[Document(metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;Microsoft® Word 2019&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;Microsoft® Word 2019&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2025-06-20T17:18:19+08:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2025-06-20T17:18:19+08:00&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/02-load.pdf&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;page&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;1&#x27;</span>&#125;, page_content=<span class="string">&#x27;&quot;他的车，他的命！ 他忽然想起来，一年，二年，至少有三四年；一滴汗，两滴汗，不\n知道多少万滴汗，才挣出那辆车。从风里雨里的咬牙，从饭里茶里的自苦，才赚出那辆车。\n那辆车是他的一切挣扎与困苦的总结果与报酬，像身经百战的武士的一颗徽章。……他老想\n着远远的一辆车，可以使他自由，独立，像自己的手脚的那么一辆车。&quot; \n \n&quot;他吃，他喝，他嫖，他赌，他懒，他狡猾， 因为他没了心，他的心被人家摘了去。他\n只剩下那个高大的肉架子，等着溃烂，预备着到乱死岗子去。……体面的、要强的、好梦想\n的、利己的、个人的、健壮的、伟大的祥子，不知陪着人家送了多少回殡；不知道何时何地\n会埋起他自己来， 埋起这堕落的、 自私的、 不幸的、 社会病胎里的产儿， 个人主义的末路鬼！\n&quot;&#x27;</span>)]</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>同样的： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">type</span> (pages[<span class="number">0</span>]) <span class="comment">#langchain_core.documents.base.Document</span></span><br><span class="line"></span><br><span class="line">pages[<span class="number">0</span>].page_content <span class="comment">#只获取本页内容</span></span><br><span class="line"> </span><br><span class="line">pages[<span class="number">0</span>].metadata <span class="comment"># &#123;...,&#x27;source&#x27;: &#x27;./asset/load/load.pdf&#x27;,.., &#x27;page&#x27;: 0&#125;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="举例2"><strong>举例2：</strong></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders.pdf <span class="keyword">import</span> PyPDFLoader  </span><br><span class="line">  </span><br><span class="line">pdf_loader = PyPDFLoader(  </span><br><span class="line">    file_path=<span class="string">&quot;https://arxiv.org/pdf/2302.03803&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = pdf_loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs))  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(doc)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br></pre></td><td class="code"><pre><span class="line">8</span><br><span class="line">page_content=<span class="string">&#x27;arXiv:2302.03803v1  [math.AG]  7 Feb 2023</span></span><br><span class="line"><span class="string">A WEAK (k, k )-LEFSCHETZ THEOREM FOR PROJECTIVE</span></span><br><span class="line"><span class="string">TORIC ORBIFOLDS</span></span><br><span class="line"><span class="string">William D. Montoya</span></span><br><span class="line"><span class="string">Instituto de Matem´ atica, Estat´ ıstica e Computa¸ c˜ ao Cient´ ıﬁca,</span></span><br><span class="line"><span class="string">Universidade Estadual de Campinas (UNICAMP),</span></span><br><span class="line"><span class="string">Rua S´ ergio Buarque de Holanda 651, 13083-859, Campinas, SP , Brazil</span></span><br><span class="line"><span class="string">February 9, 2023</span></span><br><span class="line"><span class="string">Abstract</span></span><br><span class="line"><span class="string">Firstly we show a generalization of the (1,1)-Lefschetz theorem for projective</span></span><br><span class="line"><span class="string">toric orbifolds and secondly we prove that on 2k-dimensional quasi-smooth hyper-</span></span><br><span class="line"><span class="string">surfaces coming from quasi-smooth intersection surfaces, under the Cayley trick,</span></span><br><span class="line"><span class="string">every rational (k, k)-cohomology class is algebraic, i.e., the Hodge conjectureholds</span></span><br><span class="line"><span class="string">on them.</span></span><br><span class="line"><span class="string">1 Introduction</span></span><br><span class="line"><span class="string">In [3] we proved that, under suitable conditions, on a very general codimension s quasi-</span></span><br><span class="line"><span class="string">smooth intersection subvariety X in a projective toric orbifold Pd</span></span><br><span class="line"><span class="string">Σ with d +s = 2(k +1)</span></span><br><span class="line"><span class="string">the Hodge conjecture holds, that is, every (p, p )-cohomology class, under the Poincar´ e</span></span><br><span class="line"><span class="string">duality is a rational linear combination of fundamental classes of alge braic subvarieties</span></span><br><span class="line"><span class="string">of X. The proof of the above-mentioned result relies, for p ≠ d +1 − s, on a Lefschetz</span></span><br><span class="line"><span class="string">Date: February 9, 2023</span></span><br><span class="line"><span class="string">2020 Mathematics Subject Classiﬁcation: 14C30, 14M10, 14J70, 14M25</span></span><br><span class="line"><span class="string">Keywords: (1,1)- Lefschetz theorem, Hodge conjecture, toric varieties, complete intersection</span></span><br><span class="line"><span class="string">Email: wmontoya@ime.unicamp.br</span></span><br><span class="line"><span class="string">1&#x27;</span> metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;dvips + GPL Ghostscript GIT PRERELEASE 9.22&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;LaTeX with hyperref&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;keywords&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;https://arxiv.org/pdf/2302.03803&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: 8, <span class="string">&#x27;page&#x27;</span>: 0, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;1&#x27;</span>&#125;</span><br><span class="line">page_content=<span class="string">&#x27;theorem ([7]) and the Hard Lefschetz theorem for projective orb ifolds ([11]). When p =</span></span><br><span class="line"><span class="string">d +1 −s the proof relies on the Cayley trick, a trick which associates to X a quasi-smooth</span></span><br><span class="line"><span class="string">hypersurface Y in a projective vector bundle, and the Cayley Proposition (4.3) which</span></span><br><span class="line"><span class="string">gives an isomorphism of some primitive cohomologies (4.2) of X and Y . The Cayley</span></span><br><span class="line"><span class="string">trick, following the philosophy of Mavlyutov in [7], reduces results kn own for quasi-smooth</span></span><br><span class="line"><span class="string">hypersurfaces to quasi-smooth intersection subvarieties. The id ea in this paper goes the</span></span><br><span class="line"><span class="string">other way around, we translate some results for quasi-smooth int ersection subvarieties to</span></span><br><span class="line"><span class="string">quasi-smooth hypersurfaces, mainly the (1, 1)-Lefschetz theorem.</span></span><br><span class="line"><span class="string">Acknowledgement. I thank Prof. Ugo Bruzzo and Tiago Fonseca for useful discus-</span></span><br><span class="line"><span class="string">sions. I also acknowledge support from FAPESP postdoctoral gra nt No. 2019/23499-7.</span></span><br><span class="line"><span class="string">2 Preliminaries and Notation</span></span><br><span class="line"><span class="string">2.1 Toric varieties</span></span><br><span class="line"><span class="string">Let M be a free abelian group of rank d, let N =Hom(M, Z ), and NR =N ⊗Z R.</span></span><br><span class="line"><span class="string">Deﬁnition 2.1. • A convex subset σ ⊂NR is a rational k-dimensional simplicial cone</span></span><br><span class="line"><span class="string">if there exist k linearly independent primitive elements e1, . . . , e k ∈ N such that σ =</span></span><br><span class="line"><span class="string">&#123;µ1e1 +⋯+ µkek&#125;.</span></span><br><span class="line"><span class="string">• The generators ei are integral if for every i and any nonnegative rational number µ</span></span><br><span class="line"><span class="string">the product µei is in N only if µ is an integer.</span></span><br><span class="line"><span class="string">• Given two rational simplicial cones σ, σ′ one says that σ′ is a face of σ (σ′ &lt; σ) if</span></span><br><span class="line"><span class="string">the set of integral generators of σ′ is a subset of the set of integral generators of σ.</span></span><br><span class="line"><span class="string">• A ﬁnite set Σ =&#123;σ1, . . . , σ t&#125; of rational simplicial cones is called a rational simplicia l</span></span><br><span class="line"><span class="string">complete d-dimensional fan if:</span></span><br><span class="line"><span class="string">1. all faces of cones in Σ are in Σ ;</span></span><br><span class="line"><span class="string">2. if σ, σ ′ ∈Σ then σ ∩σ′ &lt;σ and σ ∩σ′ &lt;σ′;</span></span><br><span class="line"><span class="string">3. NR =σ1 ∪⋅⋅⋅∪ σt.</span></span><br><span class="line"><span class="string">A rational simplicial complete d-dimensional fan Σ deﬁnes a d-dimensional toric variety</span></span><br><span class="line"><span class="string">Pd</span></span><br><span class="line"><span class="string">Σ having only orbifold singularities which we assume to be projective. Mo reover, T ∶=</span></span><br><span class="line"><span class="string">N ⊗Z C∗ ≃ (C∗)d is the torus action on Pd</span></span><br><span class="line"><span class="string">Σ . We denote by Σ (i) the i-dimensional cones</span></span><br><span class="line"><span class="string">2&#x27;</span> metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;dvips + GPL Ghostscript GIT PRERELEASE 9.22&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;LaTeX with hyperref&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;keywords&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;https://arxiv.org/pdf/2302.03803&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: 8, <span class="string">&#x27;page&#x27;</span>: 1, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;2&#x27;</span>&#125;</span><br><span class="line">page_content=<span class="string">&#x27;of Σ and each ρ ∈Σ corresponds to an irreducible T -invariant Weil divisor Dρ on Pd</span></span><br><span class="line"><span class="string">Σ . Let</span></span><br><span class="line"><span class="string">Cl(Σ ) be the group of Weil divisors on Pd</span></span><br><span class="line"><span class="string">Σ module rational equivalences.</span></span><br><span class="line"><span class="string">The total coordinate ring of Pd</span></span><br><span class="line"><span class="string">Σ is the polynomial ring S = C[xρ /divides.alt0 ρ ∈ Σ (1)], S has the</span></span><br><span class="line"><span class="string">Cl(Σ )-grading, a Weil divisor D =∑ρ∈Σ (1) uρDρ determines the monomial xu ∶=∏ρ∈Σ (1) xuρ</span></span><br><span class="line"><span class="string">ρ ∈</span></span><br><span class="line"><span class="string">S and conversely deg (xu)=[D]∈Cl(Σ ).</span></span><br><span class="line"><span class="string">For a cone σ ∈ Σ, ˆσ is the set of 1-dimensional cone in Σ that are not contained in σ</span></span><br><span class="line"><span class="string">and xˆσ ∶=∏ρ∈ˆσ xρ is the associated monomial in S.</span></span><br><span class="line"><span class="string">Deﬁnition 2.2. The irrelevant ideal of Pd</span></span><br><span class="line"><span class="string">Σ is the monomial ideal BΣ ∶=&lt; xˆσ /divides.alt0 σ ∈ Σ &gt; and</span></span><br><span class="line"><span class="string">the zero locus Z(Σ )∶=V(BΣ ) in the aﬃne space Ad ∶=Spec(S) is the irrelevant locus.</span></span><br><span class="line"><span class="string">Proposition 2.3 (Theorem 5.1.11 [5]) . The toric variety Pd</span></span><br><span class="line"><span class="string">Σ is a categorical quotient</span></span><br><span class="line"><span class="string">Ad ∖Z(Σ ) by the group Hom(Cl(Σ ), C∗) and the group action is induced by the Cl(Σ )-</span></span><br><span class="line"><span class="string">grading of S.</span></span><br><span class="line"><span class="string">2.2 Orbifolds</span></span><br><span class="line"><span class="string">Now we give a brief introduction to complex orbifolds and we mention th e needed theorems</span></span><br><span class="line"><span class="string">for the next section. Namely: de Rham theorem and Dolbeault theor em for complex</span></span><br><span class="line"><span class="string">orbifolds.</span></span><br><span class="line"><span class="string">Deﬁnition 2.4. A complex orbifold of complex dimension d is a singular complex space</span></span><br><span class="line"><span class="string">whose singularities are locally isomorphic to quotient sin gularities Cd/slash.left G, for ﬁnite sub-</span></span><br><span class="line"><span class="string">groups G ⊂Gl(d, C).</span></span><br><span class="line"><span class="string">Deﬁnition 2.5. A diﬀerential form on a complex orbifold Z is deﬁned locally at z ∈Z as</span></span><br><span class="line"><span class="string">a G-invariant diﬀerential form on Cd where G ⊂ Gl(d, C) and Z is locally isomorphic to</span></span><br><span class="line"><span class="string">Cd/slash.left G around z.</span></span><br><span class="line"><span class="string">Roughly speaking the local geometry of orbifolds reduces to local G-invariant geometry.</span></span><br><span class="line"><span class="string">We have a complex of diﬀerential forms (A●(Z), d )and a double complex (A●, ●(Z), ∂, ¯∂)</span></span><br><span class="line"><span class="string">of bigraded diﬀerential forms which deﬁne the de Rham and the Dolbe ault cohomology</span></span><br><span class="line"><span class="string">groups (for a ﬁxed p ∈N) respectively:</span></span><br><span class="line"><span class="string">H●</span></span><br><span class="line"><span class="string">dR(Z, C)∶= kerd</span></span><br><span class="line"><span class="string">im d and Hp, ●(Z, ¯∂)∶= ker ¯∂</span></span><br><span class="line"><span class="string">im ¯∂</span></span><br><span class="line"><span class="string">Theorem 2.6 (Theorem 3.4.4 in [4] and Theorem 1.2 in [1] ) . Let Z be a compact complex</span></span><br><span class="line"><span class="string">orbifold. There are natural isomorphisms:</span></span><br><span class="line"><span class="string">3&#x27;</span> metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;dvips + GPL Ghostscript GIT PRERELEASE 9.22&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;LaTeX with hyperref&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;keywords&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;https://arxiv.org/pdf/2302.03803&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: 8, <span class="string">&#x27;page&#x27;</span>: 2, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;3&#x27;</span>&#125;</span><br><span class="line">page_content=<span class="string">&#x27;• H●</span></span><br><span class="line"><span class="string">dR(Z, C)≃H●(Z, C)</span></span><br><span class="line"><span class="string">• Hp, ●(Z, ¯∂)≃H●(X, Ω p</span></span><br><span class="line"><span class="string">Z )</span></span><br><span class="line"><span class="string">3 (1,1)-Lefschetz theorem for projective toric orbifolds</span></span><br><span class="line"><span class="string">Deﬁnition 3.1. A subvariety X ⊂Pd</span></span><br><span class="line"><span class="string">Σ is quasi-smooth if V(IX )⊂A#Σ (1) is smooth outside</span></span><br><span class="line"><span class="string">Z(Σ ).</span></span><br><span class="line"><span class="string">Example 3.2. Quasi-smooth hypersurfaces or more generally quasi-smooth inte rsection sub-</span></span><br><span class="line"><span class="string">varieties are quasi-smooth subvarieties (see [2] or [7] for more det ails).</span></span><br><span class="line"><span class="string">△</span></span><br><span class="line"><span class="string">Remark 3.3. Quasi-smooth subvarieties are suborbifolds of Pd</span></span><br><span class="line"><span class="string">Σ in the sense of Satake in [8].</span></span><br><span class="line"><span class="string">Intuitively speaking they are subvarieties whose only singularities co me from the ambient</span></span><br><span class="line"><span class="string">space.</span></span><br><span class="line"><span class="string">△</span></span><br><span class="line"><span class="string">Theorem 3.4. Let X ⊂ Pd</span></span><br><span class="line"><span class="string">Σ be a quasi-smooth subvariety. Then every (1, 1)-cohomology</span></span><br><span class="line"><span class="string">class λ ∈H1, 1(X)∩H2(X, Z) is algebraic</span></span><br><span class="line"><span class="string">Proof. From the exponential short exact sequence</span></span><br><span class="line"><span class="string">0 →Z →OX →O∗</span></span><br><span class="line"><span class="string">X →0</span></span><br><span class="line"><span class="string">we have a long exact sequence in cohomology</span></span><br><span class="line"><span class="string">H1(O∗</span></span><br><span class="line"><span class="string">X )→H2(X, Z) →H2(OX )≃H0, 2(X)</span></span><br><span class="line"><span class="string">where the last isomorphisms is due to Steenbrink in [9]. Now, it is enoug h to prove the</span></span><br><span class="line"><span class="string">commutativity of the next diagram</span></span><br><span class="line"><span class="string">H2(X, Z) → → </span></span><br><span class="line"><span class="string">↓ ↓ </span></span><br><span class="line"><span class="string">H2(X, OX )</span></span><br><span class="line"><span class="string">≃ Dolbeault</span></span><br><span class="line"><span class="string">↓ ↓ </span></span><br><span class="line"><span class="string">H2(X, C)</span></span><br><span class="line"><span class="string">de Rham ≃</span></span><br><span class="line"><span class="string">↓ ↓ </span></span><br><span class="line"><span class="string">H2</span></span><br><span class="line"><span class="string">dR(X, C) → → H0, 2</span></span><br><span class="line"><span class="string">¯∂ (X)</span></span><br><span class="line"><span class="string">4&#x27;</span> metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;dvips + GPL Ghostscript GIT PRERELEASE 9.22&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;LaTeX with hyperref&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;keywords&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;https://arxiv.org/pdf/2302.03803&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: 8, <span class="string">&#x27;page&#x27;</span>: 3, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;4&#x27;</span>&#125;</span><br><span class="line">page_content=<span class="string">&#x27;The key points are the de Rham and Dolbeault’s isomorphisms for orbif olds. The rest</span></span><br><span class="line"><span class="string">of the proof follows as the (1, 1)-Lefschetz theorem in [6].</span></span><br><span class="line"><span class="string">Remark 3.5. For k = 1 and Pd</span></span><br><span class="line"><span class="string">Σ as the projective space, we recover the classical (1, 1)-</span></span><br><span class="line"><span class="string">Lefschetz theorem.</span></span><br><span class="line"><span class="string">△</span></span><br><span class="line"><span class="string">By the Hard Lefschetz Theorem for projective orbifolds (see [11] for details) we get an</span></span><br><span class="line"><span class="string">isomorphism of cohomologies :</span></span><br><span class="line"><span class="string">H●(X, Q) ≃H2 dim X−●(X, Q)</span></span><br><span class="line"><span class="string">given by the Lefschetz morphism and since it is a morphism of Hodge st ructures, we have:</span></span><br><span class="line"><span class="string">H1, 1(X, Q) ≃Hdim X−1, dim X−1(X, Q)</span></span><br><span class="line"><span class="string">For X as before:</span></span><br><span class="line"><span class="string">Corollary 3.6. If the dimension of X is 1, 2 or 3. The Hodge conjecture holds on X.</span></span><br><span class="line"><span class="string">Proof. If the dimCX = 1 the result is clear by the Hard Lefschetz theorem for projective</span></span><br><span class="line"><span class="string">orbifolds. The dimension 2 and 3 cases are covered by Theorem 3.5 an d the Hard Lefschetz.</span></span><br><span class="line"><span class="string">theorem.4 Cayley trick and Cayley proposition</span></span><br><span class="line"><span class="string">The Cayley trick is a way to associate to a quasi-smooth intersection subvariety a quasi-</span></span><br><span class="line"><span class="string">smooth hypersurface. Let L1, . . . , L s be line bundles on Pd</span></span><br><span class="line"><span class="string">Σ and let π ∶ P(E) → Pd</span></span><br><span class="line"><span class="string">Σ be the</span></span><br><span class="line"><span class="string">projective space bundle associated to the vector bundle E =L1 ⊕⋯⊕ Ls. It is known that</span></span><br><span class="line"><span class="string">P(E) is a (d +s −1)-dimensional simplicial toric variety whose fan depends on the degre es</span></span><br><span class="line"><span class="string">of the line bundles and the fan Σ. Furthermore, if the Cox ring, witho ut considering the</span></span><br><span class="line"><span class="string">grading, of Pd</span></span><br><span class="line"><span class="string">Σ is C[x1, . . . , x m] then the Cox ring of P(E) is</span></span><br><span class="line"><span class="string">C[x1, . . . , x m, y 1, . . . , y s]</span></span><br><span class="line"><span class="string">Moreover for X a quasi-smooth intersection subvariety cut oﬀ by f1, . . . , f s with deg(fi)=</span></span><br><span class="line"><span class="string">[Li] we relate the hypersurface Y cut oﬀ by F = y1f1 +⋅⋅⋅+ ysfs which turns out to be</span></span><br><span class="line"><span class="string">quasi-smooth. For more details see Section 2 in [7].</span></span><br><span class="line"><span class="string">5&#x27;</span> metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;dvips + GPL Ghostscript GIT PRERELEASE 9.22&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;LaTeX with hyperref&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;keywords&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;https://arxiv.org/pdf/2302.03803&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: 8, <span class="string">&#x27;page&#x27;</span>: 4, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;5&#x27;</span>&#125;</span><br><span class="line">page_content=<span class="string">&#x27;We will denote P(E) as Pd+s−1</span></span><br><span class="line"><span class="string">Σ ,X to keep track of its relation with X and Pd</span></span><br><span class="line"><span class="string">Σ .</span></span><br><span class="line"><span class="string">The following is a key remark.</span></span><br><span class="line"><span class="string">Remark 4.1. There is a morphism ι∶X →Y ⊂Pd+s−1</span></span><br><span class="line"><span class="string">Σ ,X . Moreover every point z ∶=(x, y )∈Y</span></span><br><span class="line"><span class="string">with y ≠ 0 has a preimage. Hence for any subvariety W = V(IW ) ⊂ X ⊂ Pd</span></span><br><span class="line"><span class="string">Σ there exists</span></span><br><span class="line"><span class="string">W ′ ⊂Y ⊂Pd+s−1</span></span><br><span class="line"><span class="string">Σ ,X such that π(W ′)=W , i.e., W ′ =&#123;z =(x, y ) /divides.alt0 x ∈W &#125;.</span></span><br><span class="line"><span class="string">△</span></span><br><span class="line"><span class="string">For X ⊂ Pd</span></span><br><span class="line"><span class="string">Σ a quasi-smooth intersection variety the morphism in cohomology indu ced</span></span><br><span class="line"><span class="string">by the inclusion i∗ ∶Hd−s(Pd</span></span><br><span class="line"><span class="string">Σ , C)→Hd−s(X, C) is injective by Proposition 1.4 in [7].</span></span><br><span class="line"><span class="string">Deﬁnition 4.2. The primitive cohomology of Hd−s</span></span><br><span class="line"><span class="string">prim(X)is the quotient Hd−s(X, C)/slash.left i∗(Hd−s(Pd</span></span><br><span class="line"><span class="string">Σ , C))</span></span><br><span class="line"><span class="string">and Hd−s</span></span><br><span class="line"><span class="string">prim(X, Q) with rational coeﬃcients.</span></span><br><span class="line"><span class="string">Hd−s(Pd</span></span><br><span class="line"><span class="string">Σ , C) and Hd−s(X, C) have pure Hodge structures, and the morphism i∗ is com-</span></span><br><span class="line"><span class="string">patible with them, so that Hd−s</span></span><br><span class="line"><span class="string">prim(X) gets a pure Hodge structure.</span></span><br><span class="line"><span class="string">The next Proposition is the Cayley proposition.</span></span><br><span class="line"><span class="string">Proposition 4.3. [Proposition 2.3 in [3] ] Let X =X1 ∩⋅⋅⋅∩ Xs be a quasi-smooth intersec-</span></span><br><span class="line"><span class="string">tion subvariety in Pd</span></span><br><span class="line"><span class="string">Σ cut oﬀ by homogeneous polynomials f1 . . . f s. Then for p ≠ d+s−1</span></span><br><span class="line"><span class="string">2 , d+s−3</span></span><br><span class="line"><span class="string">2</span></span><br><span class="line"><span class="string">Hp−1,d +s−1−p</span></span><br><span class="line"><span class="string">prim (Y )≃Hp−s,d −p</span></span><br><span class="line"><span class="string">prim (X).</span></span><br><span class="line"><span class="string">Corollary 4.4. If d +s =2(k +1),</span></span><br><span class="line"><span class="string">Hk+1−s,k +1−s</span></span><br><span class="line"><span class="string">prim (X)≃Hk,k</span></span><br><span class="line"><span class="string">prim(Y )</span></span><br><span class="line"><span class="string">Remark 4.5. The above isomorphisms are also true with rational coeﬃcients since H●(X, C) =</span></span><br><span class="line"><span class="string">H●(X, Q)⊗Q C. See the beginning of Section 7.1 in [10] for more details.</span></span><br><span class="line"><span class="string">△</span></span><br><span class="line"><span class="string">5 Main result</span></span><br><span class="line"><span class="string">Theorem 5.1. Let Y =&#123;F =y1f1 +⋯+ ykfk =0&#125;⊂P2k+1</span></span><br><span class="line"><span class="string">Σ ,X be the quasi-smooth hypersurface</span></span><br><span class="line"><span class="string">associated to the quasi-smooth intersection surface X = Xf1 ∩⋅⋅⋅∩ Xfk ⊂ Pk+2</span></span><br><span class="line"><span class="string">Σ . Then on Y</span></span><br><span class="line"><span class="string">the Hodge conjecture holds.</span></span><br><span class="line"><span class="string">Proof. If Hk,k</span></span><br><span class="line"><span class="string">prim(X, Q) = 0 we are done. So let us assume Hk,k</span></span><br><span class="line"><span class="string">prim(X, Q) ≠ 0. By the Cayley</span></span><br><span class="line"><span class="string">proposition Hk,k</span></span><br><span class="line"><span class="string">prim(Y, Q) ≃ H1, 1</span></span><br><span class="line"><span class="string">prim(X, Q) and by the (1, 1)-Lefschetz theorem for projective</span></span><br><span class="line"><span class="string">6&#x27;</span> metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;dvips + GPL Ghostscript GIT PRERELEASE 9.22&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;LaTeX with hyperref&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;keywords&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;https://arxiv.org/pdf/2302.03803&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: 8, <span class="string">&#x27;page&#x27;</span>: 5, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;6&#x27;</span>&#125;</span><br><span class="line">page_content=<span class="string">&#x27;toric orbifolds there is a non-zero algebraic basis λC1 , . . . , λ Cn with rational coeﬃcients of</span></span><br><span class="line"><span class="string">H1, 1</span></span><br><span class="line"><span class="string">prim(X, Q), that is, there are n ∶=h1, 1</span></span><br><span class="line"><span class="string">prim(X, Q) algebraic curves C1, . . . , C n in X such that</span></span><br><span class="line"><span class="string">under the Poincar´ e duality the class in homology [Ci] goes to λCi , [Ci] ↦ λCi . Recall</span></span><br><span class="line"><span class="string">that the Cox ring of Pk+2 is contained in the Cox ring of P2k+1</span></span><br><span class="line"><span class="string">Σ ,X without considering the</span></span><br><span class="line"><span class="string">grading. Considering the grading we have that if α ∈ Cl(Pk+2</span></span><br><span class="line"><span class="string">Σ ) then (α, 0) ∈ Cl(P2k+1</span></span><br><span class="line"><span class="string">Σ ,X ). So</span></span><br><span class="line"><span class="string">the polynomials deﬁning Ci ⊂ Pk+2</span></span><br><span class="line"><span class="string">Σ can be interpreted in P2k+1</span></span><br><span class="line"><span class="string">X, Σ but with diﬀerent degree.</span></span><br><span class="line"><span class="string">Moreover, by Remark 4.1 each Ci is contained in Y = &#123;F = y1f1 + ⋯ + ykfk = 0&#125; and</span></span><br><span class="line"><span class="string">furthermore it has codimension k.</span></span><br><span class="line"><span class="string">Claim: &#123;λCi &#125;n</span></span><br><span class="line"><span class="string">i=1 is a basis of Hk,k</span></span><br><span class="line"><span class="string">prim(Y, Q).</span></span><br><span class="line"><span class="string">It is enough to prove that λCi is diﬀerent from zero in Hk,k</span></span><br><span class="line"><span class="string">prim(Y, Q) or equivalently that the</span></span><br><span class="line"><span class="string">cohomology classes &#123;λCi &#125;n</span></span><br><span class="line"><span class="string">i=1 do not come from the ambient space. By contradiction, let us</span></span><br><span class="line"><span class="string">assume that there exists a j and C ⊂P2k+1</span></span><br><span class="line"><span class="string">Σ ,X such that λC ∈Hk,k (P2k+1</span></span><br><span class="line"><span class="string">Σ ,X , Q) with i∗(λC )=λCj</span></span><br><span class="line"><span class="string">or in terms of homology there exists a (k +2)-dimensional algebraic subvariety V ⊂ P2k+1</span></span><br><span class="line"><span class="string">Σ ,X</span></span><br><span class="line"><span class="string">such that V ∩Y = Cj so they are equal as a homology class of P2k+1</span></span><br><span class="line"><span class="string">Σ ,X ,i.e., [V ∩Y ] = [Cj] .</span></span><br><span class="line"><span class="string">It is easy to check that π(V )∩X =Cj as a subvariety of Pk+2</span></span><br><span class="line"><span class="string">Σ where π ∶ (x, y )↦x. Hence</span></span><br><span class="line"><span class="string">[π(V )∩X] = [Cj] which is equivalent to say that λCj comes from Pk+2</span></span><br><span class="line"><span class="string">Σ which contradicts</span></span><br><span class="line"><span class="string">the choice of [Cj].</span></span><br><span class="line"><span class="string">Remark 5.2. Into the proof of the previous theorem, the key fact was that on X the</span></span><br><span class="line"><span class="string">Hodge conjecture holds and we translate it to Y by contradiction. So, using an analogous</span></span><br><span class="line"><span class="string">argument we have:</span></span><br><span class="line"><span class="string">△</span></span><br><span class="line"><span class="string">Proposition 5.3. Let Y =&#123;F =y1fs+⋯+ysfs =0&#125;⊂P2k+1</span></span><br><span class="line"><span class="string">Σ ,X be the quasi-smooth hypersurface</span></span><br><span class="line"><span class="string">associated to a quasi-smooth intersection subvariety X = Xf1 ∩ ⋅⋅⋅ ∩ Xfs ⊂ Pd</span></span><br><span class="line"><span class="string">Σ such that</span></span><br><span class="line"><span class="string">d +s =2(k +1). If the Hodge conjecture holds on X then it holds as well on Y .</span></span><br><span class="line"><span class="string">Corollary 5.4. If the dimension of Y is 2s −1, 2s or 2s +1 then the Hodge conjecture</span></span><br><span class="line"><span class="string">holds on Y .</span></span><br><span class="line"><span class="string">Proof. By Proposition 5.3 and Corollary 3.6.</span></span><br><span class="line"><span class="string">7&#x27;</span> metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;dvips + GPL Ghostscript GIT PRERELEASE 9.22&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;LaTeX with hyperref&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;keywords&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;https://arxiv.org/pdf/2302.03803&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: 8, <span class="string">&#x27;page&#x27;</span>: 6, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;7&#x27;</span>&#125;</span><br><span class="line">page_content=<span class="string">&#x27;References</span></span><br><span class="line"><span class="string">[1] Angella, D. Cohomologies of certain orbifolds. Journal of Geometry and Physics</span></span><br><span class="line"><span class="string">71 (2013), 117–126.</span></span><br><span class="line"><span class="string">[2] Batyrev, V. V., and Cox, D. A.On the Hodge structure of projective hypersur-</span></span><br><span class="line"><span class="string">faces in toric varieties. Duke Mathematical Journal 75, 2 (Aug 199 4).</span></span><br><span class="line"><span class="string">[3] Bruzzo, U., and Montoya, W. On the Hodge conjecture for quasi-smooth in-</span></span><br><span class="line"><span class="string">tersections in toric varieties. S˜ ao Paulo J. Math. Sci. Special Section: Geometry in</span></span><br><span class="line"><span class="string">Algebra and Algebra in Geometry (2021).</span></span><br><span class="line"><span class="string">[4] Caramello Jr, F. C.Introduction to orbifolds. arXiv:1909.08699v6 (2019).</span></span><br><span class="line"><span class="string">[5] Cox, D., Little, J., and Schenck, H.Toric varieties, vol. 124. American Math-</span></span><br><span class="line"><span class="string">ematical Soc., 2011.</span></span><br><span class="line"><span class="string">[6] Griffiths, P., and Harris, J. Principles of Algebraic Geometry. John Wiley &amp;</span></span><br><span class="line"><span class="string">Sons, Ltd, 1978.</span></span><br><span class="line"><span class="string">[7] Mavlyutov, A. R. Cohomology of complete intersections in toric varieties. Pub-</span></span><br><span class="line"><span class="string">lished in Paciﬁc J. of Math. 191 No. 1 (1999), 133–144.</span></span><br><span class="line"><span class="string">[8] Satake, I. On a Generalization of the Notion of Manifold. Proceedings of the</span></span><br><span class="line"><span class="string">National Academy of Sciences of the United States of America 42, 6 (1956), 359–363.</span></span><br><span class="line"><span class="string">[9] Steenbrink, J. H. M.Intersection form for quasi-homogeneous singularities. Com-</span></span><br><span class="line"><span class="string">positio Mathematica 34 , 2 (1977), 211–223.</span></span><br><span class="line"><span class="string">[10] Voisin, C. Hodge Theory and Complex Algebraic Geometry I, vol. 1 of Cambridge</span></span><br><span class="line"><span class="string">Studies in Advanced Mathematics . Cambridge University Press, 2002.</span></span><br><span class="line"><span class="string">[11] W ang, Z. Z., and Zaffran, D.A remark on the Hard Lefschetz theorem for K¨ ahler</span></span><br><span class="line"><span class="string">orbifolds. Proceedings of the American Mathematical Society 137 , 08 (Aug 2009).</span></span><br><span class="line"><span class="string">8&#x27;</span> metadata=&#123;<span class="string">&#x27;producer&#x27;</span>: <span class="string">&#x27;dvips + GPL Ghostscript GIT PRERELEASE 9.22&#x27;</span>, <span class="string">&#x27;creator&#x27;</span>: <span class="string">&#x27;LaTeX with hyperref&#x27;</span>, <span class="string">&#x27;creationdate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;moddate&#x27;</span>: <span class="string">&#x27;2023-02-08T20:27:28-05:00&#x27;</span>, <span class="string">&#x27;title&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;subject&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;author&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;keywords&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;https://arxiv.org/pdf/2302.03803&#x27;</span>, <span class="string">&#x27;total_pages&#x27;</span>: 8, <span class="string">&#x27;page&#x27;</span>: 7, <span class="string">&#x27;page_label&#x27;</span>: <span class="string">&#x27;8&#x27;</span>&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="举例3使用load_and_split">举例3：使用load_and_split()</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的依赖 PyPDFLoader() </span></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> PyPDFLoader </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.定义PyPDFLoader </span></span><br><span class="line">py_pdfLoader = PyPDFLoader(file_path= <span class="string">&quot;./asset/load/load.pdf&quot;</span> ) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.加载 </span></span><br><span class="line">docs = py_pdfLoader.load_and_split() <span class="comment">#底层默认使用了递归字符文本切分器 </span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> (docs)</span><br></pre></td></tr></table></figure>
<p>同样，对于 PyPDFLoader ，依然是使用 .page_content 和 .metadata 去访问数据，也就是说，每一个 文档加载器虽然代码逻辑不同，应用需求不同，但使用方式是相同的。</p>
<h2 id="加载csv">加载CSV</h2>
<h3 id="举例1加载csv所有列">举例1：加载csv所有列</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> CSVLoader  </span><br><span class="line">  </span><br><span class="line">csv_loader = CSVLoader(  </span><br><span class="line">    file_path=<span class="string">&quot;./asset/load/03-load.csv&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = csv_loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs))  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(docs)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(doc)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">4</span><br><span class="line">[Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/03-load.csv&#x27;</span>, <span class="string">&#x27;row&#x27;</span>: 0&#125;, page_content=<span class="string">&#x27;id: 1\ntitle: Introduction to Python\ncontent: Python is a popular programming language.\nauthor: John Doe&#x27;</span>), Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/03-load.csv&#x27;</span>, <span class="string">&#x27;row&#x27;</span>: 1&#125;, page_content=<span class="string">&#x27;id: 2\ntitle: Data Science Basics\ncontent: Data science involves statistics and machine learning.\nauthor: Jane Smith&#x27;</span>), Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/03-load.csv&#x27;</span>, <span class="string">&#x27;row&#x27;</span>: 2&#125;, page_content=<span class="string">&#x27;id: 3\ntitle: Web Development\ncontent: HTML, CSS and JavaScript are core web technologies.\nauthor: Mike Johnson&#x27;</span>), Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/03-load.csv&#x27;</span>, <span class="string">&#x27;row&#x27;</span>: 3&#125;, page_content=<span class="string">&#x27;id: 4\ntitle: Artificial Intelligence\ncontent: AI is transforming many industries.\nauthor: Sarah Williams&#x27;</span>)]</span><br><span class="line">page_content=<span class="string">&#x27;id: 1</span></span><br><span class="line"><span class="string">title: Introduction to Python</span></span><br><span class="line"><span class="string">content: Python is a popular programming language.</span></span><br><span class="line"><span class="string">author: John Doe&#x27;</span> metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/03-load.csv&#x27;</span>, <span class="string">&#x27;row&#x27;</span>: 0&#125;</span><br><span class="line">page_content=<span class="string">&#x27;id: 2</span></span><br><span class="line"><span class="string">title: Data Science Basics</span></span><br><span class="line"><span class="string">content: Data science involves statistics and machine learning.</span></span><br><span class="line"><span class="string">author: Jane Smith&#x27;</span> metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/03-load.csv&#x27;</span>, <span class="string">&#x27;row&#x27;</span>: 1&#125;</span><br><span class="line">page_content=<span class="string">&#x27;id: 3</span></span><br><span class="line"><span class="string">title: Web Development</span></span><br><span class="line"><span class="string">content: HTML, CSS and JavaScript are core web technologies.</span></span><br><span class="line"><span class="string">author: Mike Johnson&#x27;</span> metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/03-load.csv&#x27;</span>, <span class="string">&#x27;row&#x27;</span>: 2&#125;</span><br><span class="line">page_content=<span class="string">&#x27;id: 4</span></span><br><span class="line"><span class="string">title: Artificial Intelligence</span></span><br><span class="line"><span class="string">content: AI is transforming many industries.</span></span><br><span class="line"><span class="string">author: Sarah Williams&#x27;</span> metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/03-load.csv&#x27;</span>, <span class="string">&#x27;row&#x27;</span>: 3&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3 id="举例2加载指定列">举例2：加载指定列</h3>
<p>使用 source_column 参数指定文件加载的列，保存在source变量中。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> CSVLoader  </span><br><span class="line">  </span><br><span class="line">csv_loader = CSVLoader(  </span><br><span class="line">    file_path=<span class="string">&quot;./asset/load/03-load.csv&quot;</span>,  </span><br><span class="line">    source_column=<span class="string">&quot;author&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = csv_loader.load()  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(docs)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Document(metadata=&#123;<span class="built_in">source</span>: John Doe, row: 0&#125;, page_content=<span class="built_in">id</span>: 1\ntitle: Introduction to Python\ncontent: Python is a popular programming language.\nauthor: John Doe), Document(metadata=&#123;<span class="built_in">source</span>: Jane Smith, row: 1&#125;, page_content=<span class="built_in">id</span>: 2\ntitle: Data Science Basics\ncontent: Data science involves statistics and machine learning.\nauthor: Jane Smith), Document(metadata=&#123;<span class="built_in">source</span>: Mike Johnson, row: 2&#125;, page_content=<span class="built_in">id</span>: 3\ntitle: Web Development\ncontent: HTML, CSS and JavaScript are core web technologies.\nauthor: Mike Johnson), Document(metadata=&#123;<span class="built_in">source</span>: Sarah Williams, row: 3&#125;, page_content=<span class="built_in">id</span>: 4\ntitle: Artificial Intelligence\ncontent: AI is transforming many industries.\nauthor: Sarah Williams)]</span><br></pre></td></tr></table></figure></p>
<h2 id="加载json">加载JSON</h2>
<p>LangChain提供的JSON格式的文档加载器是<strong>JSONLoader</strong>。在实际应用场景中，JSON格式的数据占有 很大比例，而且JSON的形式也是多样的。我们需要特别关注。</p>
<p>JSONLoader 使用指定的 jq结构来解析 JSON 文件。jq是一个轻量级的命令行 JSON 处理器 ，可以对 JSON 格式的数据进行各种复杂的处理，包括数据过滤、映射、减少和转换，是处理 JSON 数据的首选 工具之一。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install jq</span><br></pre></td></tr></table></figure></p>
<h3 id="举例1使用jsonloader文档加载器加载">举例1：使用JSONLoader文档加载器加载</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> JSONLoader  </span><br><span class="line">  </span><br><span class="line">json_loader = JSONLoader(  </span><br><span class="line">    file_path=<span class="string">&quot;./asset/load/04-load.json&quot;</span>,  </span><br><span class="line">    jq_schema=<span class="string">&quot;.&quot;</span>, <span class="comment">#表示加载所有的字段  </span></span><br><span class="line">    text_content=<span class="literal">False</span>, <span class="comment">#将加载的json对象转换为json字符串  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = json_loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(docs)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;E:\\myjupyte\\尚硅谷LangChain\\chapter07-RAG\\asset\\load\\04-load.json&#x27;</span>, <span class="string">&#x27;seq_num&#x27;</span>: 1&#125;, page_content=<span class="string">&#x27;&#123;&quot;messages&quot;: [&#123;&quot;sender&quot;: &quot;Alice&quot;, &quot;content&quot;: &quot;Hello, how are you today?&quot;, &quot;timestamp&quot;: &quot;2023-05-15T10:00:00&quot;&#125;, &#123;&quot;sender&quot;: &quot;Bob&quot;, &quot;content&quot;: &quot;I\&#x27;</span>m doing well, thanks <span class="keyword">for</span> asking!<span class="string">&quot;, &quot;</span>timestamp<span class="string">&quot;: &quot;</span>2023-05-15T10:02:00<span class="string">&quot;&#125;, &#123;&quot;</span>sender<span class="string">&quot;: &quot;</span>Alice<span class="string">&quot;, &quot;</span>content<span class="string">&quot;: &quot;</span>Would you like to meet <span class="keyword">for</span> lunch?<span class="string">&quot;, &quot;</span>timestamp<span class="string">&quot;: &quot;</span>2023-05-15T10:05:00<span class="string">&quot;&#125;, &#123;&quot;</span>sender<span class="string">&quot;: &quot;</span>Bob<span class="string">&quot;, &quot;</span>content<span class="string">&quot;: &quot;</span>Sure, that sounds great!<span class="string">&quot;, &quot;</span>timestamp<span class="string">&quot;: &quot;</span>2023-05-15T10:07:00<span class="string">&quot;&#125;], &quot;</span>conversation_id<span class="string">&quot;: &quot;</span>conv_12345<span class="string">&quot;, &quot;</span>participants<span class="string">&quot;: [&quot;</span>Alice<span class="string">&quot;, &quot;</span>Bob<span class="string">&quot;]&#125;&#x27;)]</span></span><br></pre></td></tr></table></figure>
<h3 id="举例2加载json文件中messages中的所有的content字段">举例2：加载json文件中messages[]中的所有的content字段</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> JSONLoader  </span><br><span class="line">  </span><br><span class="line">json_loader = JSONLoader(  </span><br><span class="line">    file_path=<span class="string">&quot;./asset/load/04-load.json&quot;</span>,  </span><br><span class="line">    jq_schema=<span class="string">&quot;.messages[].content&quot;</span>, <span class="comment">#加载messages[]的所有的content字段  </span></span><br><span class="line">    <span class="comment">#text_content=False, #将加载的json对象转换为json字符串  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = json_loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(doc.page_content)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Hello, how are you today?</span><br><span class="line">I&#x27;m doing well, thanks for asking!</span><br><span class="line">Would you like to meet for lunch?</span><br><span class="line">Sure, that sounds great!</span><br></pre></td></tr></table></figure></p>
<h3 id="举例3提取04-response.json文件中嵌套在-data.items.content-的文本">举例3：提取04-response.json文件中嵌套在 data.items[].content 的文本</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> JSONLoader  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 方式1：  </span></span><br><span class="line"><span class="comment"># json_loader = JSONLoader(  </span></span><br><span class="line"><span class="comment">#     file_path=&quot;./asset/load/04-response.json&quot;,  </span></span><br><span class="line"><span class="comment">#     jq_schema=&quot;.data.items[].content&quot;, #data.items[].content  </span></span><br><span class="line"><span class="comment"># )  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 方式2：  </span></span><br><span class="line">json_loader = JSONLoader(  </span><br><span class="line">    file_path=<span class="string">&quot;./asset/load/04-response.json&quot;</span>,  </span><br><span class="line">    jq_schema=<span class="string">&quot;.data.items[]&quot;</span>, <span class="comment">#data.items[].content  </span></span><br><span class="line">    content_key=<span class="string">&quot;.content&quot;</span>,  </span><br><span class="line">    is_content_key_jq_parsable=<span class="literal">True</span>, <span class="comment">#用jq解析content_key  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = json_loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(doc.page_content)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">This article explains how to parse API responses...</span><br><span class="line">Learn to handle nested structures with...</span><br><span class="line">Best practices <span class="keyword">for</span> preserving metadata...</span><br></pre></td></tr></table></figure></p>
<h3 id="举例4提取04-response.json文件中嵌套在-data.items-里的-titlecontent-和-其文本">举例4：提取04-response.json文件中嵌套在 data.items[] 里的 title、content 和 其文本</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> JSONLoader  </span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义json文件的路径  </span></span><br><span class="line">file_path = <span class="string">&#x27;asset/load/04-response.json&#x27;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.定义JSONLoader对象  </span></span><br><span class="line"><span class="comment"># 提取嵌套在 data.items[].content 的文本，并保留其他字段作为元数据  </span></span><br><span class="line"><span class="comment"># loader = JSONLoader(  </span></span><br><span class="line"><span class="comment">#     file_path=file_path,  </span></span><br><span class="line"><span class="comment">#     # jq_schema=&quot;.data.items[] | &#123;id, author, text: (.title + &#x27;\n&#x27; + .content)&#125;&quot;,  </span></span><br><span class="line"><span class="comment">#     jq_schema=&#x27;&#x27;&#x27;.data.items[] | &#123;  </span></span><br><span class="line"><span class="comment">#     id,  </span></span><br><span class="line"><span class="comment">#     author,  </span></span><br><span class="line"><span class="comment">#     created_at,  </span></span><br><span class="line"><span class="comment">#     title, # 保留title字段  </span></span><br><span class="line"><span class="comment">#     text: (.title + &quot;\n&quot; + .content)  </span></span><br><span class="line"><span class="comment">#     &#125;&#x27;&#x27;&#x27;,  </span></span><br><span class="line"><span class="comment">#     content_key=&quot;.text&quot;,  # 再从条目中提取 content 字段  </span></span><br><span class="line"><span class="comment">#     is_content_key_jq_parsable=True  # 用jq解析content_key  </span></span><br><span class="line"><span class="comment"># )  </span></span><br><span class="line">loader = JSONLoader(  </span><br><span class="line">    file_path=file_path,  </span><br><span class="line">    <span class="comment"># jq_schema=&quot;.data.items[] | &#123;id, author, text: (.title + &#x27;\n&#x27; + .content)&#125;&quot;,  </span></span><br><span class="line">    jq_schema=<span class="string">&quot;.data.items[]&quot;</span>,  </span><br><span class="line">    content_key=<span class="string">&#x27;.title + &quot;\\n\\n&quot; + .content&#x27;</span>,  </span><br><span class="line">    is_content_key_jq_parsable=<span class="literal">True</span>  <span class="comment"># 用jq解析content_key  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># loader = JSONLoader(  </span></span><br><span class="line"><span class="comment">#     file_path=file_path,  </span></span><br><span class="line"><span class="comment">#     # jq_schema=&quot;.data.items[] | &#123;id, author, text: (.title + &#x27;\n&#x27; + .content)&#125;&quot;,  </span></span><br><span class="line"><span class="comment">#     jq_schema=&#x27;&#x27;&#x27;  </span></span><br><span class="line"><span class="comment">#         .data.items[] | &#123;  </span></span><br><span class="line"><span class="comment">#             metadata: &#123;  </span></span><br><span class="line"><span class="comment">#                 id,  </span></span><br><span class="line"><span class="comment">#                 author,  </span></span><br><span class="line"><span class="comment">#                 created_at  </span></span><br><span class="line"><span class="comment">#             &#125;,  </span></span><br><span class="line"><span class="comment">#             content: (.title + &quot;\n\n&quot; + .content)  </span></span><br><span class="line"><span class="comment">#         &#125;  </span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;,  # 构建新结构  </span></span><br><span class="line"><span class="comment">#      content_key=&#x27;.title + &quot;\\n\\n&quot; + .content&#x27;,  </span></span><br><span class="line"><span class="comment">#     is_content_key_jq_parsable=True  # 用jq解析content_key  </span></span><br><span class="line"><span class="comment"># )  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.加载  </span></span><br><span class="line">data = loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> data:  </span><br><span class="line">    <span class="built_in">print</span>(doc.page_content)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Understanding JSONLoader</span><br><span class="line"></span><br><span class="line">This article explains how to parse API responses...</span><br><span class="line">Advanced jq Schema Patterns</span><br><span class="line"></span><br><span class="line">Learn to handle nested structures with...</span><br><span class="line">LangChain Metadata Handling</span><br><span class="line"></span><br><span class="line">Best practices for preserving metadata...</span><br></pre></td></tr></table></figure></p>
<h2 id="加载html了解">加载HTML(了解)</h2>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install unstructured</span><br></pre></td></tr></table></figure>
<p>举例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的依赖</span></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> UnstructuredHTMLLoader </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.定义UnstructuredHTMLLoader对象 </span></span><br><span class="line"><span class="comment"># strategy: </span></span><br><span class="line"><span class="comment"># &quot;fast&quot; 解析加载html文件速度是比较快（但可能丢失部分结构或元数据） </span></span><br><span class="line"><span class="comment"># &quot;hi_res&quot;: (高分辨率解析) 解析精准（速度慢一些） </span></span><br><span class="line"><span class="comment"># &quot;ocr_only&quot; 强制使用ocr提取文本，仅仅适用于图像（对HTML无效） </span></span><br><span class="line"><span class="comment"># mode ：one of `&#123;&#x27;paged&#x27;, &#x27;elements&#x27;, &#x27;single&#x27;&#125; </span></span><br><span class="line"><span class="comment"># &quot;elements&quot; 按语义元素（标题、段落、列表、表格等）拆分成多个独立的小文档</span></span><br><span class="line"> html_loader = UnstructuredHTMLLoader( </span><br><span class="line">	 file_path= <span class="string">&quot;asset/load/05-load.html&quot;</span> , </span><br><span class="line">	 mode= <span class="string">&quot;elements&quot;</span> , </span><br><span class="line">	 strategy= <span class="string">&quot;fast&quot;</span> ) </span><br><span class="line">	 </span><br><span class="line"><span class="comment"># 3.加载</span></span><br><span class="line">docs = html_loader.load() </span><br><span class="line"><span class="built_in">print</span> ( <span class="built_in">len</span> (docs)) <span class="comment"># 16 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.打印</span></span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs: </span><br><span class="line">	<span class="built_in">print</span> (doc)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">16</span></span><br><span class="line">page_content=&#x27;首发于自然语言处理算法与实践&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;zho&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;UncategorizedText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;b082a3e1f4714ffa5f25741f39d82c17&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;RAG<span class="punctuation">:</span>将检索与生成方式相结合来做生成任务&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;category_depth&#x27;<span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;kor&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;Title&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">46103</span>fd31eae47ed36481d13185af8a9&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;烛之文&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;kor&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">46103</span>fd31eae47ed36481d13185af8a9&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;UncategorizedText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;e02798c2e2bb964165a9e9356b82a3f6&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;<span class="number">1</span>、前言&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;category_depth&#x27;<span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;zho&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">46103</span>fd31eae47ed36481d13185af8a9&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;Title&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">683</span>a24e897e3a9b862ead6c7979a58dc&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;在上一篇&lt;kNN-NER：利用knn近邻算法来做命名实体识别&gt;提及到文中提出kNN-NER框架是一种检索式增强的方法（retrieval augmented methods），就去查看有关retrieval augmented的paper，了解其核心思想，觉得检索式增强的方法很适合许多业务场景使用，因其以一种简捷的方式将外部知识融于模型中去。今天就分享一篇来自Facebook AI Research的paper&lt;Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks&gt;，论文提出一种检索式增强生成方法，应用于知识密集型的NLP任务（如问答生成），该篇论文被<span class="number">2020</span>年NeurIPS 会议接收。&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;nor&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">683</span>a24e897e3a9b862ead6c7979a58dc&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;NarrativeText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;d345b4a58c84984eb1acf1105fd9f214&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;文中说到，以BERT之类的大规模预训练模型将很多事实知识信息存入模型中，可以看着是pre-trained parametric类型，尽管以fine-tuned方式在下游任务取得显著的成效，但这类方法仍存在无法精准地获取和操作知识的缺陷。而在上述提及的问题上，传统知识检索的方法能很好的应对，这类方法可以看着是non-parametric memory类型。于是，论文提出检索式增强生成方法（retrieval-augmented generation，RAG），主要思想就是将pre-trained parametric与non-parametric memory结合起来做语言生成任务，将两类模型集成起来提高任务处理效果。&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;nor&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">683</span>a24e897e3a9b862ead6c7979a58dc&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;UncategorizedText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2</span>fe8d146b5803ec72e5173bf15599710&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;<span class="number">2</span>、RAG方法&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;category_depth&#x27;<span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;zho&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">46103</span>fd31eae47ed36481d13185af8a9&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;Title&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">22</span>ca96c9bf71395b8fbbf0928bd7f292&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;上图为论文提出RAG模型的整体示意图。主要包括两大模块：一个检索器（Retriever， p_\\eta(z|x) ） + 一个生成器（Generator， p_\\theta(y_i|x<span class="punctuation">,</span>z<span class="punctuation">,</span>y_<span class="punctuation">&#123;</span><span class="number">1</span><span class="punctuation">:</span>i<span class="number">-1</span><span class="punctuation">&#125;</span>) ）。前者包括query encoder和document index，分别负责query的编码和文档的索引；后者是一个seq2seq的生成模型。在检索中，使用的是最大内积搜索的方法（MIPS）来检索top-K相关文档。&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;cat&#x27;<span class="punctuation">,</span> &#x27;nor&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">22</span>ca96c9bf71395b8fbbf0928bd7f292&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;NarrativeText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">6</span>bbc63aaa7b3afb8d2685e9b3de78a4c&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;<span class="number">3</span>、实验&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;category_depth&#x27;<span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;zho&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">46103</span>fd31eae47ed36481d13185af8a9&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;Title&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">4</span>df308cd6991fb9e3f0592371bae26be&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;论文在四类Knowledge-Intensive 任务上进行实验，具体包括开放问答（Open-domain Question Answering ）、摘要式问答（Abstractive Question Answering） 、开放问题生成（Jeopardy Question Generation）、事实判断（Fact Verification ），并使用维基百科（包含<span class="number">2100</span>万个文档）作为检索库。&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;eng&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">4</span>df308cd6991fb9e3f0592371bae26be&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;UncategorizedText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;ed6e043c7fd99ec0824b91725c66e0ba&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;<span class="number">4</span>、结语&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;category_depth&#x27;<span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;zho&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">46103</span>fd31eae47ed36481d13185af8a9&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;Title&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">95</span>bc5bffaa5cfd41f5242f9f8b330761&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;本次分享基于检索增强方式将外部知识融于生成任务中一个新的框架――RAG。对比T5 和 BART这类擅长处理生成任务的模型来说，RAG更新外部知识是不需要重新预训练，成本低；而对比pipeline方法，RAG利用外部知识并不需要构造负责的特征工程。总的来说，RAG方法可作为外部知识融合框架的一种有效实例。&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;zho&#x27;<span class="punctuation">,</span> &#x27;kor&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">95</span>bc5bffaa5cfd41f5242f9f8b330761&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;UncategorizedText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">232</span>dc4ae399e0a8847bfcdeb2e64e215&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;有兴趣可关注笔者公众号：自然语言处理算法与实践&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;zho&#x27;<span class="punctuation">,</span> &#x27;kor&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">95</span>bc5bffaa5cfd41f5242f9f8b330761&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;UncategorizedText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">41</span>f28a1034fdc4291daf652054c20bd2&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;编辑于 <span class="number">2022</span><span class="number">-04</span><span class="number">-06</span> <span class="number">10</span><span class="punctuation">:</span><span class="number">47</span>&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;zho&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">95</span>bc5bffaa5cfd41f5242f9f8b330761&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;UncategorizedText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;f70255f8bf13d39885508fd845c22382&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;深度学习（Deep Learning）&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;nld&#x27;<span class="punctuation">,</span> &#x27;eng&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">95</span>bc5bffaa5cfd41f5242f9f8b330761&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;UncategorizedText&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">1818</span>d3e8e3a4ce395732bba3428a111d&#x27;<span class="punctuation">&#125;</span></span><br><span class="line">page_content=&#x27;自然语言处理算法与实践&#x27; metadata=<span class="punctuation">&#123;</span>&#x27;source&#x27;<span class="punctuation">:</span> &#x27;asset/load/<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;category_depth&#x27;<span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span> &#x27;last_modified&#x27;<span class="punctuation">:</span> &#x27;<span class="number">2025</span><span class="number">-09</span><span class="number">-24</span>T15<span class="punctuation">:</span><span class="number">26</span><span class="punctuation">:</span><span class="number">37</span>&#x27;<span class="punctuation">,</span> &#x27;languages&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;kor&#x27;<span class="punctuation">,</span> &#x27;zho&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> &#x27;file_directory&#x27;<span class="punctuation">:</span> &#x27;asset/load&#x27;<span class="punctuation">,</span> &#x27;filename&#x27;<span class="punctuation">:</span> &#x27;<span class="number">05</span>-load.html&#x27;<span class="punctuation">,</span> &#x27;filetype&#x27;<span class="punctuation">:</span> &#x27;text/html&#x27;<span class="punctuation">,</span> &#x27;parent_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">95</span>bc5bffaa5cfd41f5242f9f8b330761&#x27;<span class="punctuation">,</span> &#x27;category&#x27;<span class="punctuation">:</span> &#x27;Title&#x27;<span class="punctuation">,</span> &#x27;element_id&#x27;<span class="punctuation">:</span> &#x27;<span class="number">95058</span>f2148219d97462c5c4bfe175502&#x27;<span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h2 id="加载markdown了解">加载Markdown(了解)</h2>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install markdown </span><br><span class="line">pip install unstructured</span><br></pre></td></tr></table></figure>
<h3 id="举例1使用markdownloader加载md文件">举例1：使用MarkDownLoader加载md文件</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的依赖</span></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> UnstructuredMarkdownLoader </span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.定义UnstructuredMarkdownLoader对象</span></span><br><span class="line">md_loader = UnstructuredMarkdownLoader( file_path= <span class="string">&quot;asset/load/06-load.md&quot;</span> , strategy= <span class="string">&quot;fast&quot;</span> ) </span><br><span class="line"><span class="comment"># 3.加载</span></span><br><span class="line">docs = md_loader.load() </span><br><span class="line"><span class="built_in">print</span> ( <span class="built_in">len</span> (docs)) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.打印</span></span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs: </span><br><span class="line">	pprint(doc)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1</span><br><span class="line">Document(metadata=&#123;&#x27;source&#x27;: &#x27;asset/load/06-load.md&#x27;&#125;, page_content=&#x27;自然语言处理技术文档\n\n本文档用于测试UnstructuredMarkdownLoader的中文处理能力。\n\n第一章：简介\n\n自然语言处理(NLP)是人工智能的重要分支，主要技术包括：\n\n文本分类\n\n命名实体识别\n\n机器翻译\n\n情感分析\n\n问答系统\n\n第二章：关键技术\n\n2.1 预训练模型\n\nBERT：双向Transformer编码器\n\nGPT：自回归语言模型\n\nT5：文本到文本转换框架\n\n2.2 代码示例\n\n```python from transformers import pipeline\n\n创建文本分类管道\n\nclassifier = pipeline(&quot;text-classification&quot;, model=&quot;bert-base-chinese&quot;)\n\nresult = classifier(&quot;这家餐厅的服务很棒！&quot;) print(result)&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3 id="举例2精细分割文档保留结构信息">举例2：精细分割文档，保留结构信息</h3>
<p>将Markdown文档按语义元素（标题、段落、列表、表格等）拆分成多个独立的小文档（Element对 象），而不是返回单个大文档。通过指定mode=“elements”轻松保持这种分离。 每个分割后的元素会包含元数据。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的依赖</span></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> UnstructuredMarkdownLoader </span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.定义UnstructuredMarkdownLoader对象</span></span><br><span class="line">md_loader = UnstructuredMarkdownLoader( </span><br><span class="line">	file_path= <span class="string">&quot;./asset/load/06-load.md&quot;</span> ,</span><br><span class="line">	mode= <span class="string">&quot;elements&quot;</span> ,</span><br><span class="line">	strategy= <span class="string">&quot;fast&quot;</span> ) </span><br><span class="line">	</span><br><span class="line"><span class="comment"># 3.加载</span></span><br><span class="line">docs = md_loader.load() </span><br><span class="line"><span class="built_in">print</span> ( <span class="built_in">len</span> (docs)) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.打印</span></span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs: </span><br><span class="line"><span class="comment"># pprint(doc) </span></span><br><span class="line">	pprint(doc.page_content)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">19</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 0, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;184afae73069130590c7608c471f63f4&#x27;</span>&#125;, page_content=<span class="string">&#x27;自然语言处理技术文档&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;184afae73069130590c7608c471f63f4&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;UncategorizedText&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;18f55c7a014f88171f86dc848b58a83b&#x27;</span>&#125;, page_content=<span class="string">&#x27;本文档用于测试UnstructuredMarkdownLoader的中文处理能力。&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;184afae73069130590c7608c471f63f4&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;6a6844d806798af924a74eecc9bf3c1f&#x27;</span>&#125;, page_content=<span class="string">&#x27;第一章：简介&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;6a6844d806798af924a74eecc9bf3c1f&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;UncategorizedText&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;e7b3e94da2b42ec341e42747172c2fb1&#x27;</span>&#125;, page_content=<span class="string">&#x27;自然语言处理(NLP)是人工智能的重要分支，主要技术包括：&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;6a6844d806798af924a74eecc9bf3c1f&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;ListItem&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;eb53d308db7e96fa7bf107143411c209&#x27;</span>&#125;, page_content=<span class="string">&#x27;文本分类&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;6a6844d806798af924a74eecc9bf3c1f&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;ListItem&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;d3cd19f3de6c7be342b6d45249ed5936&#x27;</span>&#125;, page_content=<span class="string">&#x27;命名实体识别&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;6a6844d806798af924a74eecc9bf3c1f&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;ListItem&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;4af0dd9da13771840a9696cdcbb502e1&#x27;</span>&#125;, page_content=<span class="string">&#x27;机器翻译&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;6a6844d806798af924a74eecc9bf3c1f&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;ListItem&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;862050b1daeb945947f4c00587f16954&#x27;</span>&#125;, page_content=<span class="string">&#x27;情感分析&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;6a6844d806798af924a74eecc9bf3c1f&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;ListItem&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;7f221beeb60cc8089f9878c70230b9a5&#x27;</span>&#125;, page_content=<span class="string">&#x27;问答系统&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;184afae73069130590c7608c471f63f4&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;c2bf8c7c4e88556b7afb7b5407d4fbf2&#x27;</span>&#125;, page_content=<span class="string">&#x27;第二章：关键技术&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 2, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;c2bf8c7c4e88556b7afb7b5407d4fbf2&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;d32a685b6777cb3277c7732ca2603203&#x27;</span>&#125;, page_content=<span class="string">&#x27;2.1 预训练模型&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;emphasized_text_contents&#x27;</span>: [<span class="string">&#x27;BERT&#x27;</span>], <span class="string">&#x27;emphasized_text_tags&#x27;</span>: [<span class="string">&#x27;b&#x27;</span>], <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;d32a685b6777cb3277c7732ca2603203&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;ListItem&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;3efd83a33d46349a06c9489309f23af0&#x27;</span>&#125;, page_content=<span class="string">&#x27;BERT：双向Transformer编码器&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;emphasized_text_contents&#x27;</span>: [<span class="string">&#x27;GPT&#x27;</span>], <span class="string">&#x27;emphasized_text_tags&#x27;</span>: [<span class="string">&#x27;b&#x27;</span>], <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;d32a685b6777cb3277c7732ca2603203&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;ListItem&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;042b24863d1db56d10e6222413089a30&#x27;</span>&#125;, page_content=<span class="string">&#x27;GPT：自回归语言模型&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 1, <span class="string">&#x27;emphasized_text_contents&#x27;</span>: [<span class="string">&#x27;T5&#x27;</span>], <span class="string">&#x27;emphasized_text_tags&#x27;</span>: [<span class="string">&#x27;b&#x27;</span>], <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;d32a685b6777cb3277c7732ca2603203&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;ListItem&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;7da9d82f5274c3edb7ae917995c08db2&#x27;</span>&#125;, page_content=<span class="string">&#x27;T5：文本到文本转换框架&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 2, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;c2bf8c7c4e88556b7afb7b5407d4fbf2&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;58fa664fefbefa6e86ee4fc8dd128878&#x27;</span>&#125;, page_content=<span class="string">&#x27;2.2 代码示例&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;58fa664fefbefa6e86ee4fc8dd128878&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;NarrativeText&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;2d72807f991457ffe38dad8b46480b0b&#x27;</span>&#125;, page_content=<span class="string">&#x27;```python from transformers import pipeline&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;category_depth&#x27;</span>: 0, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;f5a25376ceb9e9392b4e0b2b60153cca&#x27;</span>&#125;, page_content=<span class="string">&#x27;创建文本分类管道&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;f5a25376ceb9e9392b4e0b2b60153cca&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;UncategorizedText&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;9745c5d59a60933121ca91a9b71e6acf&#x27;</span>&#125;, page_content=<span class="string">&#x27;classifier = pipeline(&quot;text-classification&quot;, model=&quot;bert-base-chinese&quot;)&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset/load/06-load.md&#x27;</span>, <span class="string">&#x27;languages&#x27;</span>: [<span class="string">&#x27;eng&#x27;</span>], <span class="string">&#x27;file_directory&#x27;</span>: <span class="string">&#x27;asset/load&#x27;</span>, <span class="string">&#x27;filename&#x27;</span>: <span class="string">&#x27;06-load.md&#x27;</span>, <span class="string">&#x27;filetype&#x27;</span>: <span class="string">&#x27;text/markdown&#x27;</span>, <span class="string">&#x27;last_modified&#x27;</span>: <span class="string">&#x27;2025-09-24T15:26:39&#x27;</span>, <span class="string">&#x27;parent_id&#x27;</span>: <span class="string">&#x27;f5a25376ceb9e9392b4e0b2b60153cca&#x27;</span>, <span class="string">&#x27;category&#x27;</span>: <span class="string">&#x27;UncategorizedText&#x27;</span>, <span class="string">&#x27;element_id&#x27;</span>: <span class="string">&#x27;7ebd846af465424c8c01cb58cfa79c86&#x27;</span>&#125;, page_content=<span class="string">&#x27;result = classifier(&quot;这家餐厅的服务很棒！&quot;) print(result)&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h2 id="加载file-directory了解">加载File Directory(了解)</h2>
<p>除了上述的单个文件加载，我们也可以批量加载一个文件夹内的所有文件。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install unstructured</span><br></pre></td></tr></table></figure> 举例： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关的依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> DirectoryLoader  </span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> PythonLoader  </span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义DirectoryLoader对象,指定要加载的文件夹路径、要加载的文件类型和是否使用多线程  </span></span><br><span class="line">directory_loader = DirectoryLoader(  </span><br><span class="line">    path=<span class="string">&quot;./asset/load&quot;</span>,  </span><br><span class="line">    glob=<span class="string">&quot;*.py&quot;</span>,  </span><br><span class="line">    use_multithreading=<span class="literal">True</span>,  </span><br><span class="line">    show_progress=<span class="literal">True</span>,  </span><br><span class="line">    loader_cls=PythonLoader  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.加载  </span></span><br><span class="line">docs = directory_loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.打印  </span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs))  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:  </span><br><span class="line">    pprint(doc)</span><br></pre></td></tr></table></figure></p>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00&lt;00:00, 227.64it/s]</span><br><span class="line">4</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset\\load\\07-fun_retun.py&#x27;</span>&#125;, page_content=<span class="string">&#x27;&quot;&quot;&quot;\n四 函数的返回值\n&quot;&quot;&quot;\n# 1.返回表达式\n# 2.不带表达式的 return 语句，返回 None。\n# 3.函数中如果没有 return 语句，在函数运行结束后也会返回 None。\n# 4.用变量接收返回结果\n# 5.return 语句可以返回多个值，多个值会放在一个元组中。\n\ndef f(a, b, c):\n    return a, b, c, [a, b, c]\nprint(f(1, 2, 3))  # (1, 2, 3, [1, 2, 3])\n&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset\\load\\07-param_form.py&#x27;</span>&#125;, page_content=<span class="string">&#x27;&quot;&quot;&quot;\n三 函数参数形式\n&quot;&quot;&quot;\n# 1.位置参数\n# 2.关键字参数\n# 3.默认参数\n# 4.不定长参数\n# 4.1 带一个*\ndef printInfo(num,*vartuple):\n    print(num)\n    print(vartuple)\n\nprintInfo(70,60,50)\n\nprint(&quot;-&quot; * 20)\n# 如果不定长的参数后面还有参数,必须通过关键字参数传参\ndef printInfo1(num1,*vartuple,num) :\n    print(num)\n    print(num1)\n    print(vartuple)\n\nprintInfo1(10,20,num = 40)\n\nprint(&quot;-&quot; * 20)\n# 如果没有给不定长的参数传参,那么得到的是空元组\nprintInfo1(70,num = 60)\n# 4.2 带二个*\ndef printInfo(num,**vardict):\n    print(num)\n    print(vardict)\n    # return\n\nprintInfo(10,key1 = 20,key2 = 30)&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset\\load\\07-fun.py&#x27;</span>&#125;, page_content=<span class="string">&#x27;&quot;&quot;&quot;\n一 函数入门\n&quot;&quot;&quot;\n# 1.不使用函数\n# 打印欢迎信息1\nprint(&quot;********************************&quot;)\nprint(&quot;*                              *&quot;)\nprint(&quot;*     欢迎来到Python世界       *&quot;)\nprint(&quot;*                              *&quot;)\nprint(&quot;********************************&quot;)\n\n# 打印欢迎信息2\nprint(&quot;********************************&quot;)\nprint(&quot;*                              *&quot;)\nprint(&quot;*     欢迎来到Python世界       *&quot;)\nprint(&quot;*                              *&quot;)\nprint(&quot;********************************&quot;)\n\n# 打印欢迎信息3\nprint(&quot;********************************&quot;)\nprint(&quot;*                              *&quot;)\nprint(&quot;*     欢迎来到Python世界       *&quot;)\nprint(&quot;*                              *&quot;)\nprint(&quot;********************************&quot;)\n\n# 2.使用函数\ndef print_welcome():\n    &quot;&quot;&quot;打印欢迎信息&quot;&quot;&quot;\n    print(&quot;********************************&quot;)\n    print(&quot;*                              *&quot;)\n    print(&quot;*     欢迎来到Python世界       *&quot;)\n    print(&quot;*                              *&quot;)\n    print(&quot;********************************&quot;)\n\n# 多次调用函数打印欢迎信息\nprint_welcome()\nprint_welcome()\nprint_welcome()&#x27;</span>)</span><br><span class="line">Document(metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;asset\\load\\07-fun_param.py&#x27;</span>&#125;, page_content=<span class="string">&#x27;&quot;&quot;&quot;\n二 函数参数\n&quot;&quot;&quot;\n\n\n# 1. 无参数版本 - 只能计算固定的购物车\ndef calculate_total_no_params():\n    &quot;&quot;&quot;计算固定购物车总价&quot;&quot;&quot;\n    prices = [100, 50, 30]  # 商品价格固定写死在函数内\n    total = 0\n    for price in prices:\n        total += price\n    return total\n\n# 只能计算一个固定的购物车\nprint(f&quot;购物车总价:&#123;calculate_total_no_params()&#125;&quot;)\n\n# 2.有参数版本 - 可以计算任意购物车\ndef calculate_total(prices):\n    &quot;&quot;&quot;计算任意购物车总价&quot;&quot;&quot;\n    total = 0\n    for price in prices:\n        total += price\n    return total\n\n# 可以计算任意购物车\ncart1 = [100, 50, 30]\ncart2 = [200, 80, 45, 60]\ncart3 = [75, 90, 120]\n\nprint(&quot;第一个购物车总价:&#123;calculate_total(cart1)&#125;:&quot;)\nprint(&quot;第二个购物车总价:&#123;calculate_total(cart2)&#125;&quot;)\nprint(f&quot;第三个购物车总价:&#123;calculate_total(cart3)&#125;&quot;)\n\n\n# 3.参数传递\n# 3.1 不可变类型 函数传递不可变对象\n\ndef changeInt(a) :\n    print(&quot;函数体中未改变前a的内存地址&quot;,id(a))\n    a = 10   #底层会创建一个新对象 然后给新对象一个新值\n    print(&quot;函数体中改变后a的内存地址&quot;,id(a))\n\na = 2 # 创建一个对象 然后给这个对象一个值\nchangeInt(a)\nprint(a)\nprint(&quot;函数外b的内存地址&quot;,id(a))\n\n\n\n# 输出结果\n# 函数体中未改变前a的内存地址 140729722661336\n# 函数体中改变后a的内存地址 140729722661592\n# 2\n# 函数外b的内存地址 140729722661336\n\n\n# 3.2 可变类型 函数传递不可变对象\n\ndef changeList(myList) :\n    myList[1] = 50\n    print(&quot;函数内的值&quot;,myList) # [1,50,3]\n    print(&quot;函数内列表的内存&quot;,id(myList)) # 0111111\n\nmlist = [1,2,3]  # 底层创建一个对象 地址0111111\nchangeList(mlist)\nprint(&quot;函数外的值&quot;,mlist) # # [1,50,3]\nprint(&quot;函数外列表的内存&quot;,id(mlist))\n\n# 输出结果\n# 函数内的值 [1, 50, 3]\n# 函数内列表的内存 1380193079680\n# 函数外的值 [1, 50, 3]\n# 函数外列表的内存 1380193079680\n\n&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h1 id="文档拆分器-text-splitters">文档拆分器 Text Splitters</h1>
<h2 id="为什么要拆分分块切分">为什么要拆分/分块/切分</h2>
<p>当拿到统一的一个Document对象后，接下来需要切分成Chunks。如果不切分，而是考虑作为一个整体 的Document对象，会存在两点问题：</p>
<ol type="1">
<li>假设提问的Query的答案出现在某一个Document对象中，那么将检索到的整个Document对象 直接放入Prompt中并不是最优的选择，因为其中一定会包含非常多无关的信息，而无效信息越 多，对大模型后续的推理影响越大。</li>
<li>任何一个大模型都存在最大输入的<strong>Token限制</strong>，如果一个Document非常大，比如一个几百兆的 PDF，那么大模型肯定无法容纳如此多的信息。</li>
</ol>
<p>基于此，一个有效的解决方案就是将完整的Document对象进行<strong>分块处理（Chunking)</strong>。无论是在存储 还是检索过程中，都将以这些<strong>块(chunks)</strong> 为基本单位，这样有效地避免内容不相关性问题和超出最大输 入限制的问题。</p>
<h2 id="chunking拆分的策略">Chunking拆分的策略</h2>
<p><strong>方法1：根据句子切分</strong>：这种方法按照自然句子边界进行切分，以保持语义完整性。</p>
<p><strong>方法2：按照固定字符数来切分</strong>：这种策略根据特定的字符数量来划分文本，但可能会在不适当的位置 切断句子。</p>
<p><strong>方法3：按固定字符数来切分，结合重叠窗口（overlapping windows）</strong>：此方法与按字符数切分相 似，但通过重叠窗口技术避免切分关键内容，确保信息连贯性。</p>
<p><strong>方法4：递归字符切分方法</strong>：通过递归字符方式动态确定切分点，这种方法可以根据文档的复杂性和内 容密度来调整块的大小。</p>
<p><strong>方法5：根据语义内容切分</strong>：这种 <strong>高级策略</strong>依据文本的语义内容来划分块，旨在保持相关信息的集中和 完整，适用于需要高度语义保持的应用场景。</p>
<blockquote>
<p>[!tip] 第2种⽅法（按照字符数切分）和第3种⽅法（按固定字符数切分结合重叠窗口）主要基于字符进⾏ ⽂本的切分，而不考虑⽂章的实际内容和语义。这种⽅式虽简单，但可能会导致 <strong>主题或语义上的断 裂</strong> 。</p>
<p>相对而⾔，第4种递归⽅法更加灵活和⾼效，它结合了固定⻓度切分和语义分析。通常是 <strong>首选策 略</strong> ，因为它能够更好地确保每个段落包含⼀个完整的主题。</p>
<p>而第5种⽅法，基于语义的分割虽然能精确地切分出完整的主题段落，但这种⽅法效率较低。它需 要运⾏复杂的分段算法（segmentation algorithm）， <strong>处理速度较慢</strong> ，并且 <strong>段落长度可能极不均 匀</strong> （有的主题段落可能很⻓，而有的则较短）。因此，尽管它在某些需要⾼精度语义保持的场景 下有其应⽤价值，但并 <strong>不适合所有情况</strong> 。</p>
</blockquote>
<p>这些方法各有优势和局限，选择适当的分块策略取决于具体的应用需求和预期的检索效果。接下来我们 依次尝试用常规手段应该如何实现上述几种方法的文本切分</p>
<h2 id="具体实现">具体实现</h2>
<p>LangChain提供了许多不同类型的文档切分器</p>
<p><a target="_blank" rel="noopener" href="https://python.langchain.com/api_reference/text_splitters/index.html">官网地址：https://python.langchain.com/api_reference/text_splitters/index.html</a></p>
<p>使用细节：</p>
<p>① TextSplitter作为各种具体的文档拆分器的父类</p>
<p>② 内部定义了一些常用的属性：</p>
<p>chunk_size: 返回块的最大尺寸，单位是字符数。默认值为4000（由长度函数测量）</p>
<p>chunk_overlap: 相邻两个块之间的字符重叠数,避免信息在边界处被切断而丢失。默认值为200,通常会设置为chunk_size的10% - 20%。</p>
<p>length_function: 用于测量给定块字符数的函数。默认赋值为len函数。len函数在Python中按Unicode字符计数，所以一个汉字、一个英文字母、一个符号都算一个字符。</p>
<p>keep_separator: 是否在块中保留分隔符，默认值为False</p>
<p>add_start_index: 如果为 <code>True</code>，则在元数据中包含块的起始索引。默认值为False</p>
<p>strip_whitespace: 如果为 <code>True</code>，则从每个文档的开始和结束处去除空白字符。默认值为True</p>
<p>② 内部定义的常用的方法：</p>
<p>情况1：按照字符串进行拆分：</p>
<p>split_text(xxx) : 传入的参数类型：字符串 ; 返回值的类型：List[str]</p>
<p>create_documents(xxx) : 传入的参数类型：List[str] ; 返回值的类型：List[Document]。底层调用了split_text(xxx)</p>
<p>情况2：按照Document对象进行拆分：</p>
<p>split_documents(xxx) : 传入的参数类型：List[Document] ; 返回值的类型：List[Document]。底层调用了create_documents(xxx)</p>
<p>2、Document对象 与 Str 是什么关系？</p>
<p>文档切分器可以按照字符进行切分，也可以按照Document进行切分。其中，Str 可以理解为是Document对象的page_content属性。</p>
<h3 id="charactertextsplittersplit-by-character">CharacterTextSplitter：Split by character</h3>
<p>参数情况说明： - chunk_size ：每个切块的最大token数量，默认值为4000。 - chunk_overlap ：相邻两个切块之间的最大重叠token数量，默认值为200。 - separator ：分割使用的分隔符，默认值为“”。 - length_function ：用于计算切块长度的方法。默认赋值为父类TextSplitter的len函数。</p>
<h4 id="举例1字符串文本的分割">举例1：字符串文本的分割</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line"><span class="keyword">from</span> zipp.glob <span class="keyword">import</span> separate  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.示例文本  </span></span><br><span class="line">text = <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">LangChain 是一个用于开发由语言模型驱动的应用程序的框架的。它提供了一套工具和抽象，使开发者能够更容易地构建复杂的应用程序。  </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.定义字符分割器  </span></span><br><span class="line">splitter = CharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">51</span>, <span class="comment"># 每块大小  </span></span><br><span class="line">    chunk_overlap=<span class="number">7</span>,<span class="comment"># 块与块之间的重复字符数  </span></span><br><span class="line">    <span class="comment">#length_function=len,  </span></span><br><span class="line">    separator=<span class="string">&quot;&quot;</span>   <span class="comment"># 设置为空字符串时，表示禁用分隔符  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.分割文本  </span></span><br><span class="line">texts = splitter.split_text(text)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.打印结果  </span></span><br><span class="line"><span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(texts):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;块 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>:长度：<span class="subst">&#123;<span class="built_in">len</span>(chunk)&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(chunk)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">块 1:长度：50</span><br><span class="line">LangChain 是一个用于开发由语言模型驱动的应用程序的框架的。它提供了一套工具和抽象，使开发者</span><br><span class="line">--------------------------------------------------</span><br><span class="line">块 2:长度：23</span><br><span class="line">抽象，使开发者能够更容易地构建复杂的应用程序。</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure></p>
<p>说明：若必须禁用分隔符（如处理无空格文本），需<strong>容忍实际块长略小于 chunk_size</strong> （尤其对中文）</p>
<h4 id="举例2指定分割符">举例2：指定分割符</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义要分割的文本  </span></span><br><span class="line">text = <span class="string">&quot;这是一个示例文本啊。我们将使用CharacterTextSplitter将其分割成小块。分割基于字符数。&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># text = &quot;&quot;&quot;  </span></span><br><span class="line"><span class="comment"># LangChain 是一个用于开发由语言模型。驱动的应用程序的框架的。它提供了一套工具和抽象。使开发者能够更容易地构建复杂的应用程序。  </span></span><br><span class="line"><span class="comment"># &quot;&quot;&quot;  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.定义分割器实例  </span></span><br><span class="line">text_splitter = CharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">30</span>,   <span class="comment"># 每个块的最大字符数  </span></span><br><span class="line">    <span class="comment"># chunk_size=43,   # 每个块的最大字符数  </span></span><br><span class="line">    chunk_overlap=<span class="number">0</span>, <span class="comment"># 块之间的重叠字符数  </span></span><br><span class="line">    separator=<span class="string">&quot;。&quot;</span>,  <span class="comment"># 按句号分割 （分隔符优先）  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.开始分割  </span></span><br><span class="line">chunks = text_splitter.split_text(text)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.打印效果  </span></span><br><span class="line"><span class="keyword">for</span>  i,chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(chunks):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;块 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>:长度：<span class="subst">&#123;<span class="built_in">len</span>(chunk)&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(chunk)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Created a chunk of size 33, <span class="built_in">which</span> is longer than the specified 30</span><br><span class="line"></span><br><span class="line">块 1:长度：9</span><br><span class="line">这是一个示例文本啊</span><br><span class="line">--------------------------------------------------</span><br><span class="line">块 2:长度：33</span><br><span class="line">我们将使用CharacterTextSplitter将其分割成小块</span><br><span class="line">--------------------------------------------------</span><br><span class="line">块 3:长度：7</span><br><span class="line">分割基于字符数</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure> <strong>注意：无重叠。</strong></p>
<p><strong>separator优先原则</strong>：当设置了 <strong>separator</strong> （如“。”），分割器会首先尝试在分隔符处分割，然后再考 虑 chunk_size。这是为了避免在句子中间硬性切断。这种设计是为了：</p>
<ol type="1">
<li>优先保持语义完整性（不切断句子）</li>
<li>避免产生无意义的碎片（如半个单词/不完整句子）</li>
<li>如果 <strong>chunk_size</strong> 比片段小，无法拆分片段，导致 overlap失效。</li>
<li>chunk_overlap仅在合并后的片段之间生效（如果 <strong>chunk_size</strong> 足够大）。如果没有合并的片 段，则 overlap失效。见举例3。</li>
</ol>
<h4 id="举例3指定分割符">举例3：指定分割符</h4>
<p>注意：<strong>有重叠</strong>。此时，文本“这是第二段内容。”的token正好就是8。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义要分割的文本  </span></span><br><span class="line">text = <span class="string">&quot;这是第一段文本。这是第二段内容。最后一段结束。&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.定义字符分割器  </span></span><br><span class="line">text_splitter = CharacterTextSplitter(  </span><br><span class="line">    separator=<span class="string">&quot;。&quot;</span>,  </span><br><span class="line">    chunk_size=<span class="number">20</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">8</span>,  </span><br><span class="line">    keep_separator=<span class="literal">True</span> <span class="comment">#chunk中是否保留切割符  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.分割文本  </span></span><br><span class="line">chunks = text_splitter.split_text(text)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.打印结果  </span></span><br><span class="line"><span class="keyword">for</span>  i,chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(chunks):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;块 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>:长度：<span class="subst">&#123;<span class="built_in">len</span>(chunk)&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(chunk)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span>*<span class="number">50</span>)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">块 1:长度：15</span><br><span class="line">这是第一段文本。这是第二段内容</span><br><span class="line">--------------------------------------------------</span><br><span class="line">块 2:长度：16</span><br><span class="line">。这是第二段内容。最后一段结束。</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure></p>
<h3 id="recursivecharactertextsplitter最常用">RecursiveCharacterTextSplitter：最常用</h3>
<p>文档切分器中较常用的是 <strong>RecursiveCharacterTextSplitter (递归字符文本切分器)</strong> ，遇<strong>特定字符</strong>时进行分割。默认情况下，它尝试进行切割的字符包括[“”, “”, " “,”"] 。</p>
<p>具体为：根据第一个字符进行切块，但如果任何切块太大，则会继续移动到下一个字符继续切块，以此 类推。 此外，还可以考虑添加，。等分割字符。 <strong>特点</strong>： - <strong>保留上下文</strong>：优先在自然语言边界（如段落、句子结尾）处分割， <strong>减少信息碎片化</strong>。 - <strong>智能分段</strong>：通过递归尝试多种分隔符，将文本分割为大小接近chunk_size的片段。 - <strong>灵活适配</strong>：适用于多种文本类型（代码、Markdown、普通文本等），是LangChain中最通用的 文本拆分器。</p>
<p>此外，还可以指定的参数包括：</p>
<ul>
<li>chunk_size：同TextSplitter（父类） 。</li>
<li>chunk_overlap：同TextSplitter（父类） 。</li>
<li>length_function：同TextSplitter（父类） 。</li>
<li>add_start_index：同TextSplitter（父类） 。</li>
</ul>
<h4 id="举例1使用split_text方法演示">举例1：使用split_text()方法演示</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义RecursiveCharacterTextSplitter分割器对象  </span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">10</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">0</span>,  </span><br><span class="line">    <span class="comment">#add_start_index=True,  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.定义拆分的内容  </span></span><br><span class="line">text=<span class="string">&quot;LangChain框架特性\n\n多模型集成(GPT/Claude)\n记忆管理功能\n链式调用设计。文档分析场景示例：需要处理PDF/Word等格式。&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.拆分器分割  </span></span><br><span class="line">paragraphs = text_splitter.split_text(text)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> para <span class="keyword">in</span> paragraphs:  </span><br><span class="line">    <span class="built_in">print</span>(para)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>结果: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">LangChain框</span><br><span class="line">-------</span><br><span class="line">架特性</span><br><span class="line">-------</span><br><span class="line">多模型集成(GPT</span><br><span class="line">-------</span><br><span class="line">/Claude)</span><br><span class="line">-------</span><br><span class="line">记忆管理功能</span><br><span class="line">-------</span><br><span class="line">链式调用设计。文档</span><br><span class="line">-------</span><br><span class="line">分析场景示例：需要处</span><br><span class="line">-------</span><br><span class="line">理PDF/Word等</span><br><span class="line">-------</span><br><span class="line">格式。</span><br><span class="line">-------</span><br></pre></td></tr></table></figure></p>
<h4 id="举例2使用create_documents方法演示传入字符串列表返回document对象列表">举例2：使用create_documents()方法演示，传入字符串列表，返回Document对象列表</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义RecursiveCharacterTextSplitter分割器对象  </span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">10</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">0</span>,  </span><br><span class="line">    add_start_index=<span class="literal">True</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.定义拆分的内容  </span></span><br><span class="line">text_list = [<span class="string">&quot;LangChain框架特性\n\n多模型集成(GPT/Claude)\n记忆管理功能\n链式调用设计。文档分析场景示例：需要处理PDF/Word等格式。&quot;</span>]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.拆分器分割  </span></span><br><span class="line">paragraphs = text_splitter.create_documents(text_list)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> para <span class="keyword">in</span> paragraphs:  </span><br><span class="line">    <span class="built_in">print</span>(para)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">page_content=<span class="string">&#x27;LangChain框&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 0&#125;</span><br><span class="line">-------</span><br><span class="line">page_content=<span class="string">&#x27;架特性&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 10&#125;</span><br><span class="line">-------</span><br><span class="line">page_content=<span class="string">&#x27;多模型集成(GPT&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 15&#125;</span><br><span class="line">-------</span><br><span class="line">page_content=<span class="string">&#x27;/Claude)&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 24&#125;</span><br><span class="line">-------</span><br><span class="line">page_content=<span class="string">&#x27;记忆管理功能&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 33&#125;</span><br><span class="line">-------</span><br><span class="line">page_content=<span class="string">&#x27;链式调用设计。文档&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 40&#125;</span><br><span class="line">-------</span><br><span class="line">page_content=<span class="string">&#x27;分析场景示例：需要处&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 49&#125;</span><br><span class="line">-------</span><br><span class="line">page_content=<span class="string">&#x27;理PDF/Word等&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 59&#125;</span><br><span class="line">-------</span><br><span class="line">page_content=<span class="string">&#x27;格式。&#x27;</span> metadata=&#123;<span class="string">&#x27;start_index&#x27;</span>: 69&#125;</span><br><span class="line">-------</span><br></pre></td></tr></table></figure></p>
<p><strong>逐步分割过程</strong></p>
<p><strong>第一阶段：顶级分割（按）</strong></p>
<ol type="1">
<li>首次分割： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">text.split( <span class="string">&quot;\n\n&quot;</span> ) → </span><br><span class="line">[ <span class="string">&quot;LangChain框架特性&quot;</span> ,</span><br><span class="line"> <span class="string">&quot;多模型集成(GPT/Claude)\n记忆管理功能\n链式调用设计。文档分析场景示例：需要处理 PDF/Word等格式。&quot;</span> ]</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>第一部分长度：13字符 &gt; 10 → 需要继续分割</li>
<li>第二部分长度：79字符 &gt; 10 → 需要继续分割</li>
</ul>
<p><strong>第二阶段：递归分割第一部分 “LangChain框架特性”</strong></p>
<ol type="1">
<li>尝试 ：无匹配</li>
<li>尝试（空格）：
<ul>
<li>检查字符串： “LangChain框架特性” （无空格）</li>
</ul></li>
<li>回退到""（字符级分割）： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span> ( <span class="string">&quot;LangChain框架特性&quot;</span> ) → </span><br><span class="line">[ <span class="string">&#x27;L&#x27;</span> , <span class="string">&#x27;a&#x27;</span> , <span class="string">&#x27;n&#x27;</span> , <span class="string">&#x27;g&#x27;</span> , <span class="string">&#x27;C&#x27;</span> , <span class="string">&#x27;h&#x27;</span> , <span class="string">&#x27;a&#x27;</span> , <span class="string">&#x27;i&#x27;</span> , <span class="string">&#x27;n&#x27;</span> , <span class="string">&#x27;框&#x27;</span> , <span class="string">&#x27;架&#x27;</span> , <span class="string">&#x27;特&#x27;</span> , <span class="string">&#x27;性&#x27;</span> ]</span><br></pre></td></tr></table></figure>
<ul>
<li>前10字符： “LangChain框”</li>
<li>剩余部分： “架特性”</li>
</ul></li>
</ol>
<p><strong>第三阶段：递归分割第二部分（长段落）</strong></p>
<ol type="1">
<li>按 分割： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;多模型集成(GPT/Claude)\n记忆管理功能\n链式调用设计。文档...&quot;</span> .split( <span class="string">&quot;\n&quot;</span> ) → </span><br><span class="line">[ <span class="string">&quot;多模型集成(GPT/Claude)&quot;</span> , <span class="comment"># 17字符 </span></span><br><span class="line"><span class="string">&quot;记忆管理功能&quot;</span> , <span class="comment"># 6字符</span></span><br><span class="line"><span class="string">&quot;链式调用设计。文档分析场景示例：需要处理PDF/Word等格式。&quot;</span> <span class="comment"># 36字符</span></span><br><span class="line">] </span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li>第1块：17字符 &gt; 10 → 继续分割</li>
<li>第2块：6字符 ≤ 10 → 直接保留</li>
<li>第3块：36字符 &gt; 10 → 继续分割</li>
</ul>
<ol start="2" type="1">
<li>分割 “多模型集成(GPT/Claude)” ：
<ul>
<li>尝试：无空格</li>
<li>回退到""：
<ul>
<li>前10字符： “多模型集成(GPT”</li>
<li>剩余7字符： “/Claude)”</li>
</ul></li>
</ul></li>
<li>分割 <strong>"链式调用设计。文档分析场景示例：需要处理PDF/Word等格式</strong>。"：
<ul>
<li>尝试：无空格</li>
<li>回退到"":
<ul>
<li>按10字符分段： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;链式调用设计。文档分析场景示例：需要处理PDF/Word等格式。&quot;</span> → </span><br><span class="line">[</span><br><span class="line"><span class="string">&quot;链式调用设计。文档&quot;</span> , </span><br><span class="line"><span class="string">&quot;分析场景示例：需要处&quot;</span> , </span><br><span class="line"><span class="string">&quot;理PDF/Word等&quot;</span> , </span><br><span class="line"><span class="string">&quot;格式。&quot;</span></span><br><span class="line"> ]</span><br></pre></td></tr></table></figure></li>
</ul></li>
</ul></li>
</ol>
<h4 id="举例3使用create_documents方法演示将本地文件内容加载成字符串进行拆分">举例3：使用create_documents()方法演示，将本地文件内容加载成字符串，进行拆分</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> RecursiveCharacterTextSplitter  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.打开.txt文件  </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;asset/load/08-ai.txt&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    state_of_the_union = f.read()  <span class="comment">#返回的是字符串  </span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(state_of_the_union))  <span class="comment"># &lt;class &#x27;str&#x27;&gt;  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.定义RecursiveCharacterTextSplitter（递归字符分割器）  </span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">100</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">20</span>,  </span><br><span class="line">    <span class="comment">#chunk_overlap=0,  </span></span><br><span class="line">    length_function=<span class="built_in">len</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.分割文本  </span></span><br><span class="line">texts = text_splitter.create_documents([state_of_the_union])  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.打印分割文本  </span></span><br><span class="line"><span class="keyword">for</span> document <span class="keyword">in</span> texts:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;🔥<span class="subst">&#123;document.page_content&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&lt;class <span class="string">&#x27;str&#x27;</span>&gt;</span><br><span class="line">🔥人工智能（AI）是什么？</span><br><span class="line">🔥人工智能（Artificial</span><br><span class="line">🔥Intelligence，简称AI）是指由计算机系统模拟人类智能的技术，使其能够执行通常需要人类认知能力的任务，如学习、推理、决策和语言理解。AI的核心目标是让机器具备感知环境、处理信息并自主行动的</span><br><span class="line">🔥让机器具备感知环境、处理信息并自主行动的能力。</span><br><span class="line">🔥1. AI的技术基础</span><br><span class="line">AI依赖多种关键技术：</span><br><span class="line"></span><br><span class="line">机器学习（ML）：通过算法让计算机从数据中学习规律，无需显式编程。例如，推荐系统通过用户历史行为预测偏好。</span><br><span class="line">🔥深度学习：基于神经网络的机器学习分支，擅长处理图像、语音等复杂数据。AlphaGo击败围棋冠军便是典型案例。</span><br><span class="line"></span><br><span class="line">自然语言处理（NLP）：使计算机理解、生成人类语言，如ChatGPT的对话能力。</span><br><span class="line">🔥2. AI的应用场景</span><br><span class="line">AI已渗透到日常生活和各行各业：</span><br><span class="line"></span><br><span class="line">医疗：辅助诊断（如AI分析医学影像）、药物研发加速。</span><br><span class="line"></span><br><span class="line">交通：自动驾驶汽车通过传感器和AI算法实现安全导航。</span><br><span class="line">🔥金融：欺诈检测、智能投顾（如风险评估模型）。</span><br><span class="line"></span><br><span class="line">教育：个性化学习平台根据学生表现调整教学内容。</span><br><span class="line"></span><br><span class="line">3. AI的挑战与未来</span><br><span class="line">尽管前景广阔，AI仍面临问题：</span><br><span class="line">🔥伦理争议：数据隐私、算法偏见（如招聘AI歧视特定群体）。</span><br><span class="line"></span><br><span class="line">就业影响：自动化可能取代部分人工岗位，但也会创造新职业。</span><br><span class="line"></span><br><span class="line">技术瓶颈：通用人工智能（AGI）尚未实现，当前AI仅擅长特定任务。</span><br><span class="line">🔥未来，AI将与人类协作而非替代：医生借助AI提高诊断效率，教师利用AI定制课程。其发展需平衡技术创新与社会责任，确保技术造福全人类。</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h4 id="举例4使用split_documents方法演示利用pdfloader加载文档对文档的内容用递归切割器切割">举例4：使用split_documents()方法演示，利用PDFLoader加载文档，对文档的内容用递归切割器切割</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> PyPDFLoader  </span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义PyPDFLoader加载器  </span></span><br><span class="line">loader = PyPDFLoader(<span class="string">&quot;./asset/load/02-load.pdf&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.加载和切割文档对象  </span></span><br><span class="line">docs = loader.load()   <span class="comment"># 返回Document对象构成的list  </span></span><br><span class="line"><span class="comment"># print(f&quot;第0页：\n&#123;docs[0]&#125;&quot;)  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.定义切割器  </span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">200</span>,  </span><br><span class="line">    <span class="comment">#chunk_size=120,  </span></span><br><span class="line">    chunk_overlap=<span class="number">0</span>,  </span><br><span class="line">    <span class="comment"># chunk_overlap=100,  </span></span><br><span class="line">    length_function=<span class="built_in">len</span>,  </span><br><span class="line">    add_start_index=<span class="literal">True</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.对pdf内容进行切割得到文档对象  </span></span><br><span class="line">paragraphs = text_splitter.split_documents(docs)  </span><br><span class="line"><span class="comment">#paragraphs = text_splitter.create_documents([text])  </span></span><br><span class="line"><span class="keyword">for</span> para <span class="keyword">in</span> paragraphs:  </span><br><span class="line">    <span class="built_in">print</span>(para.page_content)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;他的车，他的命！ 他忽然想起来，一年，二年，至少有三四年；一滴汗，两滴汗，不</span></span><br><span class="line"><span class="string">知道多少万滴汗，才挣出那辆车。从风里雨里的咬牙，从饭里茶里的自苦，才赚出那辆车。</span></span><br><span class="line"><span class="string">那辆车是他的一切挣扎与困苦的总结果与报酬，像身经百战的武士的一颗徽章。……他老想</span></span><br><span class="line"><span class="string">着远远的一辆车，可以使他自由，独立，像自己的手脚的那么一辆车。&quot;</span> </span><br><span class="line"> </span><br><span class="line"><span class="string">&quot;他吃，他喝，他嫖，他赌，他懒，他狡猾， 因为他没了心，他的心被人家摘了去。他</span></span><br><span class="line"><span class="string">-------</span></span><br><span class="line"><span class="string">只剩下那个高大的肉架子，等着溃烂，预备着到乱死岗子去。……体面的、要强的、好梦想</span></span><br><span class="line"><span class="string">的、利己的、个人的、健壮的、伟大的祥子，不知陪着人家送了多少回殡；不知道何时何地</span></span><br><span class="line"><span class="string">会埋起他自己来， 埋起这堕落的、 自私的、 不幸的、 社会病胎里的产儿， 个人主义的末路鬼！</span></span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line">-------</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h4 id="举例5自定义分隔符">举例5：自定义分隔符</h4>
<p>有些书写系统没有单词边界，例如中文、日文和泰文。使用默认分隔符列表[“”, “”, " “,”"]分割文 本可能导致单词错误的分割。为了保持单词在一起，你可以自定义分割字符，覆盖分隔符列表以包含额 外的标点符号。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">text_splitter = RecursiveCharacterTextSplitter( chunk_size=<span class="number">200</span>, chunk_overlap=<span class="number">20</span>, <span class="comment"># 增加重叠字符 </span></span><br><span class="line">separators=[ <span class="string">&quot;\n\n&quot;</span> , <span class="string">&quot;\n&quot;</span> , <span class="string">&quot;。&quot;</span> , <span class="string">&quot;！&quot;</span> , <span class="string">&quot;？&quot;</span> , <span class="string">&quot;……&quot;</span> , <span class="string">&quot;，&quot;</span> , <span class="string">&quot;&quot;</span> ], <span class="comment"># 添加中文标点 </span></span><br><span class="line">length_function= <span class="built_in">len</span> , keep_separator=<span class="literal">True</span> <span class="comment">#保留句尾标点（如 ……），避免切割后丢失语气和逻辑 </span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="tokentextsplittercharactertextsplittersplit-by-tokens">TokenTextSplitter/CharacterTextSplitter：Split by tokens</h3>
<p>当我们将文本拆分为块时，除了字符以外，还可以： <strong>按Token的数量分割</strong> （而非字符或单词数），将长 文本切分成多个小块。</p>
<p><strong>什么是Token？</strong> - 对模型而言，Token是文本的最小处理单位。例如： - 英文： “hello” → 1个Token， - 中文： “ChatGPT” → 2个Token（ “Chat” + “GPT” ）。 “人工智能” → 可能拆分为2-3个Token（取决于分词器）。</p>
<p><strong>为什么按Token分割？</strong> - 语言模型对输入长度的限制是基于Token数（如GPT-4的8k/32k Token上限），直接按字符或单 词分割可能导致实际Token数超限。（确保每个文本块不超过模型的Token上限） - 大语言模型(LLM)通常是以token的数量作为其计量(或收费)的依据，所以采用token分割也有助于 我们在使用时更方便的控制成本。</p>
<p><strong>TokenTextSplitter 使用说明</strong>： - 核心依据：Token数量 + 自然边界。（TokenTextSplitter 严格按照 token 数量进行分割，但同时 会优先在自然边界（如句尾）处切断，以尽量保证语义的完整性。） - 优点：与LLM的Token计数逻辑一致，能尽量保持语义完整 - 缺点：对非英语或特定领域文本，Token化效果可能不佳 - 典型场景：需要精确控制Token数输入LLM的场景</p>
<h4 id="举例1使用tokentextsplitter">举例1：使用TokenTextSplitter</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> TokenTextSplitter  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.初始化 TokenTextSplittertext_splitter = TokenTextSplitter(  </span></span><br><span class="line">    chunk_size=<span class="number">33</span>,  <span class="comment">#最大 token 数为 32    chunk_overlap=0, #重叠 token 数为 0    encoding_name=&quot;cl100k_base&quot;,  # 使用 OpenAI 的编码器,将文本转换为 token 序列  </span></span><br><span class="line">  </span><br><span class="line">)  </span><br><span class="line"><span class="comment"># 3.定义文本  </span></span><br><span class="line">text = <span class="string">&quot;人工智能是一个强大的开发框架。它支持多种语言模型和工具链。人工智能是指通过计算机程序模拟人类智能的一门科学。自20世纪50年代诞生以来，人工智能经历了多次起伏。&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.开始切割  </span></span><br><span class="line">texts = text_splitter.split_text(text)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 打印分割结果  </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;原始文本被分割成了 <span class="subst">&#123;<span class="built_in">len</span>(texts)&#125;</span> 个块:&quot;</span>)  </span><br><span class="line"><span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(texts):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;块 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>: 长度：<span class="subst">&#123;<span class="built_in">len</span>(chunk)&#125;</span> 内容：<span class="subst">&#123;chunk&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">50</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">原始文本被分割成了 3 个块:</span><br><span class="line">块 1: 长度：29 内容：人工智能是一个强大的开发框架。它支持多种语言模型和工具链。</span><br><span class="line">--------------------------------------------------</span><br><span class="line">块 2: 长度：32 内容：人工智能是指通过计算机程序模拟人类智能的一门科学。自20世纪50</span><br><span class="line">--------------------------------------------------</span><br><span class="line">块 3: 长度：19 内容：年代诞生以来，人工智能经历了多次起伏。</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure></p>
<p><strong>为什么会出现这样的分割？</strong> 1、<strong>第一块 (29字符)</strong> ：内容是一个完整的句子，以句号结尾。TokenTextSplitter识别到这是一个自然的 语义边界，即使这里的 token 数量可能尚未达到 33，它也选择在此处切割，以保证第一块语义的完整 性。</p>
<p>2、<strong>第二块 (32字符)</strong> ：内容包含了另一个完整句子 “<strong>人工智能是指…一门科学</strong>。”以及下一句的开头 20世纪50” 。分割器在处理完第一个句子的 token 后，可能 token 数量已经接近 “自 chunk_size ，于是 在下一个自然边界（这里是句号）之后继续读取了少量 token（“自20世纪50”），直到非常接近 33 token 的限制。</p>
<p><strong>注意</strong>：“50” 之后被切断，是因为编码器很可能将“50”识别为一个独立的 token，而“年代”是另 一个 token。为了保证 token 的完整性，它不会在“50”字符中间切断。</p>
<p>3、<strong>第三块 (19字符)</strong> ：是第二块中断内容的剩余部分，形成了一个较短的块。这是因为剩余内容本身的 token 数量就较少。 <strong>特别注意：字符长度不等于 Token 数量</strong>。</p>
<h4 id="举例2使用charactertextsplitter">举例2：使用CharacterTextSplitter</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line"><span class="keyword">import</span> tiktoken  <span class="comment"># 用于计算Token数量  </span></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义通过Token切割器  </span></span><br><span class="line">text_splitter = CharacterTextSplitter.from_tiktoken_encoder(  </span><br><span class="line">    encoding_name=<span class="string">&quot;cl100k_base&quot;</span>, <span class="comment"># 使用 OpenAI 的编码器  </span></span><br><span class="line">    chunk_size=<span class="number">18</span>, <span class="comment">#设置最大的token数  </span></span><br><span class="line">    chunk_overlap=<span class="number">0</span>,  </span><br><span class="line">    separator=<span class="string">&quot;。&quot;</span>,  <span class="comment"># 指定中文句号为分隔符  </span></span><br><span class="line">    keep_separator=<span class="literal">False</span>,  <span class="comment"># chunk中是否保留分隔符  </span></span><br><span class="line">)  </span><br><span class="line"><span class="comment"># 3.定义文本  </span></span><br><span class="line">text = <span class="string">&quot;人工智能是一个强大的开发框架。它支持多种语言模型和工具链。今天天气很好，想出去踏青。但是又比较懒不想出去，怎么办&quot;</span>  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.开始切割  </span></span><br><span class="line">texts = text_splitter.split_text(text)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;分割后的块数: <span class="subst">&#123;<span class="built_in">len</span>(texts)&#125;</span>&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.初始化tiktoken编码器（用于Token计数）  </span></span><br><span class="line">encoder = tiktoken.get_encoding(<span class="string">&quot;cl100k_base&quot;</span>)  <span class="comment"># 确保与CharacterTextSplitter的encoding_name一致  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 6.打印每个块的Token数和内容  </span></span><br><span class="line"><span class="keyword">for</span> i, chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(texts):  </span><br><span class="line">    tokens = encoder.encode(chunk)  <span class="comment"># 现在encoder已定义  </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;块 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>: <span class="subst">&#123;<span class="built_in">len</span>(tokens)&#125;</span> Token\n内容: <span class="subst">&#123;chunk&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">分割后的块数: 4</span><br><span class="line">块 1: 17 Token</span><br><span class="line">内容: 人工智能是一个强大的开发框架</span><br><span class="line"></span><br><span class="line">块 2: 14 Token</span><br><span class="line">内容: 它支持多种语言模型和工具链</span><br><span class="line"></span><br><span class="line">块 3: 18 Token</span><br><span class="line">内容: 今天天气很好，想出去踏青</span><br><span class="line"></span><br><span class="line">块 4: 21 Token</span><br><span class="line">内容: 但是又比较懒不想出去，怎么办</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3 id="semanticchunker语义分块">SemanticChunker：语义分块</h3>
<p>SemanticChunking（语义分块）是 LangChain 中一种更高级的文本分割方法，它超越了传统的基于字 符或固定大小的分块方式，而是根据<strong>文本的语义结构</strong>进行智能分块，使每个分块保持<strong>语义完整性</strong>，从而 提高检索增强生成(RAG)等应用的效果。</p>
<p><strong>语义分割 vs 传统分割</strong></p>
<table>
<thead>
<tr class="header">
<th>特性</th>
<th>语义分割（SemanticChunker）</th>
<th>传统字符分割（RecursiveCharacter）</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>分割依据</td>
<td>嵌入向量相似度</td>
<td>固定字符/换行符</td>
</tr>
<tr class="even">
<td>语义完整性</td>
<td>✅ 保持主题连贯</td>
<td>❌ 可能切断句子逻辑</td>
</tr>
<tr class="odd">
<td>计算成本</td>
<td>❌ 高（需嵌入模型）</td>
<td>✅ 低</td>
</tr>
<tr class="even">
<td>适用场景</td>
<td>需要高语义一致性的任务</td>
<td>简单文本预处理</td>
</tr>
</tbody>
</table>
<p>举例： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_experimental.text_splitter <span class="keyword">import</span> SemanticChunker  </span><br><span class="line"><span class="keyword">from</span> langchain_openai.embeddings <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 加载文本  </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;asset/load/09-ai1.txt&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:  </span><br><span class="line">    state_of_the_union = f.read()  <span class="comment">#返回字符串  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 获取嵌入模型  </span></span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = <span class="string">&quot;sk-jdwjsxnkyahrzybuiorfenmjmvaakupdxxxxxxxxx&quot;</span>  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = <span class="string">&quot;https://api.siliconflow.cn/v1&quot;</span>  </span><br><span class="line">embed_model = OpenAIEmbeddings(  </span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 获取切割器  </span></span><br><span class="line">text_splitter = SemanticChunker(  </span><br><span class="line">    embeddings=embed_model,  </span><br><span class="line">    breakpoint_threshold_type=<span class="string">&quot;percentile&quot;</span>,<span class="comment">#断点阈值类型：字面值[&quot;百分位数&quot;, &quot;标准差&quot;, &quot;四分位距&quot;, &quot;梯度&quot;] 选其一  </span></span><br><span class="line">    breakpoint_threshold_amount=<span class="number">65.0</span> <span class="comment">#断点阈值数量 (极低阈值 → 高分割敏感度)  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 切分文档  </span></span><br><span class="line">docs = text_splitter.create_documents(texts = [state_of_the_union])  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs))  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;🔍 文档 <span class="subst">&#123;doc&#125;</span>:&quot;</span>)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">4</span><br><span class="line">🔍 文档 page_content=<span class="string">&#x27;人工智能综述：发展、应用与未来展望</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">摘要</span></span><br><span class="line"><span class="string">人工智能（Artificial Intelligence，AI）作为计算机科学的一个重要分支，近年来取得了突飞猛进的发展。本文综述了人工智能的发展历程、核心技术、应用领域以及未来发展趋势。通过对人工智能的定义、历史背景、主要技术（如机器学习、深度学习、自然语言处理等）的详细介绍，探讨了人工智能在医疗、金融、教育、交通等领域的应用，并分析了人工智能发展过程中面临的挑战与机遇。最后，本文对人工智能的未来发展进行了展望，提出了可能的突破方向。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1.&#x27;</span>:</span><br><span class="line">🔍 文档 page_content=<span class="string">&#x27;引言</span></span><br><span class="line"><span class="string">人工智能是指通过计算机程序模拟人类智能的一门科学。自20世纪50年代诞生以来，人工智能经历了多次起伏，近年来随着计算能力的提升和大数据的普及，人工智能技术取得了显著的进展。人工智能的应用已经渗透到日常生活的方方面面，从智能手机的语音助手到自动驾驶汽车，从医疗诊断到金融分析，人工智能正在改变着人类社会的运行方式。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. 人工智能的发展历程</span></span><br><span class="line"><span class="string">2.1 早期发展</span></span><br><span class="line"><span class="string">人工智能的概念最早可以追溯到20世纪50年代。1956年，达特茅斯会议（Dartmouth Conference）被认为是人工智能研究的正式开端。在随后的几十年里，人工智能研究经历了多次高潮与低谷。早期的研究主要集中在符号逻辑和专家系统上，但由于计算能力的限制和算法的不足，进展缓慢。</span></span><br><span class="line"><span class="string">2.2 机器学习的兴起</span></span><br><span class="line"><span class="string">20世纪90年代，随着统计学习方法的引入，机器学习逐渐成为人工智能研究的主流。支持向量机（SVM）、决策树、随机森林等算法在分类和回归任务中取得了良好的效果。这一时期，机器学习开始应用于数据挖掘、模式识别等领域。</span></span><br><span class="line"><span class="string">2.3 深度学习的突破</span></span><br><span class="line"><span class="string">2012年，深度学习在图像识别领域取得了突破性进展，标志着人工智能进入了一个新的阶段。深度学习通过多层神经网络模拟人脑的工作方式，能够自动提取特征并进行复杂的模式识别。卷积神经网络（CNN）、循环神经网络（RNN）和长短期记忆网络（LSTM）等深度学习模型在图像处理、自然语言处理、语音识别等领域取得了显著成果。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3.&#x27;</span>:</span><br><span class="line">🔍 文档 page_content=<span class="string">&#x27;人工智能的核心技术</span></span><br><span class="line"><span class="string">3.1 机器学习</span></span><br><span class="line"><span class="string">机器学习是人工智能的核心技术之一，通过算法使计算机从数据中学习并做出决策。常见的机器学习算法包括监督学习、无监督学习和强化学习。监督学习通过标记数据进行训练，无监督学习则从未标记数据中寻找模式，强化学习则通过与环境交互来优化决策。</span></span><br><span class="line"><span class="string">3.2 深度学习</span></span><br><span class="line"><span class="string">深度学习是机器学习的一个子领域，通过多层神经网络进行特征提取和模式识别。深度学习在图像识别、自然语言处理、语音识别等领域取得了显著成果。常见的深度学习模型包括卷积神经网络（CNN）、循环神经网络（RNN）和长短期记忆网络（LSTM）。</span></span><br><span class="line"><span class="string">3.3 自然语言处理</span></span><br><span class="line"><span class="string">自然语言处理（NLP）是人工智能的一个重要分支，致力于使计算机能够理解和生成人类语言。NLP技术广泛应用于机器翻译、情感分析、文本分类等领域。近年来，基于深度学习的NLP模型（如BERT、GPT）在语言理解任务中取得了突破性进展。</span></span><br><span class="line"><span class="string">3.4 计算机视觉</span></span><br><span class="line"><span class="string">计算机视觉是人工智能的另一个重要分支，致力于使计算机能够理解和处理图像和视频。计算机视觉技术广泛应用于图像识别、目标检测、人脸识别等领域。深度学习模型（如CNN）在计算机视觉任务中取得了显著成果。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4. 人工智能的应用领域</span></span><br><span class="line"><span class="string">4.1 医疗健康</span></span><br><span class="line"><span class="string">人工智能在医疗健康领域的应用包括疾病诊断、药物研发、个性化医疗等。通过分析医学影像和患者数据，人工智能可以帮助医生更准确地诊断疾病，提高治疗效果。</span></span><br><span class="line"><span class="string">4.2 金融</span></span><br><span class="line"><span class="string">人工智能在金融领域的应用包括风险评估、欺诈检测、算法交易等。通过分析市场数据和交易记录，人工智能可以帮助金融机构做出更明智的决策，提高运营效率。</span></span><br><span class="line"><span class="string">4.3 教育</span></span><br><span class="line"><span class="string">人工智能在教育领域的应用包括个性化学习、智能辅导、自动评分等。通过分析学生的学习数据，人工智能可以为学生提供个性化的学习建议，提高学习效果。</span></span><br><span class="line"><span class="string">4.4 交通</span></span><br><span class="line"><span class="string">人工智能在交通领域的应用包括自动驾驶、交通管理、智能导航等。通过分析交通数据和路况信息，人工智能可以帮助优化交通流量，提高交通安全。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">5. 人工智能的挑战与机遇</span></span><br><span class="line"><span class="string">5.1 挑战</span></span><br><span class="line"><span class="string">人工智能发展过程中面临的主要挑战包括数据隐私、算法偏见、安全性问题等。数据隐私问题涉及到个人数据的收集和使用，算法偏见问题则涉及到算法的公平性和透明度，安全性问题则涉及到人工智能系统的可靠性和稳定性。</span></span><br><span class="line"><span class="string">5.2 机遇</span></span><br><span class="line"><span class="string">尽管面临挑战，人工智能的发展也带来了巨大的机遇。人工智能技术的进步将推动各行各业的创新，提高生产效率，改善生活质量。未来，人工智能有望在更多领域取得突破，为人类社会带来更多的便利和福祉。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">6.&#x27;</span>:</span><br><span class="line">🔍 文档 page_content=<span class="string">&#x27;未来展望</span></span><br><span class="line"><span class="string">6.1 技术突破</span></span><br><span class="line"><span class="string">未来，人工智能技术有望在以下几个方面取得突破：一是算法的优化和创新，提高模型的效率和准确性；二是计算能力的提升，支持更复杂的模型和更大规模的数据处理；三是跨学科研究的深入，推动人工智能与其他领域的融合。</span></span><br><span class="line"><span class="string">6.2 应用拓展</span></span><br><span class="line"><span class="string">随着技术的进步，人工智能的应用领域将进一步拓展。未来，人工智能有望在更多领域发挥重要作用，如环境保护、能源管理、智能制造等。人工智能将成为推动社会进步的重要力量。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">7. 结论</span></span><br><span class="line"><span class="string">人工智能作为一门快速发展的科学，正在改变着人类社会的运行方式。通过不断的技术创新和应用拓展，人工智能将为人类社会带来更多的便利和福祉。然而，人工智能的发展也面临着诸多挑战，需要社会各界共同努力，推动人工智能的健康发展。&#x27;</span>:</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p><strong>关于参数的说明：</strong> 1. breakpoint_threshold_type （断点阈值类型） - 作用：定义文本语义边界的检测算法，决定何时分割文本块。 - 可选值及原理：</p>
<table>
<thead>
<tr class="header">
<th>类型</th>
<th>原理说明</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>percentile</td>
<td>计算相邻句子嵌入向量的余弦距离，取<strong>距离分 布的第N百分位</strong>值作为阈值，高于此值则分割</td>
<td>常规文本（如文 章、报告）</td>
</tr>
<tr class="even">
<td>standard_deviation</td>
<td>以<strong>均值 + N倍</strong>标准差为阈值，识别语义突变 点</td>
<td>语义变化剧烈的 文档（如技术手 册）</td>
</tr>
<tr class="odd">
<td>interquartile</td>
<td>用<strong>四分位距（IQR）</strong> 定义异常值边界，超过则 分割</td>
<td>长文档（如书 籍）</td>
</tr>
<tr class="even">
<td>gradient</td>
<td>基于<strong>嵌入向量变化的梯度</strong>检测分割点（需自定 义实现）</td>
<td>实验性需求</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li>breakpoint_threshold_amount （断点阈值量）</li>
</ol>
<ul>
<li>作用：控制分割的<strong>粒度敏感度</strong>，值越小分割越细（块越多），值越大分割越粗（块越少）。 取值范围与示例：
<ul>
<li><strong>percentile</strong> 模式：0.0~100.0，用户代码设 65.0 表示仅当余弦距离 &gt; 所有距离中最低的 65.0%值时分割 。默认值是：95.0，兼顾语义完整性与检索效率。值过小（比如0.1），会产 生大量小文本块，过度分割可能导致上下文断裂。</li>
<li><strong>standard_deviation</strong> 模式：浮点数（如 1.5 表示均值+1.5倍标准差）。</li>
<li><strong>interquartile</strong> 模式：倍数（如1.5 是IQR标准值）。</li>
</ul></li>
</ul>
<h3 id="其它拆分器">其它拆分器</h3>
<h4 id="类型1htmlheadertextsplittersplit-by-html-header">类型1：HTMLHeaderTextSplitter：Split by HTML header</h4>
<p>HTMLHeaderTextSplitter是一种专门用于处理HTML文档的文本分割方法，它根据HTML的<strong>标题标签（如&lt;h1&gt;,&lt;h2&gt;等）</strong> 将文档划分为逻辑分块，同时保留标题的层级结构信息。 举例： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖 </span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> HTMLHeaderTextSplitter </span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.定义HTML文件 </span></span><br><span class="line">html_string = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">次处是html文件内容</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 4.用于指定要根据哪些HTML标签来分割文本 </span></span><br><span class="line">headers_to_split_on = [ </span><br><span class="line">	(  <span class="string">&quot;h1&quot;</span> , <span class="string">&quot;标题1&quot;</span> ),</span><br><span class="line">	(  <span class="string">&quot;h2&quot;</span> , <span class="string">&quot;标题2&quot;</span> ), </span><br><span class="line">	( <span class="string">&quot;h3&quot;</span> , <span class="string">&quot;标题3&quot;</span> ),</span><br><span class="line">	] </span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.定义HTMLHeaderTextSplitter分割器 </span></span><br><span class="line">html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.分割器分割 </span></span><br><span class="line">html_header_splits = html_splitter.split_text(html_string) </span><br><span class="line">html_header_splits</span><br></pre></td></tr></table></figure></p>
<p>说明： - 标题下文本内容所属标题的层级信息保存在元数据中。 - 每个分块会自动继承父级标题的上下文，避免信息割裂。</p>
<h4 id="类型2codetextsplittersplit-code">类型2：CodeTextSplitter：Split code</h4>
<p>CodeTextSplitter是一个 专为代码文件设计的文本分割器（Text Splitter），支持代码的语言包括[‘cpp’, ‘go’, ‘java’, ‘js’, ‘php’, ‘proto’, ‘python’, ‘rst’, ‘ruby’, ‘rust’, ‘scala’, ‘swift’, ‘markdown’, ‘latex’, ‘html’, ‘sol’]。它能够根据编程语言的语法结构（如函数、类、代码块等）智能地拆分代码，保持代码逻辑的完 整性。</p>
<p>与递归文本分割器（如RecursiveCharacterTextSplitter）不同，CodeTextSplitter 针对代码的特性进 行了优化， <strong>避免在函数或类的中间截断</strong>。</p>
<p>举例1：支持的语言 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install langchain-text-splitters</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="string">&#x27;</span></span><br><span class="line"><span class="string">import Language </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 支持分割语言类型 </span></span><br><span class="line"><span class="string"># Full list of supported languages &#x27;</span></span><br><span class="line"></span><br><span class="line">langs = [e.value <span class="keyword">for</span> e <span class="keyword">in</span> Language] </span><br><span class="line"><span class="built_in">print</span> (langs)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[cpp, go, java, kotlin, js, ts, php, proto, python, rst, ruby, rust, scala, swift, markdown, latex, html, sol, csharp, cobol, c, lua, perl, haskell, elixir, powershell]</span><br></pre></td></tr></table></figure>
<p>举例2： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> (  </span><br><span class="line">    Language,  </span><br><span class="line">    RecursiveCharacterTextSplitter,  </span><br><span class="line"> )  </span><br><span class="line"><span class="keyword">from</span> pprint <span class="keyword">import</span> pprint  </span><br><span class="line"> <span class="comment"># 2.定义要分割的python代码片段  </span></span><br><span class="line">PYTHON_CODE = <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string"> def hello_world():    </span></span><br><span class="line"><span class="string">	 print(&quot;Hello, World!&quot;) </span></span><br><span class="line"><span class="string">	 </span></span><br><span class="line"><span class="string">def hello_world1():    </span></span><br><span class="line"><span class="string">	print(&quot;Hello, World1!&quot;) &quot;&quot;&quot;</span> <span class="comment"># 3.定义递归字符切分器  </span></span><br><span class="line">python_splitter = RecursiveCharacterTextSplitter.from_language(  </span><br><span class="line">    language=Language.PYTHON,  </span><br><span class="line">    chunk_size=<span class="number">50</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">0</span>  </span><br><span class="line"> )  </span><br><span class="line"> <span class="comment"># 4.文档切分  </span></span><br><span class="line">python_docs = python_splitter.create_documents(texts=[PYTHON_CODE])  </span><br><span class="line">pprint(python_docs)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[Document(metadata=&#123;&#125;, page_content=<span class="string">&#x27;def hello_world():\n   print(&quot;Hello, World!&quot;)&#x27;</span>),</span><br><span class="line"> Document(metadata=&#123;&#125;, page_content=<span class="string">&#x27;def hello_world1():\n   print(&quot;Hello, World1!&quot;)&#x27;</span>)]</span><br></pre></td></tr></table></figure></p>
<h4 id="类型3markdowntextsplittermd数据类型">类型3：MarkdownTextSplitter：md数据类型</h4>
<p>因为Markdown格式有特定的语法，一般整体内容由 <strong>h1、h2、h3</strong> 等多级标题组织，所以 MarkdownHeaderTextSplitter的切分策略就是根据 <strong>标题来分割文本内容</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> MarkdownTextSplitter  </span><br><span class="line">markdown_text = <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string"> # 一级标题\n  </span></span><br><span class="line"><span class="string">这是一级标题下的内容\n\n  </span></span><br><span class="line"><span class="string"> ## 二级标题\n- 二级下列表项1\n- 二级下列表项2\n  </span></span><br><span class="line"><span class="string"> &quot;&quot;&quot;</span> <span class="comment"># 关键步骤：直接修改实例属性  </span></span><br><span class="line">splitter = MarkdownTextSplitter(chunk_size=<span class="number">30</span>, chunk_overlap=<span class="number">0</span>)  </span><br><span class="line">splitter._is_separator_regex = <span class="literal">True</span>  <span class="comment">#  强制将分隔符视为正则表达式  </span></span><br><span class="line"><span class="comment"># print(len(docs))  </span></span><br><span class="line"><span class="comment"># 执行分割  </span></span><br><span class="line">docs = splitter.create_documents(texts = [markdown_text])  </span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n🔍 分块 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>:&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(doc.page_content)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">🔍 分块 1:</span><br><span class="line"><span class="comment"># 一级标题</span></span><br><span class="line"></span><br><span class="line">这是一级标题下的内容</span><br><span class="line"></span><br><span class="line">🔍 分块 2:</span><br><span class="line"><span class="comment">## 二级标题</span></span><br><span class="line">- 二级下列表项1</span><br><span class="line"></span><br><span class="line">🔍 分块 3:</span><br><span class="line">- 二级下列表项2</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h1 id="文档嵌入模型-text-embedding-models">文档嵌入模型 Text Embedding Models</h1>
<h2 id="嵌入模型概述">嵌入模型概述</h2>
<p><strong>Text Embedding Models</strong>：文档嵌入模型，提供将文本编码为向量的能力，即<strong>文档向量化</strong> ，<strong>文档写入</strong>和<strong>用户 查询匹配</strong>前都会先执行文档嵌入编码，即向量化。 <img src="file-20250928094827404.png" alt="500" /></p>
<p>LangChain中针对向量化模型的封装提供了两种接口，一种针对<strong>文档的向量化(embed_documents)</strong>，一 种针对<strong>句子的向量化embed_query。</strong></p>
<h2 id="句子的向量化embed_query">句子的向量化（embed_query）</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = os.getenv(<span class="string">&quot;SILICONFLOW_API_KEY&quot;</span>)  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = os.getenv(<span class="string">&quot;BASE_URL&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">embedding_model = OpenAIEmbeddings(  </span><br><span class="line">    <span class="comment"># model=&quot;text-embedding-ada-002&quot;  </span></span><br><span class="line">    model = <span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">text = <span class="string">&quot;Nice to meet you!&quot;</span>  </span><br><span class="line">  </span><br><span class="line">embed_query = embedding_model.embed_query(text = text,)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(embed_query))  <span class="comment"># 1536 --&gt; 3072  </span></span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(embed_query[:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1024</span><br><span class="line">[-0.014332670718431473, -0.02295164205133915, -0.01733478531241417, -0.006827387027442455, 0.04202958941459656, -0.028665341436862946, -0.023823224008083344, -0.031376928091049194, -0.09374341368675232, 0.08986972272396088]</span><br></pre></td></tr></table></figure></p>
<h2 id="文档的向量化embed_documents">文档的向量化（embed_documents）</h2>
<p>文档的向量化，接收的参数是字符串数组。</p>
<h3 id="举例1-1">举例1</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = os.getenv(<span class="string">&quot;SILICONFLOW_API_KEY&quot;</span>)  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = os.getenv(<span class="string">&quot;BASE_URL&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 初始化嵌入模型  </span></span><br><span class="line">embeddings_model = OpenAIEmbeddings(model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 待嵌入的文本列表  </span></span><br><span class="line">texts = [  </span><br><span class="line">    <span class="string">&quot;Hi there!&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;Oh, hello!&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;What&#x27;s your name?&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;My friends call me World&quot;</span>,  </span><br><span class="line">    <span class="string">&quot;Hello World!&quot;</span>  </span><br><span class="line">]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 生成嵌入向量  </span></span><br><span class="line">embeddings = embeddings_model.embed_documents(texts)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(texts)):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;texts[i]&#125;</span>:<span class="subst">&#123;embeddings[i][:<span class="number">3</span>]&#125;</span>&quot;</span>,end=<span class="string">&quot;\n\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Hi there!:[-0.005018789321184158, -0.02362913265824318, -0.015080382116138935]</span><br><span class="line"></span><br><span class="line">Oh, hello!:[-0.016794802621006966, 0.0015314100310206413, -0.013306026346981525]</span><br><span class="line"></span><br><span class="line">What<span class="string">&#x27;s your name?:[-0.0057384539395570755, -0.011427008546888828, -0.018862050026655197]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">My friends call me World:[0.01912776567041874, 0.0315045565366745, -0.013761605136096478]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Hello World!:[0.0033330952282994986, 0.017623262479901314, -0.011646676808595657]</span></span><br></pre></td></tr></table></figure></p>
<h3 id="举例2-1">举例2</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> CSVLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">embeddings_model = OpenAIEmbeddings(  </span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 情况1：  </span></span><br><span class="line">loader = CSVLoader(<span class="string">&quot;./asset/load/03-load.csv&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)  </span><br><span class="line">docs = loader.load_and_split()  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#print(len(docs))  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 存放的是每一个chrunk的embedding。  </span></span><br><span class="line">embeded_docs = embeddings_model.embed_documents([doc.page_content <span class="keyword">for</span> doc <span class="keyword">in</span> docs])  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(embeded_docs))  </span><br><span class="line"><span class="comment"># 表示的是每一个chrunk的embedding的维度  </span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(embeded_docs[<span class="number">0</span>]))  </span><br><span class="line"><span class="built_in">print</span>(embeded_docs[<span class="number">0</span>][:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">4</span><br><span class="line">1024</span><br><span class="line">[0.020796308293938637, -0.06914985924959183, -0.016174905002117157, -0.02148095890879631, 0.004043726250529289, 0.018742350861430168, 0.04381773620843887, 0.07394243031740189, -0.06641125679016113, 0.03834051638841629]</span><br></pre></td></tr></table></figure></p>
<h1 id="向量存储vector-stores">向量存储(Vector Stores)</h1>
<h2 id="理解向量存储">理解向量存储</h2>
<p>将文本向量化之后，下一步就是进行向量的存储。这部分包含两块： - <strong>向量的存储</strong>：将非结构化数据向量化后，完成存储 - <strong>向量的查询</strong>：查询时，嵌入非结构化查询并检索与嵌入查询“最相似”的嵌入向量。即具有相似性 检索能力</p>
<figure>
<img src="file-20250928095510561.png" alt="500" /><figcaption aria-hidden="true">500</figcaption>
</figure>
<h2 id="常用的向量数据库">常用的向量数据库</h2>
<p>LangChain提供了超过 50种 不同向量存储（Vector Stores）的集成，从开源的 本地向量存储到 云托管的私有向量存储，允许你选择最适合需求的向量存储。 LangChain支持的向量存储参考 VectorStore 接口和实现。 <img src="file-20250928095622717.png" alt="500" /></p>
<p>典型的介绍如下：</p>
<table>
<colgroup>
<col style="width: 10%" />
<col style="width: 89%" />
</colgroup>
<thead>
<tr class="header">
<th>向量数据库</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Chroma</strong></td>
<td>开源、免费的嵌入式数据库</td>
</tr>
<tr class="even">
<td>FAISS</td>
<td>Meta出品，开源、免费，Facebook AI相似性搜索服务。（Facebook AI Similarity Search，Facebook AI 相似性搜索库） /fæs/</td>
</tr>
<tr class="odd">
<td>Milvus</td>
<td>用于存储、索引和管理由深度神经网络和其他ML模型产生的大量嵌入向量的数据库</td>
</tr>
<tr class="even">
<td>Pinecone</td>
<td>具有广泛功能的向量数据库</td>
</tr>
<tr class="odd">
<td>Redis</td>
<td>基于Redis的检索器</td>
</tr>
</tbody>
</table>
<h2 id="代码实现">代码实现</h2>
<p>使用向量数据库组件时需要同时传入包含<strong>文本块的Document类对象</strong>以及<strong>文本向量化组件</strong>，向量数据库组 件会自动完成将文本向量化的工作，并写入数据库中。</p>
<h3 id="数据的存储">数据的存储</h3>
<h4 id="举例1从txt文档中加载数据向量化后存储到chroma数据库">举例1：从TXT文档中加载数据，向量化后存储到Chroma数据库</h4>
<p>安装模块： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install chromadb </span><br><span class="line">pip install langchain-chroma</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> TextLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = os.getenv(<span class="string">&quot;SILICONFLOW_API_KEY&quot;</span>)  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = os.getenv(<span class="string">&quot;BASE_URL&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 步骤1：创建一个TextLoader的实例，并将指定的文档加载  </span></span><br><span class="line">loader = TextLoader(  </span><br><span class="line">    file_path=<span class="string">&quot;./asset/load/09-ai1.txt&quot;</span>,  </span><br><span class="line">    encoding=<span class="string">&quot;utf-8&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = loader.load()  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 步骤2：创建文本拆分器，并拆分文档  </span></span><br><span class="line">text_splitter = CharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">1000</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">100</span>,  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">splitter_docs = text_splitter.split_documents(docs)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># print(len(splitter_docs))  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 步骤3：创建嵌入模型  </span></span><br><span class="line">embedding_model = OpenAIEmbeddings(model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 步骤4：将文档及嵌入模型传入到Chroma相关的结构中，进行数据的存储  </span></span><br><span class="line">db = Chroma.from_documents(  </span><br><span class="line">    documents=splitter_docs,  </span><br><span class="line">    embedding=embedding_model,  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>思考：此时数据存储在哪里呢？</strong> 注意：Chroma主要有两种存储模式：<strong>内存模式</strong>和<strong>持久化模式</strong>。当使用persist_directory参数时，数据 会保存到指定目录；如果没有指定，则默认使用内存存储。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">db1 = Chroma.from_documents(  </span><br><span class="line">    documents=splitter_docs,  </span><br><span class="line">    embedding=embedding_model,  </span><br><span class="line">    persist_directory=<span class="string">&quot;./asset/chroma-1&quot;</span>,  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>2、需要明确，在向量数据库中，不仅存储了数据（或文档）的向量，而且还存储了数据（或文档）本身。</p>
<hr />
<p>演示一下：检索的需求 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;人工智能的核心技术有哪些呢？&quot;</span>  </span><br><span class="line">  </span><br><span class="line">docs = db.similarity_search(query)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(docs[<span class="number">0</span>].page_content)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">5. 人工智能的挑战与机遇</span><br><span class="line">5.1 挑战</span><br><span class="line">人工智能发展过程中面临的主要挑战包括数据隐私、算法偏见、安全性问题等。数据隐私问题涉及到个人数据的收集和使用，算法偏见问题则涉及到算法的公平性和透明度，安全性问题则涉及到人工智能系统的可靠性和稳定性。</span><br><span class="line">5.2 机遇</span><br><span class="line">尽管面临挑战，人工智能的发展也带来了巨大的机遇。人工智能技术的进步将推动各行各业的创新，提高生产效率，改善生活质量。未来，人工智能有望在更多领域取得突破，为人类社会带来更多的便利和福祉。</span><br><span class="line"></span><br><span class="line">6. 未来展望</span><br><span class="line">6.1 技术突破</span><br><span class="line">未来，人工智能技术有望在以下几个方面取得突破：一是算法的优化和创新，提高模型的效率和准确性；二是计算能力的提升，支持更复杂的模型和更大规模的数据处理；三是跨学科研究的深入，推动人工智能与其他领域的融合。</span><br><span class="line">6.2 应用拓展</span><br><span class="line">随着技术的进步，人工智能的应用领域将进一步拓展。未来，人工智能有望在更多领域发挥重要作用，如环境保护、能源管理、智能制造等。人工智能将成为推动社会进步的重要力量。</span><br><span class="line"></span><br><span class="line">7. 结论</span><br><span class="line">人工智能作为一门快速发展的科学，正在改变着人类社会的运行方式。通过不断的技术创新和应用拓展，人工智能将为人类社会带来更多的便利和福祉。然而，人工智能的发展也面临着诸多挑战，需要社会各界共同努力，推动人工智能的健康发展。</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h4 id="举例2操作csv文档并向量化">举例2：操作csv文档，并向量化</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> CSVLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = os.getenv(<span class="string">&quot;SILICONFLOW_API_KEY&quot;</span>)  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = os.getenv(<span class="string">&quot;BASE_URL&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 获取嵌入模型  </span></span><br><span class="line">embeddings = OpenAIEmbeddings(model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 加载文档并拆分（第1次拆分）  </span></span><br><span class="line">loader = CSVLoader(<span class="string">&quot;./asset/load/03-load.csv&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)  </span><br><span class="line">pages = loader.load_and_split()  </span><br><span class="line"><span class="comment">#print(len(pages))  # 4  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 文本拆分（第2次拆分）  </span></span><br><span class="line">text_spliter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=<span class="number">500</span>)  </span><br><span class="line">docs = text_spliter.split_documents(pages)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 向量存储  </span></span><br><span class="line">db_path = <span class="string">&#x27;./asset/chroma-2&#x27;</span>  </span><br><span class="line">db = Chroma.from_documents(docs, embeddings, persist_directory=db_path)</span><br></pre></td></tr></table></figure>
<h3 id="数据的检索">数据的检索</h3>
<p>举例：一个包含构建Chroma向量数据库以及向量检索的代码 前置代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain_chroma <span class="keyword">import</span> Chroma  </span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义文档  </span></span><br><span class="line">raw_documents = [  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;葡萄是一种常见的水果，属于葡萄科葡萄属植物。它的果实呈圆形或椭圆形，颜色有绿色、紫色、红色等多种。葡萄富含维生素C和抗氧化物质，可以直接食用或酿造成葡萄酒。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;水果&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;植物&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;白菜是十字花科蔬菜，原产于中国北方。它的叶片层层包裹形成紧密的球状，口感清脆微甜。白菜富含膳食纤维和维生素K，常用于制作泡菜、炒菜或煮汤。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;蔬菜&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;植物&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;动物&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;哺乳动物&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;猫是小型肉食性哺乳动物，性格独立但也能与人类建立亲密关系。它们夜视能力极强，擅长捕猎老鼠。家猫的品种包括波斯猫、暹罗猫等，毛色和花纹多样。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;动物&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;哺乳动物&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;人类是地球上最具智慧的生物，属于灵长目人科。现代人类（智人）拥有高度发达的大脑，创造了语言、工具和文明。人类的平均寿命约70-80年，分布在全球各地。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;生物&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;灵长类&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;太阳是太阳系的中心恒星，直径约139万公里，主要由氢和氦组成。它通过核聚变反应产生能量，为地球提供光和热。太阳活动周期约为11年，会影响地球气候。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;天文&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;恒星&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;长城是中国古代的军事防御工程，总长度超过2万公里。它始建于春秋战国时期，秦朝连接各段，明朝大规模重修。长城是世界文化遗产和人类建筑奇迹。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;历史&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;建筑&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;量子力学是研究微观粒子运动规律的物理学分支。它提出了波粒二象性、测不准原理等概念，彻底改变了人类对物质世界的认知。量子计算机正是基于这一理论发展而来。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;物理&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;科学&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;《红楼梦》是中国古典文学四大名著之一，作者曹雪芹。小说以贾、史、王、薛四大家族的兴衰为背景，描绘了贾宝玉与林黛玉的爱情悲剧，反映了封建社会的种种矛盾。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;文学&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;小说&quot;</span>&#125;  </span><br><span class="line">    ),  </span><br><span class="line">    Document(  </span><br><span class="line">        page_content=<span class="string">&quot;新冠病毒（SARS-CoV-2）是一种可引起呼吸道疾病的冠状病毒。它通过飞沫传播，主要症状包括发热、咳嗽、乏力。疫苗和戴口罩是有效的预防措施。&quot;</span>,  </span><br><span class="line">        metadata=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;医学&quot;</span>, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;病毒&quot;</span>&#125;  </span><br><span class="line">    )  </span><br><span class="line">]  </span><br><span class="line"><span class="comment"># 3. 创建嵌入模型  </span></span><br><span class="line">embedding = OpenAIEmbeddings(model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.创建向量数据库  </span></span><br><span class="line">db = Chroma.from_documents(  </span><br><span class="line">    documents=raw_documents,  </span><br><span class="line">    embedding=embedding,  </span><br><span class="line">    persist_directory=<span class="string">&quot;./asset/chroma-3&quot;</span>,  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="相似性检索similarity_search">① 相似性检索（similarity_search）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5. 检索示例（返回前3个最相关结果）  </span></span><br><span class="line">query = <span class="string">&quot;哺乳动物&quot;</span>  </span><br><span class="line">docs = db.similarity_search(query, k=<span class="number">3</span>)  <span class="comment"># k=3表示返回3个最相关文档  </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;查询: &#x27;<span class="subst">&#123;query&#125;</span>&#x27; 的结果:&quot;</span>)  </span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs, <span class="number">1</span>):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n结果 <span class="subst">&#123;i&#125;</span>:&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;内容: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;元数据: <span class="subst">&#123;doc.metadata&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">查询: <span class="string">&#x27;哺乳动物&#x27;</span> 的结果:</span><br><span class="line"></span><br><span class="line">结果 1:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">结果 2:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">结果 3:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="支持直接对问题向量查询similarity_search_by_vector">② 支持直接对问题向量查询（similarity_search_by_vector）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;哺乳动物&quot;</span>  </span><br><span class="line">embedding_vector = embedding.embed_query(query)  </span><br><span class="line">  </span><br><span class="line">docs = db.similarity_search_by_vector(embedding_vector, k=<span class="number">3</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;查询: &#x27;<span class="subst">&#123;query&#125;</span>&#x27; 的结果:&quot;</span>)  </span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs, <span class="number">1</span>):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n结果 <span class="subst">&#123;i&#125;</span>:&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;内容: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;元数据: <span class="subst">&#123;doc.metadata&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">查询: <span class="string">&#x27;哺乳动物&#x27;</span> 的结果:</span><br><span class="line"></span><br><span class="line">结果 1:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">结果 2:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">结果 3:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h4 id="相似性检索支持过滤元数据filter">③ 相似性检索，支持过滤元数据（filter）</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;哺乳动物&quot;</span>  </span><br><span class="line">  </span><br><span class="line">docs = db.similarity_search(  </span><br><span class="line">    query=query,  </span><br><span class="line">    k=<span class="number">3</span>,  </span><br><span class="line">    <span class="built_in">filter</span>=&#123;<span class="string">&quot;source&quot;</span>: <span class="string">&quot;动物&quot;</span>&#125;)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs, <span class="number">1</span>):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n结果 <span class="subst">&#123;i&#125;</span>:&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;内容: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;元数据: <span class="subst">&#123;doc.metadata&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">结果 1:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">结果 2:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">结果 3:</span><br><span class="line">内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">元数据: &#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h4 id="通过l2距离分数进行搜索similarity_search_with_score">④ 通过L2距离分数进行搜索（similarity_search_with_score）</h4>
<p>说明：分数值越小，检索到的文档越和问题相似。分值取值范围：[0，正无穷] <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docs = db.similarity_search_with_score(  </span><br><span class="line">    <span class="string">&quot;量子力学是什么?&quot;</span>  </span><br><span class="line">)  </span><br><span class="line"><span class="keyword">for</span> doc, score <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot; [L2距离得分=<span class="subst">&#123;score:<span class="number">.3</span>f&#125;</span>] <span class="subst">&#123;doc.page_content&#125;</span> [<span class="subst">&#123;doc.metadata&#125;</span>]&quot;</span>)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[L2距离得分=1.055] 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。 [&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>&#125;]</span><br><span class="line">[L2距离得分=1.057] 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。 [&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>&#125;]</span><br><span class="line">[L2距离得分=1.058] 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。 [&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>&#125;]</span><br><span class="line">[L2距离得分=1.071] 人类是地球上最具智慧的生物，属于灵长目人科。现代人类（智人）拥有高度发达的大脑，创造了语言、工具和文明。人类的平均寿命约70-80年，分布在全球各地。 [&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;生物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;灵长类&#x27;</span>&#125;]</span><br></pre></td></tr></table></figure></p>
<h4 id="通过余弦相似度分数进行搜索_similarity_search_with_relevance_scores">⑤ 通过余弦相似度分数进行搜索（_similarity_search_with_relevance_scores）</h4>
<p>说明：分数值越接近1（上限），检索到的文档越和问题相似。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docs = db._similarity_search_with_relevance_scores(  </span><br><span class="line">    <span class="string">&quot;量子力学是什么?&quot;</span>  </span><br><span class="line">)  </span><br><span class="line"><span class="keyword">for</span> doc, score <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;* [余弦相似度得分=<span class="subst">&#123;score:<span class="number">.3</span>f&#125;</span>] <span class="subst">&#123;doc.page_content&#125;</span> [<span class="subst">&#123;doc.metadata&#125;</span>]&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">* [余弦相似度得分=0.254] 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。 [&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>&#125;]</span><br><span class="line">* [余弦相似度得分=0.253] 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。 [&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>&#125;]</span><br><span class="line">* [余弦相似度得分=0.252] 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。 [&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;动物&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;哺乳动物&#x27;</span>&#125;]</span><br><span class="line">* [余弦相似度得分=0.243] 人类是地球上最具智慧的生物，属于灵长目人科。现代人类（智人）拥有高度发达的大脑，创造了语言、工具和文明。人类的平均寿命约70-80年，分布在全球各地。 [&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;灵长类&#x27;</span>, <span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;生物&#x27;</span>&#125;]</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h4 id="mmr最大边际相关性max_marginal_relevance_search">⑥ MMR（最大边际相关性，max_marginal_relevance_search）</h4>
<p>MMR 是一种平衡<code>相关性</code> 和<code>多样性</code>的检索策略，避免返回高度相似的冗余结果。</p>
<p>参数说明： <strong>lambda_mult</strong> 参数值介于 0 到 1 之间，用于确定结果之间的多样性程度，其中 0 对应最大 多样性，1 对应最小多样性。默认值为 0.5。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">docs = db.max_marginal_relevance_search(  </span><br><span class="line">    query=<span class="string">&quot;量子力学是什么&quot;</span>,  </span><br><span class="line">    lambda_mult=<span class="number">0.8</span>,  <span class="comment"># 侧重相似性  </span></span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🔍 关于【量子力学是什么】的搜索结果：&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span> * <span class="number">50</span>)  </span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n📖 结果 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>:&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;📌 内容: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;🏷️ 标签: <span class="subst">&#123;<span class="string">&#x27;, &#x27;</span>.join(<span class="string">f&#x27;<span class="subst">&#123;k&#125;</span>=<span class="subst">&#123;v&#125;</span>&#x27;</span> <span class="keyword">for</span> k, v <span class="keyword">in</span> doc.metadata.items())&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">🔍 关于【量子力学是什么】的搜索结果：</span><br><span class="line">==================================================</span><br><span class="line"></span><br><span class="line">📖 结果 1:</span><br><span class="line">📌 内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">🏷️ 标签: <span class="built_in">type</span>=哺乳动物, <span class="built_in">source</span>=动物</span><br><span class="line"></span><br><span class="line">📖 结果 2:</span><br><span class="line">📌 内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">🏷️ 标签: <span class="built_in">source</span>=动物, <span class="built_in">type</span>=哺乳动物</span><br><span class="line"></span><br><span class="line">📖 结果 3:</span><br><span class="line">📌 内容: 狗是人类最早驯化的动物之一，属于犬科。它们具有高度社会性，能理解人类情绪，常被用作宠物、导盲犬或警犬。不同品种的狗在体型、毛色和性格上有很大差异。</span><br><span class="line">🏷️ 标签: <span class="built_in">type</span>=哺乳动物, <span class="built_in">source</span>=动物</span><br><span class="line"></span><br><span class="line">📖 结果 4:</span><br><span class="line">📌 内容: 人类是地球上最具智慧的生物，属于灵长目人科。现代人类（智人）拥有高度发达的大脑，创造了语言、工具和文明。人类的平均寿命约70-80年，分布在全球各地。</span><br><span class="line">🏷️ 标签: <span class="built_in">type</span>=灵长类, <span class="built_in">source</span>=生物</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h1 id="检索器召回器-retrievers">检索器(召回器) Retrievers</h1>
<p>从“向量存储组件”的代码实现5.4.2中可以看到，向量数据库本身已经包含了实现召回功能的函数方法 (<strong>similarity_search</strong> )。该函数通过计算原始查询向量与数据库中存储向量之间的相似度来实现召回。</p>
<p>LangChain还提供了 <strong>更加复杂的召回策略</strong>，这些策略被集成在Retrievers（检索器或召回器）组件中。</p>
<p>Retrievers（检索器）是一种用于从大量文档中检索与给定查询相关的文档或信息片段的工具。检索器 <strong>不需要存储文档</strong>，只需要 <strong>返回（或检索）文档</strong>即可。 <img src="file-20250928102015858.png" /></p>
<p><strong>Retrievers 的执行步骤：</strong></p>
<ul>
<li>步骤1：将输入查询转换为向量表示。</li>
<li>步骤2：在向量存储中搜索与查询向量最相似的文档向量（通常使用余弦相似度或欧几里得距离等度量方 法）。</li>
<li>步骤3：返回与查询最相关的文档或文本片段，以及它们的相似度得分。</li>
</ul>
<h2 id="代码实现-1">代码实现</h2>
<p>Retriever 一般和 VectorStore 配套实现，通过as_retriever() 方法获取。 举例： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> TextLoader  </span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_text_splitters <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义文档加载器  </span></span><br><span class="line">loader = TextLoader(file_path=<span class="string">&#x27;./asset/load/09-ai1.txt&#x27;</span>,encoding=<span class="string">&quot;utf-8&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.加载文档  </span></span><br><span class="line">documents = loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.定义文本切割器  </span></span><br><span class="line">text_splitter = CharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">100</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5.切割文档  </span></span><br><span class="line">docs = text_splitter.split_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 6.定义嵌入模型  </span></span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = os.getenv(<span class="string">&quot;SILICONFLOW_API_KEY&quot;</span>)  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = os.getenv(<span class="string">&quot;BASE_URL&quot;</span>)  </span><br><span class="line">embeddings = OpenAIEmbeddings(  </span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>  </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取向量数据库  </span></span><br><span class="line">db = FAISS.from_documents(documents=docs,embedding=embeddings)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 基于向量数据库获取检索器  </span></span><br><span class="line">retriever = db.as_retriever()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 进行数据的检索  </span></span><br><span class="line">docs = retriever.invoke(<span class="built_in">input</span> = <span class="string">&quot;深度学习是什么？&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs))  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;------<span class="subst">&#123;doc&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">3</span><br><span class="line">------page_content=<span class="string">&#x27;5. 人工智能的挑战与机遇</span></span><br><span class="line"><span class="string">5.1 挑战</span></span><br><span class="line"><span class="string">人工智能发展过程中面临的主要挑战包括数据隐私、算法偏见、安全性问题等。数据隐私问题涉及到个人数据的收集和使用，算法偏见问题则涉及到算法的公平性和透明度，安全性问题则涉及到人工智能系统的可靠性和稳定性。</span></span><br><span class="line"><span class="string">5.2 机遇</span></span><br><span class="line"><span class="string">尽管面临挑战，人工智能的发展也带来了巨大的机遇。人工智能技术的进步将推动各行各业的创新，提高生产效率，改善生活质量。未来，人工智能有望在更多领域取得突破，为人类社会带来更多的便利和福祉。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">6. 未来展望</span></span><br><span class="line"><span class="string">6.1 技术突破</span></span><br><span class="line"><span class="string">未来，人工智能技术有望在以下几个方面取得突破：一是算法的优化和创新，提高模型的效率和准确性；二是计算能力的提升，支持更复杂的模型和更大规模的数据处理；三是跨学科研究的深入，推动人工智能与其他领域的融合。</span></span><br><span class="line"><span class="string">6.2 应用拓展</span></span><br><span class="line"><span class="string">随着技术的进步，人工智能的应用领域将进一步拓展。未来，人工智能有望在更多领域发挥重要作用，如环境保护、能源管理、智能制造等。人工智能将成为推动社会进步的重要力量。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">7. 结论</span></span><br><span class="line"><span class="string">人工智能作为一门快速发展的科学，正在改变着人类社会的运行方式。通过不断的技术创新和应用拓展，人工智能将为人类社会带来更多的便利和福祉。然而，人工智能的发展也面临着诸多挑战，需要社会各界共同努力，推动人工智能的健康发展。&#x27;</span> metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/09-ai1.txt&#x27;</span>&#125;</span><br><span class="line">------page_content=<span class="string">&#x27;3. 人工智能的核心技术</span></span><br><span class="line"><span class="string">3.1 机器学习</span></span><br><span class="line"><span class="string">机器学习是人工智能的核心技术之一，通过算法使计算机从数据中学习并做出决策。常见的机器学习算法包括监督学习、无监督学习和强化学习。监督学习通过标记数据进行训练，无监督学习则从未标记数据中寻找模式，强化学习则通过与环境交互来优化决策。</span></span><br><span class="line"><span class="string">3.2 深度学习</span></span><br><span class="line"><span class="string">深度学习是机器学习的一个子领域，通过多层神经网络进行特征提取和模式识别。深度学习在图像识别、自然语言处理、语音识别等领域取得了显著成果。常见的深度学习模型包括卷积神经网络（CNN）、循环神经网络（RNN）和长短期记忆网络（LSTM）。</span></span><br><span class="line"><span class="string">3.3 自然语言处理</span></span><br><span class="line"><span class="string">自然语言处理（NLP）是人工智能的一个重要分支，致力于使计算机能够理解和生成人类语言。NLP技术广泛应用于机器翻译、情感分析、文本分类等领域。近年来，基于深度学习的NLP模型（如BERT、GPT）在语言理解任务中取得了突破性进展。</span></span><br><span class="line"><span class="string">3.4 计算机视觉</span></span><br><span class="line"><span class="string">计算机视觉是人工智能的另一个重要分支，致力于使计算机能够理解和处理图像和视频。计算机视觉技术广泛应用于图像识别、目标检测、人脸识别等领域。深度学习模型（如CNN）在计算机视觉任务中取得了显著成果。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">8. 人工智能的应用领域</span></span><br><span class="line"><span class="string">4.1 医疗健康</span></span><br><span class="line"><span class="string">人工智能在医疗健康领域的应用包括疾病诊断、药物研发、个性化医疗等。通过分析医学影像和患者数据，人工智能可以帮助医生更准确地诊断疾病，提高治疗效果。</span></span><br><span class="line"><span class="string">4.2 金融</span></span><br><span class="line"><span class="string">人工智能在金融领域的应用包括风险评估、欺诈检测、算法交易等。通过分析市场数据和交易记录，人工智能可以帮助金融机构做出更明智的决策，提高运营效率。</span></span><br><span class="line"><span class="string">4.3 教育</span></span><br><span class="line"><span class="string">人工智能在教育领域的应用包括个性化学习、智能辅导、自动评分等。通过分析学生的学习数据，人工智能可以为学生提供个性化的学习建议，提高学习效果。</span></span><br><span class="line"><span class="string">4.4 交通</span></span><br><span class="line"><span class="string">人工智能在交通领域的应用包括自动驾驶、交通管理、智能导航等。通过分析交通数据和路况信息，人工智能可以帮助优化交通流量，提高交通安全。&#x27;</span> metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/09-ai1.txt&#x27;</span>&#125;</span><br><span class="line">------page_content=<span class="string">&#x27;人工智能综述：发展、应用与未来展望</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">摘要</span></span><br><span class="line"><span class="string">人工智能（Artificial Intelligence，AI）作为计算机科学的一个重要分支，近年来取得了突飞猛进的发展。本文综述了人工智能的发展历程、核心技术、应用领域以及未来发展趋势。通过对人工智能的定义、历史背景、主要技术（如机器学习、深度学习、自然语言处理等）的详细介绍，探讨了人工智能在医疗、金融、教育、交通等领域的应用，并分析了人工智能发展过程中面临的挑战与机遇。最后，本文对人工智能的未来发展进行了展望，提出了可能的突破方向。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. 引言</span></span><br><span class="line"><span class="string">人工智能是指通过计算机程序模拟人类智能的一门科学。自20世纪50年代诞生以来，人工智能经历了多次起伏，近年来随着计算能力的提升和大数据的普及，人工智能技术取得了显著的进展。人工智能的应用已经渗透到日常生活的方方面面，从智能手机的语音助手到自动驾驶汽车，从医疗诊断到金融分析，人工智能正在改变着人类社会的运行方式。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. 人工智能的发展历程</span></span><br><span class="line"><span class="string">2.1 早期发展</span></span><br><span class="line"><span class="string">人工智能的概念最早可以追溯到20世纪50年代。1956年，达特茅斯会议（Dartmouth Conference）被认为是人工智能研究的正式开端。在随后的几十年里，人工智能研究经历了多次高潮与低谷。早期的研究主要集中在符号逻辑和专家系统上，但由于计算能力的限制和算法的不足，进展缓慢。</span></span><br><span class="line"><span class="string">2.2 机器学习的兴起</span></span><br><span class="line"><span class="string">20世纪90年代，随着统计学习方法的引入，机器学习逐渐成为人工智能研究的主流。支持向量机（SVM）、决策树、随机森林等算法在分类和回归任务中取得了良好的效果。这一时期，机器学习开始应用于数据挖掘、模式识别等领域。</span></span><br><span class="line"><span class="string">2.3 深度学习的突破</span></span><br><span class="line"><span class="string">2012年，深度学习在图像识别领域取得了突破性进展，标志着人工智能进入了一个新的阶段。深度学习通过多层神经网络模拟人脑的工作方式，能够自动提取特征并进行复杂的模式识别。卷积神经网络（CNN）、循环神经网络（RNN）和长短期记忆网络（LSTM）等深度学习模型在图像处理、自然语言处理、语音识别等领域取得了显著成果。&#x27;</span> metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;./asset/load/09-ai1.txt&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="使用相关检索策">使用相关检索策</h2>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install faiss-cpu</span><br></pre></td></tr></table></figure>
<p>前置代码： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.导入相关依赖  </span></span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_core.documents <span class="keyword">import</span> Document  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2.定义文档  </span></span><br><span class="line">document_1 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;经济复苏：美国经济正在从疫情中强劲复苏，失业率降至历史低点。！&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_2 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;基础设施：政府将投资1万亿美元用于修复道路、桥梁和宽带网络。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_3 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;气候变化：承诺到2030年将温室气体排放量减少50%。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_4 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot; 医疗保健：降低处方药价格，扩大医疗保险覆盖范围。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_5 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;教育：提供免费的社区大学教育。。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_6 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;科技：增加对半导体产业的投资以减少对外国供应链的依赖。。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_7 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;外交政策：继续支持乌克兰对抗俄罗斯的侵略。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_8 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;枪支管制：呼吁国会通过更严格的枪支管制法律。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_9 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;移民改革：提出全面的移民改革方案。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">document_10 = Document(  </span><br><span class="line">    page_content=<span class="string">&quot;社会正义：承诺解决系统性种族歧视问题。&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line">documents = [  </span><br><span class="line">    document_1,  </span><br><span class="line">    document_2,  </span><br><span class="line">    document_3,  </span><br><span class="line">    document_4,  </span><br><span class="line">    document_5,  </span><br><span class="line">    document_6,  </span><br><span class="line">    document_7,  </span><br><span class="line">    document_8,  </span><br><span class="line">    document_9,  </span><br><span class="line">    document_10,  </span><br><span class="line">]  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3.创建向量存储  </span></span><br><span class="line">embeddings = OpenAIEmbeddings(  </span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4.将文档向量化，添加到向量数据库索引中，得到向量数据库对象  </span></span><br><span class="line">db = FAISS.from_documents(documents, embeddings)</span><br></pre></td></tr></table></figure></p>
<h3 id="默认检索器使用相似性搜索">① 默认检索器使用相似性搜索</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取检索器  </span></span><br><span class="line">retriever = db.as_retriever(search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">3</span>&#125;) <span class="comment">#这里设置返回的文档数  </span></span><br><span class="line">  </span><br><span class="line">docs = retriever.invoke(<span class="string">&quot;经济政策&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n结果 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>:\n<span class="subst">&#123;doc.page_content&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">结果 1:</span><br><span class="line">社会正义：承诺解决系统性种族歧视问题。</span><br><span class="line"></span><br><span class="line">结果 2:</span><br><span class="line">外交政策：继续支持乌克兰对抗俄罗斯的侵略。</span><br><span class="line"></span><br><span class="line">结果 3:</span><br><span class="line">教育：提供免费的社区大学教育。。</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3 id="分数阈值查询">② 分数阈值查询</h3>
<p>只有相似度超过这个值才会召回 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">retriever = db.as_retriever(  </span><br><span class="line">    search_type=<span class="string">&quot;similarity_score_threshold&quot;</span>,  </span><br><span class="line">    search_kwargs=&#123;<span class="string">&quot;score_threshold&quot;</span>: <span class="number">0.1</span>&#125;  </span><br><span class="line">)  </span><br><span class="line">docs = retriever.invoke(<span class="string">&quot;经济政策&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> doc <span class="keyword">in</span> docs:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;📌 内容: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">📌 内容: 社会正义：承诺解决系统性种族歧视问题。</span><br><span class="line">📌 内容: 外交政策：继续支持乌克兰对抗俄罗斯的侵略。</span><br><span class="line">📌 内容: 教育：提供免费的社区大学教育。。</span><br><span class="line">📌 内容: 科技：增加对半导体产业的投资以减少对外国供应链的依赖。。</span><br></pre></td></tr></table></figure></p>
<p>注意只会返回满足阈值分数的文档，不会获取文档的得分。如果想查询文档的得分是否满足阈值，可以 使用向量数据库的 <strong>similarity_search_with_relevance_scores</strong> 查看 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docs_with_scores = db.similarity_search_with_relevance_scores(<span class="string">&quot;经济政策&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> doc, score <span class="keyword">in</span> docs_with_scores:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n相似度分数: <span class="subst">&#123;score:<span class="number">.4</span>f&#125;</span>&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;📌 内容: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">相似度分数: 0.2922</span><br><span class="line">📌 内容: 社会正义：承诺解决系统性种族歧视问题。</span><br><span class="line"></span><br><span class="line">相似度分数: 0.2544</span><br><span class="line">📌 内容: 外交政策：继续支持乌克兰对抗俄罗斯的侵略。</span><br><span class="line"></span><br><span class="line">相似度分数: 0.2302</span><br><span class="line">📌 内容: 教育：提供免费的社区大学教育。。</span><br><span class="line"></span><br><span class="line">相似度分数: 0.2160</span><br><span class="line">📌 内容: 科技：增加对半导体产业的投资以减少对外国供应链的依赖。。</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h3 id="mmr搜索">③ MMR搜索</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">retriever = db.as_retriever(  </span><br><span class="line">    search_type=<span class="string">&quot;mmr&quot;</span>,  </span><br><span class="line">    search_kwargs=&#123;<span class="string">&quot;fetch_k&quot;</span>:<span class="number">2</span>&#125;  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">docs = retriever.invoke(<span class="string">&quot;经济政策&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(docs))  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span>  doc  <span class="keyword">in</span>  docs:  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;📌 内容: <span class="subst">&#123;doc.page_content&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2</span><br><span class="line">📌 内容: 社会正义：承诺解决系统性种族歧视问题。</span><br><span class="line">📌 内容: 外交政策：继续支持乌克兰对抗俄罗斯的侵略。</span><br></pre></td></tr></table></figure></p>
<h2 id="结合大模型的使用">结合大模型的使用</h2>
<p>举例1：通过FAISS构建一个可搜索的向量索引数据库，并结合RAG技术让LLM去回答问题。 ### 情况1：不用RAG给LLM灌输上下文数据 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = os.getenv(<span class="string">&quot;SILICONFLOW_API_KEY&quot;</span>)  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = os.getenv(<span class="string">&quot;BASE_URL&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建大模型实例  </span></span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;deepseek-ai/DeepSeek-V3&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 调用  </span></span><br><span class="line">response = llm.invoke(<span class="string">&quot;北京有什么著名的建筑？&quot;</span>)  </span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure> 结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">北京作为中国的首都，拥有丰富的历史和现代建筑，以下是一些著名的代表：</span><br><span class="line"></span><br><span class="line"><span class="comment">### **历史建筑**</span></span><br><span class="line">1. **故宫（紫禁城）**  </span><br><span class="line">   - 明清两代的皇家宫殿，世界文化遗产，中国现存最大、最完整的古建筑群。</span><br><span class="line"></span><br><span class="line">2. **天坛**  </span><br><span class="line">   - 明清皇帝祭天的场所，以祈年殿和圜丘坛闻名，世界文化遗产。</span><br><span class="line"></span><br><span class="line">3. **颐和园**  </span><br><span class="line">   - 清代皇家园林，以昆明湖、万寿山和长廊著称，世界文化遗产。</span><br><span class="line"></span><br><span class="line">4. **长城（八达岭、慕田峪段）**  </span><br><span class="line">   - 世界七大奇迹之一，北京周边保存完好的段落包括八达岭和慕田峪。</span><br><span class="line"></span><br><span class="line">5. **圆明园**  </span><br><span class="line">   - 曾为“万园之园”，现存遗址公园，见证近代历史。</span><br><span class="line"></span><br><span class="line">6. **雍和宫**  </span><br><span class="line">   - 北京最大的藏传佛教寺院，曾是雍正皇帝的府邸。</span><br><span class="line"></span><br><span class="line">7. **钟鼓楼**  </span><br><span class="line">   - 古代报时中心，位于中轴线北端，保留元代格局。</span><br><span class="line"></span><br><span class="line"><span class="comment">### **近现代建筑**</span></span><br><span class="line">1. **天安门广场及周边**  </span><br><span class="line">   - **人民大会堂**：国家政治活动中心。  </span><br><span class="line">   - **国家博物馆**：中国最大的综合性博物馆。  </span><br><span class="line">   - **人民英雄纪念碑**：纪念近代革命烈士的标志。  </span><br><span class="line">   - **毛主席纪念堂**：安放毛泽东遗体的纪念建筑。</span><br><span class="line"></span><br><span class="line">2. **奥林匹克公园**  </span><br><span class="line">   - **鸟巢（国家体育场）**：2008年奥运会主体育场，现代钢结构代表作。  </span><br><span class="line">   - **水立方（国家游泳中心）**：独特的膜结构设计，现为“冰立方”。</span><br><span class="line"></span><br><span class="line">3. **中央电视台总部大楼（“大裤衩”）**  </span><br><span class="line">   - 由荷兰建筑师雷姆·库哈斯设计，后现代地标建筑。</span><br><span class="line"></span><br><span class="line">4. **国家大剧院**  </span><br><span class="line">   - 法国建筑师保罗·安德鲁设计，钛金属穹顶宛如“水上明珠”。</span><br><span class="line"></span><br><span class="line">5. **北京大兴国际机场**  </span><br><span class="line">   - 扎哈·哈迪德设计，全球最大单体航站楼，以“凤凰展翅”为造型。</span><br><span class="line"></span><br><span class="line">6. **中信大厦（中国尊）**  </span><br><span class="line">   - 北京最高建筑（528米），CBD核心区的现代摩天大楼。</span><br><span class="line"></span><br><span class="line"><span class="comment">### **特色建筑**</span></span><br><span class="line">- **胡同与四合院**：如南锣鼓巷、什刹海周边，展现老北京民居风貌。  </span><br><span class="line">- **北京坊**：前门附近的现代文化街区，融合中西建筑风格。  </span><br><span class="line">- **琉璃厂文化街**：传统书画古玩街区，仿古建筑风格。</span><br><span class="line"></span><br><span class="line">这些建筑不仅代表了北京的历史底蕴，也展现了其作为国际大都市的现代活力。如果有具体兴趣方向，可以深入推荐！</span><br></pre></td></tr></table></figure></p>
<h3 id="情况2使用rag给llm灌输上下文数据">情况2：使用RAG给LLM灌输上下文数据</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 导入所有需要的包  </span></span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate  </span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI,OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> TextLoader  </span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter  </span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 2. 创建自定义提示词模板  </span></span><br><span class="line">prompt_template = <span class="string">&quot;&quot;&quot;请使用以下提供的文本内容来回答问题。仅使用提供的文本信息，如果文本中没有相关信息，请回答&quot;抱歉，提供的文本中没有这个信息&quot;。  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">文本内容：  </span></span><br><span class="line"><span class="string">&#123;context&#125;  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">问题：&#123;question&#125;  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">回答：  </span></span><br><span class="line"><span class="string">&quot;  </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>  </span><br><span class="line">  </span><br><span class="line">prompt = PromptTemplate.from_template(prompt_template)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 3. 初始化模型  </span></span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = os.getenv(<span class="string">&quot;SILICONFLOW_API_KEY&quot;</span>)  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = os.getenv(<span class="string">&quot;BASE_URL&quot;</span>)  </span><br><span class="line">llm = ChatOpenAI(  </span><br><span class="line">    model=<span class="string">&quot;deepseek-ai/DeepSeek-V3&quot;</span>,  </span><br><span class="line">    temperature=<span class="number">0</span>  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line">embedding_model = OpenAIEmbeddings(model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 4. 加载文档  </span></span><br><span class="line">loader = TextLoader(<span class="string">&quot;./asset/load/10-test_doc.txt&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)  </span><br><span class="line">documents = loader.load()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 5. 分割文档  </span></span><br><span class="line">text_splitter = CharacterTextSplitter(  </span><br><span class="line">    chunk_size=<span class="number">1000</span>,  </span><br><span class="line">    chunk_overlap=<span class="number">100</span>,  </span><br><span class="line">)  </span><br><span class="line">texts = text_splitter.split_documents(documents)  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#print(f&quot;文档个数:&#123;len(texts)&#125;&quot;)  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 6. 创建向量存储  </span></span><br><span class="line">vectorstore = FAISS.from_documents(  </span><br><span class="line">    documents=texts,  </span><br><span class="line">    embedding=embedding_model  </span><br><span class="line">)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 7.获取检索器  </span></span><br><span class="line">retriever = vectorstore.as_retriever()  </span><br><span class="line">  </span><br><span class="line">docs = retriever.invoke(<span class="string">&quot;北京有什么著名的建筑？&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 8. 创建Runnable链  </span></span><br><span class="line">chain = prompt | llm  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 9. 提问  </span></span><br><span class="line">result = chain.invoke(<span class="built_in">input</span>=&#123;<span class="string">&quot;question&quot;</span>:<span class="string">&quot;北京有什么著名的建筑？&quot;</span>,<span class="string">&quot;context&quot;</span>:docs&#125;)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n回答:&quot;</span>, result.content)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">回答: 根据提供的文本内容，北京有以下著名建筑：</span><br><span class="line"></span><br><span class="line">1. 故宫（紫禁城） - 明清皇家宫殿，世界文化遗产  </span><br><span class="line">2. 天安门 - 标志性建筑，拥有世界最大城市广场  </span><br><span class="line">3. 颐和园 - 清代皇家园林，世界文化遗产  </span><br><span class="line">4. 天坛 - 明清祭天场所，世界文化遗产  </span><br><span class="line">5. 八达岭长城 - 最著名的长城段落  </span><br><span class="line">6. 国家体育场（鸟巢） - 2008奥运主体育场  </span><br><span class="line">7. 中央电视台总部大楼（<span class="string">&quot;大裤衩&quot;</span>）  </span><br><span class="line">8. 国家大剧院（<span class="string">&quot;巨蛋&quot;</span>）  </span><br><span class="line">9. 北京大兴国际机场 - <span class="string">&quot;新世界七大奇迹&quot;</span>之一  </span><br><span class="line">10. 鼓楼和钟楼 - 古代报时中心</span><br></pre></td></tr></table></figure></p>
<h3 id="举例2使用chroma数据库-与举例1类似">举例2：使用Chroma数据库 （与举例1类似）</h3>
<h4 id="阶段1文档的切分">阶段1：文档的切分</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 1. 文档加载  </span></span><br><span class="line"><span class="keyword">from</span> langchain_community.document_loaders <span class="keyword">import</span> UnstructuredMarkdownLoader  </span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> MarkdownTextSplitter  </span><br><span class="line">markdown_path = <span class="string">&quot;asset/load/11-langchain.md&quot;</span>  </span><br><span class="line"> <span class="comment"># 2.定义UnstructuredMarkdownLoader对象  </span></span><br><span class="line">loader = UnstructuredMarkdownLoader(markdown_path)  </span><br><span class="line">   </span><br><span class="line"><span class="comment"># 3.加载  </span></span><br><span class="line">data = loader.load()  </span><br><span class="line">splitter = MarkdownTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">100</span>)  </span><br><span class="line"><span class="comment"># 4.执行分割  </span></span><br><span class="line">  </span><br><span class="line">documents = splitter.split_documents(data)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(documents))  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(documents):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n🔍 分块 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>:&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(doc.page_content)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br></pre></td><td class="code"><pre><span class="line">13</span><br><span class="line"></span><br><span class="line">🔍 分块 1:</span><br><span class="line">How-to guides</span><br><span class="line"></span><br><span class="line">Here you’ll find answers to “How do I….?” types of questions. These guides are goal-oriented and concrete; they&#x27;re meant to help you complete a specific task. For conceptual explanations see the Conceptual guide. For end-to-end walkthroughs see Tutorials. For comprehensive descriptions of every class and function see the API Reference.</span><br><span class="line"></span><br><span class="line">Installation</span><br><span class="line"></span><br><span class="line">How to: install LangChain packages</span><br><span class="line"></span><br><span class="line">How to: use LangChain with different Pydantic versions</span><br><span class="line"></span><br><span class="line">Key features</span><br><span class="line"></span><br><span class="line">This highlights functionality that is core to using LangChain.</span><br><span class="line"></span><br><span class="line">How to: return structured data from a model</span><br><span class="line"></span><br><span class="line">How to: use a model to call tools</span><br><span class="line"></span><br><span class="line">How to: stream runnables</span><br><span class="line"></span><br><span class="line">How to: debug your LLM apps</span><br><span class="line"></span><br><span class="line">Components</span><br><span class="line"></span><br><span class="line">These are the core building blocks you can use when building applications.</span><br><span class="line"></span><br><span class="line">Chat models</span><br><span class="line"></span><br><span class="line">Chat Models are newer forms of language models that take messages in and output a message. See supported integrations for details on getting started with chat models from a specific provider.</span><br><span class="line"></span><br><span class="line">How to: do function/tool calling</span><br><span class="line"></span><br><span class="line">🔍 分块 2:</span><br><span class="line">How to: do function/tool calling</span><br><span class="line"></span><br><span class="line">How to: get models to return structured output</span><br><span class="line"></span><br><span class="line">How to: cache model responses</span><br><span class="line"></span><br><span class="line">How to: get log probabilities</span><br><span class="line"></span><br><span class="line">How to: create a custom chat model class</span><br><span class="line"></span><br><span class="line">How to: stream a response back</span><br><span class="line"></span><br><span class="line">How to: track token usage</span><br><span class="line"></span><br><span class="line">How to: track response metadata across providers</span><br><span class="line"></span><br><span class="line">How to: use chat model to call tools</span><br><span class="line"></span><br><span class="line">How to: stream tool calls</span><br><span class="line"></span><br><span class="line">How to: handle rate limits</span><br><span class="line"></span><br><span class="line">How to: few shot prompt tool behavior</span><br><span class="line"></span><br><span class="line">How to: bind model-specific formatted tools</span><br><span class="line"></span><br><span class="line">How to: force a specific tool call</span><br><span class="line"></span><br><span class="line">How to: work with local models</span><br><span class="line"></span><br><span class="line">How to: init any model in one line</span><br><span class="line"></span><br><span class="line">How to: pass multimodal data directly to models</span><br><span class="line"></span><br><span class="line">Messages</span><br><span class="line"></span><br><span class="line">Messages are the input and output of chat models. They have some content and a role, which describes the source of the message.</span><br><span class="line"></span><br><span class="line">How to: trim messages</span><br><span class="line"></span><br><span class="line">How to: filter messages</span><br><span class="line"></span><br><span class="line">How to: merge consecutive messages of the same type</span><br><span class="line"></span><br><span class="line">Prompt templates</span><br><span class="line"></span><br><span class="line">Prompt Templates are responsible for formatting user input into a format that can be passed to a language model.</span><br><span class="line"></span><br><span class="line">🔍 分块 3:</span><br><span class="line">How to: use few shot examples</span><br><span class="line"></span><br><span class="line">How to: use few shot examples in chat models</span><br><span class="line"></span><br><span class="line">How to: partially format prompt templates</span><br><span class="line"></span><br><span class="line">How to: compose prompts together</span><br><span class="line"></span><br><span class="line">How to: use multimodal prompts</span><br><span class="line"></span><br><span class="line">Example selectors</span><br><span class="line"></span><br><span class="line">Example Selectors are responsible for selecting the correct few shot examples to pass to the prompt.</span><br><span class="line"></span><br><span class="line">How to: use example selectors</span><br><span class="line"></span><br><span class="line">How to: select examples by length</span><br><span class="line"></span><br><span class="line">How to: select examples by semantic similarity</span><br><span class="line"></span><br><span class="line">How to: select examples by semantic ngram overlap</span><br><span class="line"></span><br><span class="line">How to: select examples by maximal marginal relevance</span><br><span class="line"></span><br><span class="line">How to: select examples from LangSmith few-shot datasets</span><br><span class="line"></span><br><span class="line">LLMs</span><br><span class="line"></span><br><span class="line">What LangChain calls LLMs are older forms of language models that take a string in and output a string.</span><br><span class="line"></span><br><span class="line">How to: cache model responses</span><br><span class="line"></span><br><span class="line">How to: create a custom LLM class</span><br><span class="line"></span><br><span class="line">How to: stream a response back</span><br><span class="line"></span><br><span class="line">How to: track token usage</span><br><span class="line"></span><br><span class="line">How to: work with local models</span><br><span class="line"></span><br><span class="line">Output parsers</span><br><span class="line"></span><br><span class="line">Output Parsers are responsible for taking the output of an LLM and parsing into more structured format.</span><br><span class="line"></span><br><span class="line">🔍 分块 4:</span><br><span class="line">How to: parse text from message objects</span><br><span class="line"></span><br><span class="line">How to: use output parsers to parse an LLM response into structured format</span><br><span class="line"></span><br><span class="line">How to: parse JSON output</span><br><span class="line"></span><br><span class="line">How to: parse XML output</span><br><span class="line"></span><br><span class="line">How to: parse YAML output</span><br><span class="line"></span><br><span class="line">How to: retry when output parsing errors occur</span><br><span class="line"></span><br><span class="line">How to: try to fix errors in output parsing</span><br><span class="line"></span><br><span class="line">How to: write a custom output parser class</span><br><span class="line"></span><br><span class="line">Document loaders</span><br><span class="line"></span><br><span class="line">Document Loaders are responsible for loading documents from a variety of sources.</span><br><span class="line"></span><br><span class="line">How to: load PDF files</span><br><span class="line"></span><br><span class="line">How to: load web pages</span><br><span class="line"></span><br><span class="line">How to: load CSV data</span><br><span class="line"></span><br><span class="line">How to: load data from a directory</span><br><span class="line"></span><br><span class="line">How to: load HTML data</span><br><span class="line"></span><br><span class="line">How to: load JSON data</span><br><span class="line"></span><br><span class="line">How to: load Markdown data</span><br><span class="line"></span><br><span class="line">How to: load Microsoft Office data</span><br><span class="line"></span><br><span class="line">How to: write a custom document loader</span><br><span class="line"></span><br><span class="line">Text splitters</span><br><span class="line"></span><br><span class="line">Text Splitters take a document and split into chunks that can be used for retrieval.</span><br><span class="line"></span><br><span class="line">How to: recursively split text</span><br><span class="line"></span><br><span class="line">How to: split HTML</span><br><span class="line"></span><br><span class="line">How to: split by character</span><br><span class="line"></span><br><span class="line">How to: split code</span><br><span class="line"></span><br><span class="line">How to: split Markdown by headers</span><br><span class="line"></span><br><span class="line">How to: recursively split JSON</span><br><span class="line"></span><br><span class="line">🔍 分块 5:</span><br><span class="line">How to: split code</span><br><span class="line"></span><br><span class="line">How to: split Markdown by headers</span><br><span class="line"></span><br><span class="line">How to: recursively split JSON</span><br><span class="line"></span><br><span class="line">How to: split text into semantic chunks</span><br><span class="line"></span><br><span class="line">How to: split by tokens</span><br><span class="line"></span><br><span class="line">Embedding models</span><br><span class="line"></span><br><span class="line">Embedding Models take a piece of text and create a numerical representation of it. See supported integrations for details on getting started with embedding models from a specific provider.</span><br><span class="line"></span><br><span class="line">How to: embed text data</span><br><span class="line"></span><br><span class="line">How to: cache embedding results</span><br><span class="line"></span><br><span class="line">How to: create a custom embeddings class</span><br><span class="line"></span><br><span class="line">Vector stores</span><br><span class="line"></span><br><span class="line">Vector stores are databases that can efficiently store and retrieve embeddings. See supported integrations for details on getting started with vector stores from a specific provider.</span><br><span class="line"></span><br><span class="line">How to: use a vector store to retrieve data</span><br><span class="line"></span><br><span class="line">Retrievers</span><br><span class="line"></span><br><span class="line">Retrievers are responsible for taking a query and returning relevant documents.</span><br><span class="line"></span><br><span class="line">How to: use a vector store to retrieve data</span><br><span class="line"></span><br><span class="line">How to: generate multiple queries to retrieve data for</span><br><span class="line"></span><br><span class="line">How to: use contextual compression to compress the data retrieved</span><br><span class="line"></span><br><span class="line">🔍 分块 6:</span><br><span class="line">How to: use contextual compression to compress the data retrieved</span><br><span class="line"></span><br><span class="line">How to: write a custom retriever class</span><br><span class="line"></span><br><span class="line">How to: add similarity scores to retriever results</span><br><span class="line"></span><br><span class="line">How to: combine the results from multiple retrievers</span><br><span class="line"></span><br><span class="line">How to: reorder retrieved results to mitigate the &quot;lost in the middle&quot; effect</span><br><span class="line"></span><br><span class="line">How to: generate multiple embeddings per document</span><br><span class="line"></span><br><span class="line">How to: retrieve the whole document for a chunk</span><br><span class="line"></span><br><span class="line">How to: generate metadata filters</span><br><span class="line"></span><br><span class="line">How to: create a time-weighted retriever</span><br><span class="line"></span><br><span class="line">How to: use hybrid vector and keyword retrieval</span><br><span class="line"></span><br><span class="line">Indexing</span><br><span class="line"></span><br><span class="line">Indexing is the process of keeping your vectorstore in-sync with the underlying data source.</span><br><span class="line"></span><br><span class="line">How to: reindex data to keep your vectorstore in-sync with the underlying data source</span><br><span class="line"></span><br><span class="line">Tools</span><br><span class="line"></span><br><span class="line">LangChain Tools contain a description of the tool (to pass to the language model) as well as the implementation of the function to call. Refer here for a list of pre-built tools.</span><br><span class="line"></span><br><span class="line">How to: create tools</span><br><span class="line"></span><br><span class="line">How to: use built-in tools and toolkits</span><br><span class="line"></span><br><span class="line">How to: use chat models to call tools</span><br><span class="line"></span><br><span class="line">🔍 分块 7:</span><br><span class="line">How to: use built-in tools and toolkits</span><br><span class="line"></span><br><span class="line">How to: use chat models to call tools</span><br><span class="line"></span><br><span class="line">How to: pass tool outputs to chat models</span><br><span class="line"></span><br><span class="line">How to: pass run time values to tools</span><br><span class="line"></span><br><span class="line">How to: add a human-in-the-loop for tools</span><br><span class="line"></span><br><span class="line">How to: handle tool errors</span><br><span class="line"></span><br><span class="line">How to: force models to call a tool</span><br><span class="line"></span><br><span class="line">How to: disable parallel tool calling</span><br><span class="line"></span><br><span class="line">How to: access the RunnableConfig from a tool</span><br><span class="line"></span><br><span class="line">How to: stream events from a tool</span><br><span class="line"></span><br><span class="line">How to: return artifacts from a tool</span><br><span class="line"></span><br><span class="line">How to: convert Runnables to tools</span><br><span class="line"></span><br><span class="line">How to: add ad-hoc tool calling capability to models</span><br><span class="line"></span><br><span class="line">How to: pass in runtime secrets</span><br><span class="line"></span><br><span class="line">Multimodal</span><br><span class="line"></span><br><span class="line">How to: pass multimodal data directly to models</span><br><span class="line"></span><br><span class="line">How to: use multimodal prompts</span><br><span class="line"></span><br><span class="line">Agents</span><br><span class="line"></span><br><span class="line">note</span><br><span class="line"></span><br><span class="line">For in depth how-to guides for agents, please check out LangGraph documentation.</span><br><span class="line"></span><br><span class="line">How to: use legacy LangChain Agents (AgentExecutor)</span><br><span class="line"></span><br><span class="line">How to: migrate from legacy LangChain agents to LangGraph</span><br><span class="line"></span><br><span class="line">Callbacks</span><br><span class="line"></span><br><span class="line">Callbacks allow you to hook into the various stages of your LLM application&#x27;s execution.</span><br><span class="line"></span><br><span class="line">How to: pass in callbacks at runtime</span><br><span class="line"></span><br><span class="line">🔍 分块 8:</span><br><span class="line">How to: pass in callbacks at runtime</span><br><span class="line"></span><br><span class="line">How to: attach callbacks to a module</span><br><span class="line"></span><br><span class="line">How to: pass callbacks into a module constructor</span><br><span class="line"></span><br><span class="line">How to: create custom callback handlers</span><br><span class="line"></span><br><span class="line">How to: use callbacks in async environments</span><br><span class="line"></span><br><span class="line">How to: dispatch custom callback events</span><br><span class="line"></span><br><span class="line">Custom</span><br><span class="line"></span><br><span class="line">All of LangChain components can easily be extended to support your own versions.</span><br><span class="line"></span><br><span class="line">How to: create a custom chat model class</span><br><span class="line"></span><br><span class="line">How to: create a custom LLM class</span><br><span class="line"></span><br><span class="line">How to: create a custom embeddings class</span><br><span class="line"></span><br><span class="line">How to: write a custom retriever class</span><br><span class="line"></span><br><span class="line">How to: write a custom document loader</span><br><span class="line"></span><br><span class="line">How to: write a custom output parser class</span><br><span class="line"></span><br><span class="line">How to: create custom callback handlers</span><br><span class="line"></span><br><span class="line">How to: define a custom tool</span><br><span class="line"></span><br><span class="line">How to: dispatch custom callback events</span><br><span class="line"></span><br><span class="line">Serialization</span><br><span class="line"></span><br><span class="line">How to: save and load LangChain objects</span><br><span class="line"></span><br><span class="line">Use cases</span><br><span class="line"></span><br><span class="line">These guides cover use-case specific details.</span><br><span class="line"></span><br><span class="line">Q&amp;A with RAG</span><br><span class="line"></span><br><span class="line">Retrieval Augmented Generation (RAG) is a way to connect LLMs to external sources of data. For a high-level tutorial on RAG, check out this guide.</span><br><span class="line"></span><br><span class="line">How to: add chat history</span><br><span class="line"></span><br><span class="line">🔍 分块 9:</span><br><span class="line">How to: add chat history</span><br><span class="line"></span><br><span class="line">How to: stream</span><br><span class="line"></span><br><span class="line">How to: return sources</span><br><span class="line"></span><br><span class="line">How to: return citations</span><br><span class="line"></span><br><span class="line">How to: do per-user retrieval</span><br><span class="line"></span><br><span class="line">Extraction</span><br><span class="line"></span><br><span class="line">Extraction is when you use LLMs to extract structured information from unstructured text. For a high level tutorial on extraction, check out this guide.</span><br><span class="line"></span><br><span class="line">How to: use reference examples</span><br><span class="line"></span><br><span class="line">How to: handle long text</span><br><span class="line"></span><br><span class="line">How to: do extraction without using function calling</span><br><span class="line"></span><br><span class="line">Chatbots</span><br><span class="line"></span><br><span class="line">Chatbots involve using an LLM to have a conversation. For a high-level tutorial on building chatbots, check out this guide.</span><br><span class="line"></span><br><span class="line">How to: manage memory</span><br><span class="line"></span><br><span class="line">How to: do retrieval</span><br><span class="line"></span><br><span class="line">How to: use tools</span><br><span class="line"></span><br><span class="line">How to: manage large chat history</span><br><span class="line"></span><br><span class="line">Query analysis</span><br><span class="line"></span><br><span class="line">Query Analysis is the task of using an LLM to generate a query to send to a retriever. For a high-level tutorial on query analysis, check out this guide.</span><br><span class="line"></span><br><span class="line">How to: add examples to the prompt</span><br><span class="line"></span><br><span class="line">How to: handle cases where no queries are generated</span><br><span class="line"></span><br><span class="line">How to: handle multiple queries</span><br><span class="line"></span><br><span class="line">How to: handle multiple retrievers</span><br><span class="line"></span><br><span class="line">How to: construct filters</span><br><span class="line"></span><br><span class="line">🔍 分块 10:</span><br><span class="line">How to: handle multiple queries</span><br><span class="line"></span><br><span class="line">How to: handle multiple retrievers</span><br><span class="line"></span><br><span class="line">How to: construct filters</span><br><span class="line"></span><br><span class="line">How to: deal with high cardinality categorical variables</span><br><span class="line"></span><br><span class="line">Q&amp;A over SQL + CSV</span><br><span class="line"></span><br><span class="line">You can use LLMs to do question answering over tabular data. For a high-level tutorial, check out this guide.</span><br><span class="line"></span><br><span class="line">How to: use prompting to improve results</span><br><span class="line"></span><br><span class="line">How to: do query validation</span><br><span class="line"></span><br><span class="line">How to: deal with large databases</span><br><span class="line"></span><br><span class="line">How to: deal with CSV files</span><br><span class="line"></span><br><span class="line">Q&amp;A over graph databases</span><br><span class="line"></span><br><span class="line">You can use an LLM to do question answering over graph databases. For a high-level tutorial, check out this guide.</span><br><span class="line"></span><br><span class="line">How to: add a semantic layer over the database</span><br><span class="line"></span><br><span class="line">How to: construct knowledge graphs</span><br><span class="line"></span><br><span class="line">Summarization</span><br><span class="line"></span><br><span class="line">LLMs can summarize and otherwise distill desired information from text, including large volumes of text. For a high-level tutorial, check out this guide.</span><br><span class="line"></span><br><span class="line">How to: summarize text in a single LLM call</span><br><span class="line"></span><br><span class="line">How to: summarize text through parallelization</span><br><span class="line"></span><br><span class="line">How to: summarize text through iterative refinement</span><br><span class="line"></span><br><span class="line">LangChain Expression Language (LCEL)</span><br><span class="line"></span><br><span class="line">🔍 分块 11:</span><br><span class="line">How to: summarize text through iterative refinement</span><br><span class="line"></span><br><span class="line">LangChain Expression Language (LCEL)</span><br><span class="line"></span><br><span class="line">Should I use LCEL?</span><br><span class="line"></span><br><span class="line">LCEL is an orchestration solution. See our concepts page for recommendations on when to use LCEL.</span><br><span class="line"></span><br><span class="line">LangChain Expression Language is a way to create arbitrary custom chains. It is built on the Runnable protocol.</span><br><span class="line"></span><br><span class="line">LCEL cheatsheet: For a quick overview of how to use the main LCEL primitives.</span><br><span class="line"></span><br><span class="line">Migration guide: For migrating legacy chain abstractions to LCEL.</span><br><span class="line"></span><br><span class="line">How to: chain runnables</span><br><span class="line"></span><br><span class="line">How to: stream runnables</span><br><span class="line"></span><br><span class="line">How to: invoke runnables in parallel</span><br><span class="line"></span><br><span class="line">How to: add default invocation args to runnables</span><br><span class="line"></span><br><span class="line">How to: turn any function into a runnable</span><br><span class="line"></span><br><span class="line">How to: pass through inputs from one chain step to the next</span><br><span class="line"></span><br><span class="line">How to: configure runnable behavior at runtime</span><br><span class="line"></span><br><span class="line">How to: add message history (memory) to a chain</span><br><span class="line"></span><br><span class="line">How to: route between sub-chains</span><br><span class="line"></span><br><span class="line">How to: create a dynamic (self-constructing) chain</span><br><span class="line"></span><br><span class="line">How to: inspect runnables</span><br><span class="line"></span><br><span class="line">How to: add fallbacks to a runnable</span><br><span class="line"></span><br><span class="line">🔍 分块 12:</span><br><span class="line">How to: inspect runnables</span><br><span class="line"></span><br><span class="line">How to: add fallbacks to a runnable</span><br><span class="line"></span><br><span class="line">How to: pass runtime secrets to a runnable</span><br><span class="line"></span><br><span class="line">LangGraph</span><br><span class="line"></span><br><span class="line">LangGraph is an extension of LangChain aimed at building robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.</span><br><span class="line"></span><br><span class="line">LangGraph documentation is currently hosted on a separate site. You can peruse LangGraph how-to guides here.</span><br><span class="line"></span><br><span class="line">LangSmith</span><br><span class="line"></span><br><span class="line">LangSmith allows you to closely trace, monitor and evaluate your LLM application. It seamlessly integrates with LangChain and LangGraph, and you can use it to inspect and debug individual steps of your chains and agents as you build.</span><br><span class="line"></span><br><span class="line">LangSmith documentation is hosted on a separate site. You can peruse LangSmith how-to guides here, but we&#x27;ll highlight a few sections that are particularly relevant to LangChain below:</span><br><span class="line"></span><br><span class="line">Evaluation</span><br><span class="line"></span><br><span class="line">🔍 分块 13:</span><br><span class="line">Evaluation</span><br><span class="line"></span><br><span class="line">Evaluating performance is a vital part of building LLM-powered applications. LangSmith helps with every step of the process from creating a dataset to defining metrics to running evaluators.</span><br><span class="line"></span><br><span class="line">To learn more, check out the LangSmith evaluation how-to guides.</span><br><span class="line"></span><br><span class="line">Tracing</span><br><span class="line"></span><br><span class="line">Tracing gives you observability inside your chains and agents, and is vital in diagnosing issues.</span><br><span class="line"></span><br><span class="line">How to: trace with LangChain</span><br><span class="line"></span><br><span class="line">How to: add metadata and tags to traces</span><br><span class="line"></span><br><span class="line">You can see general tracing-related how-tos in this section of the LangSmith docs.</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h4 id="阶段2向量存储与检索">阶段2：向量存储与检索</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings  </span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> Chroma  </span><br><span class="line">   </span><br><span class="line"><span class="comment"># 5. 获取嵌入模型import os  </span></span><br><span class="line"><span class="keyword">import</span> dotenv  </span><br><span class="line">dotenv.load_dotenv()  </span><br><span class="line">  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = os.getenv(<span class="string">&quot;SILICONFLOW_API_KEY&quot;</span>)  </span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_BASE_URL&#x27;</span>] = os.getenv(<span class="string">&quot;BASE_URL&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">embeddings = OpenAIEmbeddings(  </span><br><span class="line">    model=<span class="string">&quot;Qwen/Qwen3-Embedding-0.6B&quot;</span>,  </span><br><span class="line">)  </span><br><span class="line"> <span class="comment"># 6. 向量数据存储（默认存储到内存中）  </span></span><br><span class="line">db = Chroma.from_documents(documents, embeddings)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 7. 向量检索  </span></span><br><span class="line">retriever = db.as_retriever()  </span><br><span class="line">docs = retriever.invoke(<span class="string">&quot;what is Chat Models?&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i, doc <span class="keyword">in</span> <span class="built_in">enumerate</span>(docs):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n🔍 分块 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>:&quot;</span>)  </span><br><span class="line">    <span class="built_in">print</span>(doc.page_content)</span><br></pre></td></tr></table></figure>
<p>结果： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">🔍 分块 1:</span><br><span class="line">How to: use few shot examples</span><br><span class="line"></span><br><span class="line">How to: use few shot examples <span class="keyword">in</span> chat models</span><br><span class="line"></span><br><span class="line">How to: partially format prompt templates</span><br><span class="line"></span><br><span class="line">How to: compose prompts together</span><br><span class="line"></span><br><span class="line">How to: use multimodal prompts</span><br><span class="line"></span><br><span class="line">Example selectors</span><br><span class="line"></span><br><span class="line">Example Selectors are responsible <span class="keyword">for</span> selecting the correct few shot examples to pass to the prompt.</span><br><span class="line"></span><br><span class="line">How to: use example selectors</span><br><span class="line"></span><br><span class="line">How to: <span class="keyword">select</span> examples by length</span><br><span class="line"></span><br><span class="line">How to: <span class="keyword">select</span> examples by semantic similarity</span><br><span class="line"></span><br><span class="line">How to: <span class="keyword">select</span> examples by semantic ngram overlap</span><br><span class="line"></span><br><span class="line">How to: <span class="keyword">select</span> examples by maximal marginal relevance</span><br><span class="line"></span><br><span class="line">How to: <span class="keyword">select</span> examples from LangSmith few-shot datasets</span><br><span class="line"></span><br><span class="line">LLMs</span><br><span class="line"></span><br><span class="line">What LangChain calls LLMs are older forms of language models that take a string <span class="keyword">in</span> and output a string.</span><br><span class="line"></span><br><span class="line">How to: cache model responses</span><br><span class="line"></span><br><span class="line">How to: create a custom LLM class</span><br><span class="line"></span><br><span class="line">How to: stream a response back</span><br><span class="line"></span><br><span class="line">How to: track token usage</span><br><span class="line"></span><br><span class="line">How to: work with <span class="built_in">local</span> models</span><br><span class="line"></span><br><span class="line">Output parsers</span><br><span class="line"></span><br><span class="line">Output Parsers are responsible <span class="keyword">for</span> taking the output of an LLM and parsing into more structured format.</span><br><span class="line"></span><br><span class="line">🔍 分块 2:</span><br><span class="line">How to: summarize text through iterative refinement</span><br><span class="line"></span><br><span class="line">LangChain Expression Language (LCEL)</span><br><span class="line"></span><br><span class="line">Should I use LCEL?</span><br><span class="line"></span><br><span class="line">LCEL is an orchestration solution. See our concepts page <span class="keyword">for</span> recommendations on when to use LCEL.</span><br><span class="line"></span><br><span class="line">LangChain Expression Language is a way to create arbitrary custom chains. It is built on the Runnable protocol.</span><br><span class="line"></span><br><span class="line">LCEL cheatsheet: For a quick overview of how to use the main LCEL primitives.</span><br><span class="line"></span><br><span class="line">Migration guide: For migrating legacy chain abstractions to LCEL.</span><br><span class="line"></span><br><span class="line">How to: chain runnables</span><br><span class="line"></span><br><span class="line">How to: stream runnables</span><br><span class="line"></span><br><span class="line">How to: invoke runnables <span class="keyword">in</span> parallel</span><br><span class="line"></span><br><span class="line">How to: add default invocation args to runnables</span><br><span class="line"></span><br><span class="line">How to: turn any <span class="keyword">function</span> into a runnable</span><br><span class="line"></span><br><span class="line">How to: pass through inputs from one chain step to the next</span><br><span class="line"></span><br><span class="line">How to: configure runnable behavior at runtime</span><br><span class="line"></span><br><span class="line">How to: add message <span class="built_in">history</span> (memory) to a chain</span><br><span class="line"></span><br><span class="line">How to: route between sub-chains</span><br><span class="line"></span><br><span class="line">How to: create a dynamic (self-constructing) chain</span><br><span class="line"></span><br><span class="line">How to: inspect runnables</span><br><span class="line"></span><br><span class="line">How to: add fallbacks to a runnable</span><br><span class="line"></span><br><span class="line">🔍 分块 3:</span><br><span class="line">How to: <span class="keyword">do</span> <span class="keyword">function</span>/tool calling</span><br><span class="line"></span><br><span class="line">How to: get models to <span class="built_in">return</span> structured output</span><br><span class="line"></span><br><span class="line">How to: cache model responses</span><br><span class="line"></span><br><span class="line">How to: get <span class="built_in">log</span> probabilities</span><br><span class="line"></span><br><span class="line">How to: create a custom chat model class</span><br><span class="line"></span><br><span class="line">How to: stream a response back</span><br><span class="line"></span><br><span class="line">How to: track token usage</span><br><span class="line"></span><br><span class="line">How to: track response metadata across providers</span><br><span class="line"></span><br><span class="line">How to: use chat model to call tools</span><br><span class="line"></span><br><span class="line">How to: stream tool calls</span><br><span class="line"></span><br><span class="line">How to: handle rate limits</span><br><span class="line"></span><br><span class="line">How to: few shot prompt tool behavior</span><br><span class="line"></span><br><span class="line">How to: <span class="built_in">bind</span> model-specific formatted tools</span><br><span class="line"></span><br><span class="line">How to: force a specific tool call</span><br><span class="line"></span><br><span class="line">How to: work with <span class="built_in">local</span> models</span><br><span class="line"></span><br><span class="line">How to: init any model <span class="keyword">in</span> one line</span><br><span class="line"></span><br><span class="line">How to: pass multimodal data directly to models</span><br><span class="line"></span><br><span class="line">Messages</span><br><span class="line"></span><br><span class="line">Messages are the input and output of chat models. They have some content and a role, <span class="built_in">which</span> describes the <span class="built_in">source</span> of the message.</span><br><span class="line"></span><br><span class="line">How to: trim messages</span><br><span class="line"></span><br><span class="line">How to: filter messages</span><br><span class="line"></span><br><span class="line">How to: merge consecutive messages of the same <span class="built_in">type</span></span><br><span class="line"></span><br><span class="line">Prompt templates</span><br><span class="line"></span><br><span class="line">Prompt Templates are responsible <span class="keyword">for</span> formatting user input into a format that can be passed to a language model.</span><br><span class="line"></span><br><span class="line">🔍 分块 4:</span><br><span class="line">How to: pass <span class="keyword">in</span> callbacks at runtime</span><br><span class="line"></span><br><span class="line">How to: attach callbacks to a module</span><br><span class="line"></span><br><span class="line">How to: pass callbacks into a module constructor</span><br><span class="line"></span><br><span class="line">How to: create custom callback handlers</span><br><span class="line"></span><br><span class="line">How to: use callbacks <span class="keyword">in</span> async environments</span><br><span class="line"></span><br><span class="line">How to: dispatch custom callback events</span><br><span class="line"></span><br><span class="line">Custom</span><br><span class="line"></span><br><span class="line">All of LangChain components can easily be extended to support your own versions.</span><br><span class="line"></span><br><span class="line">How to: create a custom chat model class</span><br><span class="line"></span><br><span class="line">How to: create a custom LLM class</span><br><span class="line"></span><br><span class="line">How to: create a custom embeddings class</span><br><span class="line"></span><br><span class="line">How to: write a custom retriever class</span><br><span class="line"></span><br><span class="line">How to: write a custom document loader</span><br><span class="line"></span><br><span class="line">How to: write a custom output parser class</span><br><span class="line"></span><br><span class="line">How to: create custom callback handlers</span><br><span class="line"></span><br><span class="line">How to: define a custom tool</span><br><span class="line"></span><br><span class="line">How to: dispatch custom callback events</span><br><span class="line"></span><br><span class="line">Serialization</span><br><span class="line"></span><br><span class="line">How to: save and load LangChain objects</span><br><span class="line"></span><br><span class="line">Use cases</span><br><span class="line"></span><br><span class="line">These guides cover use-case specific details.</span><br><span class="line"></span><br><span class="line">Q&amp;A with RAG</span><br><span class="line"></span><br><span class="line">Retrieval Augmented Generation (RAG) is a way to connect LLMs to external sources of data. For a high-level tutorial on RAG, check out this guide.</span><br><span class="line"></span><br><span class="line">How to: add chat <span class="built_in">history</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h4 id="阶段3">阶段3</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI  </span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate  </span><br><span class="line">  </span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;deepseek-ai/DeepSeek-V3&quot;</span>)  </span><br><span class="line"><span class="comment"># 8.定义提示词模版  </span></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">你是一个问答机器人。  </span></span><br><span class="line"><span class="string">你的任务是根据下述给定的已知信息回答用户问题。  </span></span><br><span class="line"><span class="string">确保你的回复完全依据下述已知信息。不要编造答案。  </span></span><br><span class="line"><span class="string">如果下述已知信息不足以回答用户的问题，请直接回复&quot;我无法回答您的问题&quot;。  </span></span><br><span class="line"><span class="string">已知信息:  </span></span><br><span class="line"><span class="string"> &#123;context&#125;用户问：  </span></span><br><span class="line"><span class="string">&#123;question&#125;  </span></span><br><span class="line"><span class="string">请用中文回答用户问题。  </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>  </span><br><span class="line"><span class="comment"># 7.得到提示词模版对象  </span></span><br><span class="line">prompt_template = PromptTemplate.from_template(template=template)  </span><br><span class="line"><span class="comment"># 8.得到提示词对象  </span></span><br><span class="line">prompt = prompt_template.invoke(&#123;<span class="string">&quot;question&quot;</span>:<span class="string">&quot;what is Chat Models?&quot;</span>,<span class="string">&quot;context&quot;</span>:docs&#125;)  </span><br><span class="line"> <span class="comment"># 9. 调用LLM  </span></span><br><span class="line">response = llm.invoke(prompt)  </span><br><span class="line"><span class="built_in">print</span>(response.content)</span><br></pre></td></tr></table></figure>
<p>结果: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">根据已知信息，<span class="string">&quot;Chat Models&quot;</span>（聊天模型）是LangChain中的一个组件，它们以**消息**（Messages）作为输入和输出。每条消息包含内容（content）和角色（role），角色用于描述消息的来源（例如用户、系统等）。  </span><br><span class="line"></span><br><span class="line">已知信息中提到：  </span><br><span class="line">- 聊天模型的输入输出是结构化的消息（而非传统LLM的纯文本字符串）。  </span><br><span class="line">- 支持通过消息处理功能（如合并连续同类型消息、过滤或修剪消息）。  </span><br><span class="line">- 其他功能包括工具调用（tool calling）、流式返回响应（streaming）、跟踪令牌使用情况（token usage）等。  </span><br><span class="line"></span><br><span class="line">如果需要更具体的定义或实现细节，当前信息不足以回答。</span><br></pre></td></tr></table></figure></p>
<p>聊天模型（Chat Models）是新型的语言模型，它接收消息并输出消息。请查看特定提供者的支持集成以 了解如何开始使用聊天模型。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://cryingatnight.github.io">Yinjin Yao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://cryingatnight.github.io/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/">https://cryingatnight.github.io/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://cryingatnight.github.io" target="_blank">Yinjin Yao的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LangChain/">LangChain</a></div><div class="post-share"><div class="social-share" data-image="/img/lita9.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/09/26/LangChain%E4%BD%BF%E7%94%A8%E6%A6%82%E8%BF%B0/" title="LangChain使用概述"><img class="cover" src="/img/lita6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">LangChain使用概述</div></div><div class="info-2"><div class="info-item-1">LangChain使用概述 LangChain的使用场景    项目名称 技术点 难度     文档问答助手 Prompt + Embedding + RetrievalQA ⭐⭐   智能日程规划助手 Agent + Tool + Memory ⭐⭐⭐   LLM+数据库问答 SQLDatabaseToolkit + Agent ⭐⭐⭐⭐   多模型路由对话系统 RouterChain + 多 LLM ⭐⭐⭐⭐   互联网智能客服 ConversationChain + RAG +Agent ⭐⭐⭐⭐⭐   企业知识库助手（RAG + 本地模 型） VectorDB + LLM + Streamlit ⭐⭐⭐⭐⭐    LangChain资料介绍  官网地址：https://www.langchain.com/langchain 官网文档：https://python.langchain.com/docs/introduction/ API文档：https://python.langc...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/09/26/LangChain%E4%BD%BF%E7%94%A8%E6%A6%82%E8%BF%B0/" title="LangChain使用概述"><img class="cover" src="/img/lita6.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-26</div><div class="info-item-2">LangChain使用概述</div></div><div class="info-2"><div class="info-item-1">LangChain使用概述 LangChain的使用场景    项目名称 技术点 难度     文档问答助手 Prompt + Embedding + RetrievalQA ⭐⭐   智能日程规划助手 Agent + Tool + Memory ⭐⭐⭐   LLM+数据库问答 SQLDatabaseToolkit + Agent ⭐⭐⭐⭐   多模型路由对话系统 RouterChain + 多 LLM ⭐⭐⭐⭐   互联网智能客服 ConversationChain + RAG +Agent ⭐⭐⭐⭐⭐   企业知识库助手（RAG + 本地模 型） VectorDB + LLM + Streamlit ⭐⭐⭐⭐⭐    LangChain资料介绍  官网地址：https://www.langchain.com/langchain 官网文档：https://python.langchain.com/docs/introduction/ API文档：https://python.langc...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/headimage.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Yinjin Yao</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/cryingatnight/cryingatnight.github.io"><i class="fab fa-github"></i><span>关注</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/cryingatnight/cryingatnight.github.io" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1816192779@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#retrieval%E6%A8%A1%E5%9D%97%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%84%8F%E4%B9%89"><span class="toc-number">1.</span> <span class="toc-text">Retrieval模块的设计意义</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">大模型的幻觉问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rag%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.2.</span> <span class="toc-text">RAG的优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#retrieval%E6%B5%81%E7%A8%8B"><span class="toc-number">1.3.</span> <span class="toc-text">Retrieval流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E8%8A%821source%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="toc-number">1.3.1.</span> <span class="toc-text">环节1：Source（数据源）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E8%8A%822load%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.3.2.</span> <span class="toc-text">环节2：Load（加载）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E8%8A%823transform%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.3.3.</span> <span class="toc-text">环节3：Transform（转换）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8E%AF%E8%8A%823.1text-splitting%E6%96%87%E6%A1%A3%E6%8B%86%E5%88%86"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">环节3.1：Text Splitting（文档拆分）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E8%8A%824embed%E5%B5%8C%E5%85%A5"><span class="toc-number">1.3.4.</span> <span class="toc-text">环节4：Embed（嵌入）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E8%8A%825store%E5%AD%98%E5%82%A8"><span class="toc-number">1.3.5.</span> <span class="toc-text">环节5：Store（存储）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%AF%E8%8A%826retrieve%E6%A3%80%E7%B4%A2"><span class="toc-number">1.3.6.</span> <span class="toc-text">环节6：Retrieve（检索）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8-document-loaders"><span class="toc-number">2.</span> <span class="toc-text">文档加载器 Document Loaders</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDtxt"><span class="toc-number">2.1.</span> <span class="toc-text">加载txt</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDpdf"><span class="toc-number">2.2.</span> <span class="toc-text">加载pdf</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1"><span class="toc-number">2.2.1.</span> <span class="toc-text">举例1：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2"><span class="toc-number">2.2.2.</span> <span class="toc-text">举例2：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B3%E4%BD%BF%E7%94%A8load_and_split"><span class="toc-number">2.2.3.</span> <span class="toc-text">举例3：使用load_and_split()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDcsv"><span class="toc-number">2.3.</span> <span class="toc-text">加载CSV</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1%E5%8A%A0%E8%BD%BDcsv%E6%89%80%E6%9C%89%E5%88%97"><span class="toc-number">2.3.1.</span> <span class="toc-text">举例1：加载csv所有列</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2%E5%8A%A0%E8%BD%BD%E6%8C%87%E5%AE%9A%E5%88%97"><span class="toc-number">2.3.2.</span> <span class="toc-text">举例2：加载指定列</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDjson"><span class="toc-number">2.4.</span> <span class="toc-text">加载JSON</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1%E4%BD%BF%E7%94%A8jsonloader%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%8A%A0%E8%BD%BD"><span class="toc-number">2.4.1.</span> <span class="toc-text">举例1：使用JSONLoader文档加载器加载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2%E5%8A%A0%E8%BD%BDjson%E6%96%87%E4%BB%B6%E4%B8%ADmessages%E4%B8%AD%E7%9A%84%E6%89%80%E6%9C%89%E7%9A%84content%E5%AD%97%E6%AE%B5"><span class="toc-number">2.4.2.</span> <span class="toc-text">举例2：加载json文件中messages[]中的所有的content字段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B3%E6%8F%90%E5%8F%9604-response.json%E6%96%87%E4%BB%B6%E4%B8%AD%E5%B5%8C%E5%A5%97%E5%9C%A8-data.items.content-%E7%9A%84%E6%96%87%E6%9C%AC"><span class="toc-number">2.4.3.</span> <span class="toc-text">举例3：提取04-response.json文件中嵌套在 data.items[].content 的文本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B4%E6%8F%90%E5%8F%9604-response.json%E6%96%87%E4%BB%B6%E4%B8%AD%E5%B5%8C%E5%A5%97%E5%9C%A8-data.items-%E9%87%8C%E7%9A%84-titlecontent-%E5%92%8C-%E5%85%B6%E6%96%87%E6%9C%AC"><span class="toc-number">2.4.4.</span> <span class="toc-text">举例4：提取04-response.json文件中嵌套在 data.items[] 里的 title、content 和 其文本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDhtml%E4%BA%86%E8%A7%A3"><span class="toc-number">2.5.</span> <span class="toc-text">加载HTML(了解)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDmarkdown%E4%BA%86%E8%A7%A3"><span class="toc-number">2.6.</span> <span class="toc-text">加载Markdown(了解)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1%E4%BD%BF%E7%94%A8markdownloader%E5%8A%A0%E8%BD%BDmd%E6%96%87%E4%BB%B6"><span class="toc-number">2.6.1.</span> <span class="toc-text">举例1：使用MarkDownLoader加载md文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2%E7%B2%BE%E7%BB%86%E5%88%86%E5%89%B2%E6%96%87%E6%A1%A3%E4%BF%9D%E7%95%99%E7%BB%93%E6%9E%84%E4%BF%A1%E6%81%AF"><span class="toc-number">2.6.2.</span> <span class="toc-text">举例2：精细分割文档，保留结构信息</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BDfile-directory%E4%BA%86%E8%A7%A3"><span class="toc-number">2.7.</span> <span class="toc-text">加载File Directory(了解)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E6%8B%86%E5%88%86%E5%99%A8-text-splitters"><span class="toc-number">3.</span> <span class="toc-text">文档拆分器 Text Splitters</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%8B%86%E5%88%86%E5%88%86%E5%9D%97%E5%88%87%E5%88%86"><span class="toc-number">3.1.</span> <span class="toc-text">为什么要拆分&#x2F;分块&#x2F;切分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#chunking%E6%8B%86%E5%88%86%E7%9A%84%E7%AD%96%E7%95%A5"><span class="toc-number">3.2.</span> <span class="toc-text">Chunking拆分的策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.3.</span> <span class="toc-text">具体实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#charactertextsplittersplit-by-character"><span class="toc-number">3.3.1.</span> <span class="toc-text">CharacterTextSplitter：Split by character</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%96%87%E6%9C%AC%E7%9A%84%E5%88%86%E5%89%B2"><span class="toc-number">3.3.1.1.</span> <span class="toc-text">举例1：字符串文本的分割</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2%E6%8C%87%E5%AE%9A%E5%88%86%E5%89%B2%E7%AC%A6"><span class="toc-number">3.3.1.2.</span> <span class="toc-text">举例2：指定分割符</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B3%E6%8C%87%E5%AE%9A%E5%88%86%E5%89%B2%E7%AC%A6"><span class="toc-number">3.3.1.3.</span> <span class="toc-text">举例3：指定分割符</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#recursivecharactertextsplitter%E6%9C%80%E5%B8%B8%E7%94%A8"><span class="toc-number">3.3.2.</span> <span class="toc-text">RecursiveCharacterTextSplitter：最常用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1%E4%BD%BF%E7%94%A8split_text%E6%96%B9%E6%B3%95%E6%BC%94%E7%A4%BA"><span class="toc-number">3.3.2.1.</span> <span class="toc-text">举例1：使用split_text()方法演示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2%E4%BD%BF%E7%94%A8create_documents%E6%96%B9%E6%B3%95%E6%BC%94%E7%A4%BA%E4%BC%A0%E5%85%A5%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%97%E8%A1%A8%E8%BF%94%E5%9B%9Edocument%E5%AF%B9%E8%B1%A1%E5%88%97%E8%A1%A8"><span class="toc-number">3.3.2.2.</span> <span class="toc-text">举例2：使用create_documents()方法演示，传入字符串列表，返回Document对象列表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B3%E4%BD%BF%E7%94%A8create_documents%E6%96%B9%E6%B3%95%E6%BC%94%E7%A4%BA%E5%B0%86%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9%E5%8A%A0%E8%BD%BD%E6%88%90%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BF%9B%E8%A1%8C%E6%8B%86%E5%88%86"><span class="toc-number">3.3.2.3.</span> <span class="toc-text">举例3：使用create_documents()方法演示，将本地文件内容加载成字符串，进行拆分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B4%E4%BD%BF%E7%94%A8split_documents%E6%96%B9%E6%B3%95%E6%BC%94%E7%A4%BA%E5%88%A9%E7%94%A8pdfloader%E5%8A%A0%E8%BD%BD%E6%96%87%E6%A1%A3%E5%AF%B9%E6%96%87%E6%A1%A3%E7%9A%84%E5%86%85%E5%AE%B9%E7%94%A8%E9%80%92%E5%BD%92%E5%88%87%E5%89%B2%E5%99%A8%E5%88%87%E5%89%B2"><span class="toc-number">3.3.2.4.</span> <span class="toc-text">举例4：使用split_documents()方法演示，利用PDFLoader加载文档，对文档的内容用递归切割器切割</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B5%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E9%9A%94%E7%AC%A6"><span class="toc-number">3.3.2.5.</span> <span class="toc-text">举例5：自定义分隔符</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tokentextsplittercharactertextsplittersplit-by-tokens"><span class="toc-number">3.3.3.</span> <span class="toc-text">TokenTextSplitter&#x2F;CharacterTextSplitter：Split by tokens</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1%E4%BD%BF%E7%94%A8tokentextsplitter"><span class="toc-number">3.3.3.1.</span> <span class="toc-text">举例1：使用TokenTextSplitter</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2%E4%BD%BF%E7%94%A8charactertextsplitter"><span class="toc-number">3.3.3.2.</span> <span class="toc-text">举例2：使用CharacterTextSplitter</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#semanticchunker%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97"><span class="toc-number">3.3.4.</span> <span class="toc-text">SemanticChunker：语义分块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E5%AE%83%E6%8B%86%E5%88%86%E5%99%A8"><span class="toc-number">3.3.5.</span> <span class="toc-text">其它拆分器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E5%9E%8B1htmlheadertextsplittersplit-by-html-header"><span class="toc-number">3.3.5.1.</span> <span class="toc-text">类型1：HTMLHeaderTextSplitter：Split by HTML header</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E5%9E%8B2codetextsplittersplit-code"><span class="toc-number">3.3.5.2.</span> <span class="toc-text">类型2：CodeTextSplitter：Split code</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E5%9E%8B3markdowntextsplittermd%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">3.3.5.3.</span> <span class="toc-text">类型3：MarkdownTextSplitter：md数据类型</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B-text-embedding-models"><span class="toc-number">4.</span> <span class="toc-text">文档嵌入模型 Text Embedding Models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0"><span class="toc-number">4.1.</span> <span class="toc-text">嵌入模型概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%A5%E5%AD%90%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96embed_query"><span class="toc-number">4.2.</span> <span class="toc-text">句子的向量化（embed_query）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96embed_documents"><span class="toc-number">4.3.</span> <span class="toc-text">文档的向量化（embed_documents）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1-1"><span class="toc-number">4.3.1.</span> <span class="toc-text">举例1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2-1"><span class="toc-number">4.3.2.</span> <span class="toc-text">举例2</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8vector-stores"><span class="toc-number">5.</span> <span class="toc-text">向量存储(Vector Stores)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%90%86%E8%A7%A3%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8"><span class="toc-number">5.1.</span> <span class="toc-text">理解向量存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">5.2.</span> <span class="toc-text">常用的向量数据库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">5.3.</span> <span class="toc-text">代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AD%98%E5%82%A8"><span class="toc-number">5.3.1.</span> <span class="toc-text">数据的存储</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B1%E4%BB%8Etxt%E6%96%87%E6%A1%A3%E4%B8%AD%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%90%91%E9%87%8F%E5%8C%96%E5%90%8E%E5%AD%98%E5%82%A8%E5%88%B0chroma%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">5.3.1.1.</span> <span class="toc-text">举例1：从TXT文档中加载数据，向量化后存储到Chroma数据库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2%E6%93%8D%E4%BD%9Ccsv%E6%96%87%E6%A1%A3%E5%B9%B6%E5%90%91%E9%87%8F%E5%8C%96"><span class="toc-number">5.3.1.2.</span> <span class="toc-text">举例2：操作csv文档，并向量化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E6%A3%80%E7%B4%A2"><span class="toc-number">5.3.2.</span> <span class="toc-text">数据的检索</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%A3%80%E7%B4%A2similarity_search"><span class="toc-number">5.3.2.1.</span> <span class="toc-text">① 相似性检索（similarity_search）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E7%9B%B4%E6%8E%A5%E5%AF%B9%E9%97%AE%E9%A2%98%E5%90%91%E9%87%8F%E6%9F%A5%E8%AF%A2similarity_search_by_vector"><span class="toc-number">5.3.2.2.</span> <span class="toc-text">② 支持直接对问题向量查询（similarity_search_by_vector）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%A3%80%E7%B4%A2%E6%94%AF%E6%8C%81%E8%BF%87%E6%BB%A4%E5%85%83%E6%95%B0%E6%8D%AEfilter"><span class="toc-number">5.3.2.3.</span> <span class="toc-text">③ 相似性检索，支持过滤元数据（filter）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87l2%E8%B7%9D%E7%A6%BB%E5%88%86%E6%95%B0%E8%BF%9B%E8%A1%8C%E6%90%9C%E7%B4%A2similarity_search_with_score"><span class="toc-number">5.3.2.4.</span> <span class="toc-text">④ 通过L2距离分数进行搜索（similarity_search_with_score）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E5%88%86%E6%95%B0%E8%BF%9B%E8%A1%8C%E6%90%9C%E7%B4%A2_similarity_search_with_relevance_scores"><span class="toc-number">5.3.2.5.</span> <span class="toc-text">⑤ 通过余弦相似度分数进行搜索（_similarity_search_with_relevance_scores）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mmr%E6%9C%80%E5%A4%A7%E8%BE%B9%E9%99%85%E7%9B%B8%E5%85%B3%E6%80%A7max_marginal_relevance_search"><span class="toc-number">5.3.2.6.</span> <span class="toc-text">⑥ MMR（最大边际相关性，max_marginal_relevance_search）</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A3%80%E7%B4%A2%E5%99%A8%E5%8F%AC%E5%9B%9E%E5%99%A8-retrievers"><span class="toc-number">6.</span> <span class="toc-text">检索器(召回器) Retrievers</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">6.1.</span> <span class="toc-text">代码实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%9B%B8%E5%85%B3%E6%A3%80%E7%B4%A2%E7%AD%96"><span class="toc-number">6.2.</span> <span class="toc-text">使用相关检索策</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E6%A3%80%E7%B4%A2%E5%99%A8%E4%BD%BF%E7%94%A8%E7%9B%B8%E4%BC%BC%E6%80%A7%E6%90%9C%E7%B4%A2"><span class="toc-number">6.2.1.</span> <span class="toc-text">① 默认检索器使用相似性搜索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%95%B0%E9%98%88%E5%80%BC%E6%9F%A5%E8%AF%A2"><span class="toc-number">6.2.2.</span> <span class="toc-text">② 分数阈值查询</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mmr%E6%90%9C%E7%B4%A2"><span class="toc-number">6.2.3.</span> <span class="toc-text">③ MMR搜索</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E5%90%88%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">6.3.</span> <span class="toc-text">结合大模型的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%83%85%E5%86%B52%E4%BD%BF%E7%94%A8rag%E7%BB%99llm%E7%81%8C%E8%BE%93%E4%B8%8A%E4%B8%8B%E6%96%87%E6%95%B0%E6%8D%AE"><span class="toc-number">6.3.1.</span> <span class="toc-text">情况2：使用RAG给LLM灌输上下文数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B2%E4%BD%BF%E7%94%A8chroma%E6%95%B0%E6%8D%AE%E5%BA%93-%E4%B8%8E%E4%B8%BE%E4%BE%8B1%E7%B1%BB%E4%BC%BC"><span class="toc-number">6.3.2.</span> <span class="toc-text">举例2：使用Chroma数据库 （与举例1类似）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%B6%E6%AE%B51%E6%96%87%E6%A1%A3%E7%9A%84%E5%88%87%E5%88%86"><span class="toc-number">6.3.2.1.</span> <span class="toc-text">阶段1：文档的切分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%B6%E6%AE%B52%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2"><span class="toc-number">6.3.2.2.</span> <span class="toc-text">阶段2：向量存储与检索</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%B6%E6%AE%B53"><span class="toc-number">6.3.2.3.</span> <span class="toc-text">阶段3</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/" title="LangChain使用之Retrieval"><img src="/img/lita9.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LangChain使用之Retrieval"/></a><div class="content"><a class="title" href="/2025/09/28/LangChain%E4%BD%BF%E7%94%A8%E4%B9%8BRetrieval/" title="LangChain使用之Retrieval">LangChain使用之Retrieval</a><time datetime="2025-09-28T03:10:40.030Z" title="更新于 2025-09-28 11:10:40">2025-09-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/26/LangChain%E4%BD%BF%E7%94%A8%E6%A6%82%E8%BF%B0/" title="LangChain使用概述"><img src="/img/lita6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LangChain使用概述"/></a><div class="content"><a class="title" href="/2025/09/26/LangChain%E4%BD%BF%E7%94%A8%E6%A6%82%E8%BF%B0/" title="LangChain使用概述">LangChain使用概述</a><time datetime="2025-09-26T03:37:36.148Z" title="更新于 2025-09-26 11:37:36">2025-09-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/23/chromadb%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/" title="chromadb向量数据库"><img src="/img/lita7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="chromadb向量数据库"/></a><div class="content"><a class="title" href="/2025/09/23/chromadb%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/" title="chromadb向量数据库">chromadb向量数据库</a><time datetime="2025-09-23T16:37:51.853Z" title="更新于 2025-09-24 00:37:51">2025-09-24</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By Yinjin Yao</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div><div class="footer_custom_text">感谢阅读</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="输入以搜索内容..." type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>